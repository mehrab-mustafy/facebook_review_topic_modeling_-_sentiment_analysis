{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73d5b3f7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/mlproject/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4a60401",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('play_store_facebook_reviews_with_sentiment_full.csv')\n",
    "df1.drop(columns=['Score'], inplace=True)\n",
    "df1['Category'] = df1['Category'].replace('good', 1)\n",
    "df1['Category'] = df1['Category'].replace('bad', 0)\n",
    "\n",
    "\n",
    "df2 = pd.read_csv('app_store_facebook_reviews_with_sentiment_full.csv')\n",
    "df2.drop(columns=['Score'], inplace=True)\n",
    "df2['Category'] = df2['Category'].replace('good', 1)\n",
    "df2['Category'] = df2['Category'].replace('bad', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6de27889",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['messenger', 'newsfeed', 'photos', 'song', 'video', 'back', 'button', 'gaming', 'marketplace', 'notification', 'menu', 'reels', 'story', 'cover', 'cover photo', 'profile', 'friend', 'event', 'timeline', 'groups', 'status', 'save', 'posts', 'like', 'comments', 'share', 'reacts', 'privacy', 'album', 'login', 'signup', 'register', 'pages', 'ad', 'advertisement', 'dating']\n"
     ]
    }
   ],
   "source": [
    "facebook_features = ['messenger', 'newsfeed', 'photos', 'song', 'video', 'back', 'button', 'gaming', 'marketplace', 'notification', 'menu', 'reels',\n",
    "                     'story', 'cover', 'cover photo', 'profile', 'friend', 'event', 'timeline', 'groups', 'status', 'save', 'posts', 'like', 'comments',\n",
    "                    'share', 'reacts', 'privacy', 'album', 'login', 'signup', 'register', 'pages', 'ad', 'advertisement', 'dating', 'memory', 'message']\n",
    "print(facebook_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc1636a7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16020, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5ab325c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13977\n",
       "1     1128\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['Category'] != 'neutral']\n",
    "unique_values_counts = df['Category'].value_counts()\n",
    "unique_values_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73d0631",
   "metadata": {},
   "source": [
    "<h2>1. Preprocessing Starts for Classification<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "621461c0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mrahm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mrahm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Review Category  \\\n",
      "0      Ridiculous update -- the Back button no longer...        0   \n",
      "1      Since the most recent update, the backup arrow...        0   \n",
      "2      This app is so unreliable. This has happened w...        0   \n",
      "3      Edit: Cool, so instead of fixing the existing ...        0   \n",
      "4      Y'all took away my ability to use my phone's b...        0   \n",
      "...                                                  ...      ...   \n",
      "16015  Just last week I could edit my post on my phon...        0   \n",
      "16016  My mom passed in May and I submitted 2 request...        0   \n",
      "16017  This app is trashiest. Facebook has no rules t...        0   \n",
      "16018  This app is trash!! Y’all are so sensitive 🤬 I...        0   \n",
      "16019  Literally no excuses. This is a gigantic compa...        0   \n",
      "\n",
      "                                       content_processed  \n",
      "0      [ridicul, updat, back, button, longer, work, u...  \n",
      "1      [sinc, recent, updat, backup, arrow, work, pho...  \n",
      "2      [app, unreli, happen, way, mani, time, get, ne...  \n",
      "3      [edit, cool, instead, fix, exist, back, button...  \n",
      "4      [yall, took, away, abil, use, phone, back, but...  \n",
      "...                                                  ...  \n",
      "16015  [last, week, edit, post, phone, forgot, someth...  \n",
      "16016  [mom, pass, submit, request, account, track, r...  \n",
      "16017  [app, trashiest, facebook, rule, make, sinc, a...  \n",
      "16018  [app, trash, yall, sensit, keep, get, repriman...  \n",
      "16019  [liter, excus, gigant, compani, fix, adher, ac...  \n",
      "\n",
      "[15105 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/mlproject/lib/python3.6/site-packages/ipykernel_launcher.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "import re\n",
    "\n",
    "# Download NLTK resources (uncomment the following two lines if you haven't downloaded them before)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function for text preprocessing\n",
    "def preprocess_text(review):\n",
    "    # Convert to lowercase\n",
    "    review = review.lower()\n",
    "\n",
    "    # Remove URLs\n",
    "    review = re.sub(r'https?://\\S+|www\\.\\S+', '', review)\n",
    "\n",
    "    # Remove emojis\n",
    "    review = review.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "    # Remove punctuation, apostrophes, and quotes\n",
    "    review = re.sub(r\"[^a-zA-Z\\s]\", '', review)\n",
    "\n",
    "\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    review = emoji_pattern.sub(r'', review)\n",
    "    \n",
    "    \n",
    "    # removing apostrophe 's from words in the text\n",
    "    review = re.sub(r'\\'s\\s', ' ', review)\n",
    "    # omitting other apostrophes\n",
    "    review = re.sub(r'\\'', '', review)\n",
    "\n",
    "    # removing Emails\n",
    "    review = re.sub(r'\\S*@\\S*\\s?', '', review)\n",
    "\n",
    "\n",
    "    # removing distracting single quotes\n",
    "    review = re.sub(r\"\\'\", \"\", review)\n",
    "    \n",
    "    # Tokenize\n",
    "    words = word_tokenize(review)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # POS tagging and keep only nouns, adjectives, verbs, and adverbs\n",
    "    pos_tags = pos_tag(words)\n",
    "    words = [word for word, pos in pos_tags if pos.startswith(('N', 'J', 'V', 'R'))]\n",
    "\n",
    "    return words\n",
    "\n",
    "# Apply preprocessing and create a new column 'content_processed'\n",
    "df['content_processed'] = df['Review'].apply(preprocess_text)\n",
    "\n",
    "# Display the processed DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "034d3772",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [ridicul, updat, back, button, longer, work, u...\n",
       "1        [sinc, recent, updat, backup, arrow, work, pho...\n",
       "2        [app, unreli, happen, way, mani, time, get, ne...\n",
       "3        [edit, cool, instead, fix, exist, back, button...\n",
       "4        [yall, took, away, abil, use, phone, back, but...\n",
       "                               ...                        \n",
       "16015    [last, week, edit, post, phone, forgot, someth...\n",
       "16016    [mom, pass, submit, request, account, track, r...\n",
       "16017    [app, trashiest, facebook, rule, make, sinc, a...\n",
       "16018    [app, trash, yall, sensit, keep, get, repriman...\n",
       "16019    [liter, excus, gigant, compani, fix, adher, ac...\n",
       "Name: content_processed, Length: 15105, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content_processed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49998faf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/mlproject/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/mrahm/anaconda3/envs/mlproject/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df['content_processed'] = df['content_processed'].astype(str).str.replace(r'\\[|\\]|,', '', regex=True)\n",
    "df['content_processed'] = df['content_processed'].str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44b02b0d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/mlproject/lib/python3.6/site-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df.rename(columns={'content_processed': 'Review'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb529fd7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       Category                                             Review\n",
       "0            0  ridicul updat back button longer work use face...\n",
       "1            0  sinc recent updat backup arrow work phone im u...\n",
       "2            0  app unreli happen way mani time get new updat ...\n",
       "3            0  edit cool instead fix exist back button issu a...\n",
       "4            0  yall took away abil use phone back button bott...\n",
       "...        ...                                                ...\n",
       "16015        0  last week edit post phone forgot someth misspe...\n",
       "16016        0  mom pass submit request account track request ...\n",
       "16017        0  app trashiest facebook rule make sinc allow ra...\n",
       "16018        0  app trash yall sensit keep get reprimand guy p...\n",
       "16019        0  liter excus gigant compani fix adher accur acc...\n",
       "\n",
       "[15105 rows x 2 columns]>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4aa398e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8056a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('final_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa08434",
   "metadata": {},
   "source": [
    "<h4>Preprocessing ends for Classification<h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6455c350",
   "metadata": {},
   "source": [
    "<h2>2. Classification Starts<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26dda25",
   "metadata": {},
   "source": [
    "<h4>2.1 SVM<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db9f2a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Category', 'Review'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('final_data.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33a98997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.5: Training Loss - 1.0246146922645785, Validation Loss - 1.0427163875823457, Test Accuracy: 0.941747572815534\n",
      "C = 1: Training Loss - 1.0024401438419603, Validation Loss - 1.0320195456398344, Test Accuracy: 0.9488084730803178\n",
      "C = 5: Training Loss - 0.9542532474671601, Validation Loss - 1.0194839114277818, Test Accuracy: 0.9373345101500441\n",
      "C = 10: Training Loss - 0.9414695904894332, Validation Loss - 1.0219436637521384, Test Accuracy: 0.9324801412180053\n",
      "C = 20: Training Loss - 0.9332727182104119, Validation Loss - 1.0270904301715917, Test Accuracy: 0.9232127096204766\n",
      "C = 50: Training Loss - 0.9274112335224871, Validation Loss - 1.040285997254177, Test Accuracy: 0.910414827890556\n",
      "C = 100: Training Loss - 0.926364359789048, Validation Loss - 1.047406166955802, Test Accuracy: 0.9029126213592233\n",
      "C = 1000: Training Loss - 0.9260446943310189, Validation Loss - 1.0507430678440173, Test Accuracy: 0.8984995586937334\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your dataset (replace 'your_dataset.csv' with your actual file)\n",
    "\n",
    "# Split the dataset into features (X) and labels (y)\n",
    "X = df['Review']\n",
    "y = df['Category']\n",
    "\n",
    "# Step 1: Split the dataset into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Step 2: Vectorize the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "C_values = [0.5, 1, 5, 10, 20, 50, 100, 1000]\n",
    "\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "num_epochs = 1\n",
    "# Lists to store training and validation loss for each epoch\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Training loop for different values of C\n",
    "for C_value in C_values:\n",
    "    # Train an SVM model with the current C value\n",
    "    svm_model = SVC(kernel='linear', C=C_value, random_state=42)\n",
    "    svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # Calculate hinge loss for training set\n",
    "    train_hinge_loss = np.maximum(0, 1 - y_train * svm_model.decision_function(X_train_tfidf))\n",
    "    train_average_hinge_loss = train_hinge_loss.mean()\n",
    "    train_losses.append(train_average_hinge_loss)\n",
    "\n",
    "    # Calculate hinge loss for validation set\n",
    "    val_hinge_loss = np.maximum(0, 1 - y_val * svm_model.decision_function(X_val_tfidf))\n",
    "    val_average_hinge_loss = val_hinge_loss.mean()\n",
    "    val_losses.append(val_average_hinge_loss)\n",
    "    # Evaluate on the test set after training\n",
    "    test_predictions = svm_model.predict(X_test_tfidf)\n",
    "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "    test_confusion_matrix = confusion_matrix(y_test, test_predictions)\n",
    "    print(f\"C = {C_value}: Training Loss - {train_average_hinge_loss}, Validation Loss - {val_average_hinge_loss}, Test Accuracy: {test_accuracy}\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# Plot the training and validation losses for different C values\n",
    "plt.plot(C_values, train_losses, label='Training Loss')\n",
    "plt.plot(C_values, val_losses, label='Validation Loss')\n",
    "plt.xscale('log')  # Use a logarithmic scale for better visualization\n",
    "plt.xlabel('C (Regularization Parameter)')\n",
    "plt.ylabel('Hinge Loss')\n",
    "plt.legend()\n",
    "plt.savefig('SVM: loss_vs_C.png')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf03e8a",
   "metadata": {},
   "source": [
    "<h4>2.2 Logistic Regression<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d70bbd3-473a-4f09-9cd3-e2ba76db2fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a4fa306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 2/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 3/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 4/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 5/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 6/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 8/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 9/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 10/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 11/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 12/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 13/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 15/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 16/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 17/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 18/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 19/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 20/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 21/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 22/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 23/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 24/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 25/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 27/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 28/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 29/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 30/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 31/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 33/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 34/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 35/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 36/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 37/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 39/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 40/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 41/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 42/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 43/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 44/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 46/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 47/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 48/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 49/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 50/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 51/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 53/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 54/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 55/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 56/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 57/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 58/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 60/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 61/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 62/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 63/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 64/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 65/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 67/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 68/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 69/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 70/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 71/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 72/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 74/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 75/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 76/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 77/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 78/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 79/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 81/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 82/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 83/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 84/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 85/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 86/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 88/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 89/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 90/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 91/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 92/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 93/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 95/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 96/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 97/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 98/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 99/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 100/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 102/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 103/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 104/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 105/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 106/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 107/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 109/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 110/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 111/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 112/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 113/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 114/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 116/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 117/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 118/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 119/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 120/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 121/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 123/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 124/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 125/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 126/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 127/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 128/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 130/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 131/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 132/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 133/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 134/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 135/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 137/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 138/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 139/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 140/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 141/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 142/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 144/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 145/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 146/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 147/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 148/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 149/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 151/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 152/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 153/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 154/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 155/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 156/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 158/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 159/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 160/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 161/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 162/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 163/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 165/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 166/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 167/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 168/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 169/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 170/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 172/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 173/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 174/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 175/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 176/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 177/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 179/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 180/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 181/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 182/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 183/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 184/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 186/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 187/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 188/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 189/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 190/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 192/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 193/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 194/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 195/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 196/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 198/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 199/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 200/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 201/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 202/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 204/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 205/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 206/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 207/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 208/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 209/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 211/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 212/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 213/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 214/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 215/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 216/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 218/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 219/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 220/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 221/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 222/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 224/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 225/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 226/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 227/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 228/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 229/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 231/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 232/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 233/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 234/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 235/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 236/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 238/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 239/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 240/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 241/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 242/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 243/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 245/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 246/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 247/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 248/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 249/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 250/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 252/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 253/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 254/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 255/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 256/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 257/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 258/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 259/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 260/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 261/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 262/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 263/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 264/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 265/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 266/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 267/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 268/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 269/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 270/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 271/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 273/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 274/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 275/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 276/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 277/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 278/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 280/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 281/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 282/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 283/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 284/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 285/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 287/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 288/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 289/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 290/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 291/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 292/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 294/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 295/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 296/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 297/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 298/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 299/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 301/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 302/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 303/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 304/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 305/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 307/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 308/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 309/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 310/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 311/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 312/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 314/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 315/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 316/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 317/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 318/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 319/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 320/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 321/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 322/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 323/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 324/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 325/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 326/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 328/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 329/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 330/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 331/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 332/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 333/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 335/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 336/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 337/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 338/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 339/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 340/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 342/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 343/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 344/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 345/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 346/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 347/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 349/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 350/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 351/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 352/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 353/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 354/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 356/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 357/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 358/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 359/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 360/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 361/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 362/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 363/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 364/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 365/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 366/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 367/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 368/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 370/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 371/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 372/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 373/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 374/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 375/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 377/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 378/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 379/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 380/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 381/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 382/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 383/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 384/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 385/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 386/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 387/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 388/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 389/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 391/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 392/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 393/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 394/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 395/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 396/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 398/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 399/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 400/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 401/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 402/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 403/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 404/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 405/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 406/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 407/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 408/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 409/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 410/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 411/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 412/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 413/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 414/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 415/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 416/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 417/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 418/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 419/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 420/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 421/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 422/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 423/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 424/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 426/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 427/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 428/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 429/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 430/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 431/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 432/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 433/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 434/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 435/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 436/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 437/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 438/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 439/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 440/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 441/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 442/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 443/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 444/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 445/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 447/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 448/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 449/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 450/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 451/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 452/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 453/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 454/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 455/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 456/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 457/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 458/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 459/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 461/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 462/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 463/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 464/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 465/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 466/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 468/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 469/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 470/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 471/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 472/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 473/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 475/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 476/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 477/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 478/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 479/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 480/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 482/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 483/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 484/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 485/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 486/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 487/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 488/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 489/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 490/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 491/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 492/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 493/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 494/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 496/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 497/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 498/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 499/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 500/500 - Train Loss: 0.2604, Val Loss: 0.2689, Test Loss: 0.2642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Split the dataset into features (X) and labels (y)\n",
    "X = df['Review']\n",
    "y = df['Category']\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Vectorize the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize logistic regression model\n",
    "logreg_model = LogisticRegression(max_iter=1, random_state=42, solver='lbfgs')\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 500\n",
    "\n",
    "# Lists to store training, validation, and test loss, accuracy for each epoch\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Training loop for multiple epochs\n",
    "for epoch in range(num_epochs):\n",
    "    # Fit the model on the training set for one epoch\n",
    "    logreg_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # Predictions and log loss for training set\n",
    "    train_predictions = logreg_model.predict(X_train_tfidf)\n",
    "    train_loss = log_loss(y_train, logreg_model.predict_proba(X_train_tfidf)[:, 1])\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "\n",
    "    # Predictions and log loss for validation set\n",
    "    val_predictions = logreg_model.predict(X_val_tfidf)\n",
    "    val_loss = log_loss(y_val, logreg_model.predict_proba(X_val_tfidf)[:, 1])\n",
    "    val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "\n",
    "    # Predictions and log loss for test set\n",
    "    test_predictions = logreg_model.predict(X_test_tfidf)\n",
    "    test_loss = log_loss(y_test, logreg_model.predict_proba(X_test_tfidf)[:, 1])\n",
    "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "    # Append values to lists\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} - \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Test Loss: {test_loss:.4f}, \"\n",
    "          f\"Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}, Test Acc: {test_accuracy:.4f}\")\n",
    "\n",
    "# Plot training, validation, and test loss\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "plt.plot(range(1, num_epochs + 1), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.legend()\n",
    "plt.savefig('Log Reg: epoch_vs_loss.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot training, validation, and test accuracy\n",
    "plt.plot(range(1, num_epochs + 1), train_accuracies, label='Training Accuracy')\n",
    "plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy')\n",
    "plt.plot(range(1, num_epochs + 1), test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('Log Reg: epoch_vs_accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6deb862d-ddbe-46d2-a498-0d10c4513ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "180 fits failed out of a total of 720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.92603805 0.92603805 0.92603805        nan 0.92603805\n",
      " 0.92603805 0.92603805        nan 0.92603805 0.92603805 0.92603805\n",
      "        nan 0.92603805 0.84271226 0.85321019        nan 0.92603805\n",
      " 0.84271226 0.85321019        nan 0.92603805 0.84271226 0.85321019\n",
      "        nan 0.92603805 0.92603805 0.92603805        nan 0.92603805\n",
      " 0.92603805 0.92603805        nan 0.92603805 0.92603805 0.92603805\n",
      "        nan 0.92603805 0.84933281 0.85084621        nan 0.92603805\n",
      " 0.84933281 0.85084621        nan 0.92603805 0.84933281 0.85084621\n",
      "        nan 0.92660552 0.92603805 0.92603805        nan 0.92660552\n",
      " 0.92603805 0.92603805        nan 0.92660552 0.92603805 0.92603805\n",
      "        nan 0.84091534 0.87657181 0.87657181        nan 0.84091534\n",
      " 0.87657181 0.87657181        nan 0.84091534 0.87657181 0.87657181\n",
      "        nan 0.93965758 0.93568546 0.93559089        nan 0.93965758\n",
      " 0.93568546 0.93559089        nan 0.93965758 0.93568546 0.93559089\n",
      "        nan 0.87789743 0.89860996 0.89870453        nan 0.87789743\n",
      " 0.89860996 0.89870453        nan 0.87789743 0.89860996 0.89870453\n",
      "        nan 0.93672565 0.94552176 0.94552176        nan 0.93672565\n",
      " 0.94552176 0.94552176        nan 0.93672565 0.94552176 0.94552176\n",
      "        nan 0.91383782 0.91412177 0.91402725        nan 0.91383782\n",
      " 0.91431094 0.91402725        nan 0.91383782 0.91431094 0.91402725\n",
      "        nan 0.92386293 0.93757725 0.93776633        nan 0.92386293\n",
      " 0.93786093 0.93776633        nan 0.92386293 0.93786093 0.93776633\n",
      "        nan 0.91459427 0.91885026 0.91903943        nan 0.91459427\n",
      " 0.91903943 0.91903943        nan 0.91459427 0.91903943 0.91903943]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 10, 'class_weight': None, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best Accuracy:  0.9455217608155471\n",
      "Validation Accuracy with Best Model:  0.9430714916151809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# Assuming you have already loaded your dataset into a DataFrame 'df'\n",
    "\n",
    "# Split the dataset into features (X) and labels (y)\n",
    "X = df['Review']\n",
    "y = df['Category']\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Vectorize the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "\n",
    "# Define the logistic regression model\n",
    "logreg_model = LogisticRegression(random_state=42, solver='lbfgs')\n",
    "\n",
    "# Define the hyperparameters to search\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'max_iter': [100, 500, 1000],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(logreg_model, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Print the best parameters and their corresponding accuracy\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Accuracy: \", grid_search.best_score_)\n",
    "\n",
    "# Use the best model for predictions on the validation set\n",
    "best_model = grid_search.best_estimator_\n",
    "val_predictions = best_model.predict(X_val_tfidf)\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(\"Validation Accuracy with Best Model: \", val_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d15bd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/mlproject/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 - Train Loss: 0.6943, Val Loss: 0.6924, Test Loss: 0.6924, Train Acc: 0.3302, Val Acc: 0.6174, Test Acc: 0.6041\n",
      "Epoch 2/500 - Train Loss: 0.6925, Val Loss: 0.6905, Test Loss: 0.6905, Train Acc: 0.6033, Val Acc: 0.8354, Test Acc: 0.8314\n",
      "Epoch 3/500 - Train Loss: 0.6906, Val Loss: 0.6887, Test Loss: 0.6887, Train Acc: 0.8221, Val Acc: 0.9064, Test Acc: 0.9095\n",
      "Epoch 4/500 - Train Loss: 0.6887, Val Loss: 0.6868, Test Loss: 0.6868, Train Acc: 0.9087, Val Acc: 0.9210, Test Acc: 0.9241\n",
      "Epoch 5/500 - Train Loss: 0.6868, Val Loss: 0.6850, Test Loss: 0.6850, Train Acc: 0.9246, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 6/500 - Train Loss: 0.6850, Val Loss: 0.6831, Test Loss: 0.6831, Train Acc: 0.9259, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 7/500 - Train Loss: 0.6832, Val Loss: 0.6813, Test Loss: 0.6813, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 8/500 - Train Loss: 0.6813, Val Loss: 0.6795, Test Loss: 0.6795, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 9/500 - Train Loss: 0.6795, Val Loss: 0.6777, Test Loss: 0.6777, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 10/500 - Train Loss: 0.6777, Val Loss: 0.6759, Test Loss: 0.6759, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 11/500 - Train Loss: 0.6759, Val Loss: 0.6742, Test Loss: 0.6741, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 12/500 - Train Loss: 0.6741, Val Loss: 0.6724, Test Loss: 0.6723, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 13/500 - Train Loss: 0.6723, Val Loss: 0.6706, Test Loss: 0.6706, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 14/500 - Train Loss: 0.6705, Val Loss: 0.6689, Test Loss: 0.6688, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 15/500 - Train Loss: 0.6688, Val Loss: 0.6671, Test Loss: 0.6670, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 16/500 - Train Loss: 0.6670, Val Loss: 0.6654, Test Loss: 0.6653, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 17/500 - Train Loss: 0.6653, Val Loss: 0.6637, Test Loss: 0.6636, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 18/500 - Train Loss: 0.6635, Val Loss: 0.6619, Test Loss: 0.6618, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 19/500 - Train Loss: 0.6618, Val Loss: 0.6602, Test Loss: 0.6601, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 20/500 - Train Loss: 0.6601, Val Loss: 0.6585, Test Loss: 0.6584, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 21/500 - Train Loss: 0.6584, Val Loss: 0.6569, Test Loss: 0.6567, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 22/500 - Train Loss: 0.6567, Val Loss: 0.6552, Test Loss: 0.6550, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 23/500 - Train Loss: 0.6550, Val Loss: 0.6535, Test Loss: 0.6534, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 24/500 - Train Loss: 0.6533, Val Loss: 0.6518, Test Loss: 0.6517, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 25/500 - Train Loss: 0.6516, Val Loss: 0.6502, Test Loss: 0.6500, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 26/500 - Train Loss: 0.6499, Val Loss: 0.6485, Test Loss: 0.6484, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 27/500 - Train Loss: 0.6483, Val Loss: 0.6469, Test Loss: 0.6467, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 28/500 - Train Loss: 0.6466, Val Loss: 0.6453, Test Loss: 0.6451, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 29/500 - Train Loss: 0.6450, Val Loss: 0.6436, Test Loss: 0.6435, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 30/500 - Train Loss: 0.6433, Val Loss: 0.6420, Test Loss: 0.6418, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 31/500 - Train Loss: 0.6417, Val Loss: 0.6404, Test Loss: 0.6402, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 32/500 - Train Loss: 0.6401, Val Loss: 0.6388, Test Loss: 0.6386, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 33/500 - Train Loss: 0.6385, Val Loss: 0.6372, Test Loss: 0.6370, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 34/500 - Train Loss: 0.6369, Val Loss: 0.6357, Test Loss: 0.6354, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 35/500 - Train Loss: 0.6353, Val Loss: 0.6341, Test Loss: 0.6339, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 36/500 - Train Loss: 0.6337, Val Loss: 0.6325, Test Loss: 0.6323, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 37/500 - Train Loss: 0.6321, Val Loss: 0.6310, Test Loss: 0.6307, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 38/500 - Train Loss: 0.6306, Val Loss: 0.6294, Test Loss: 0.6292, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 39/500 - Train Loss: 0.6290, Val Loss: 0.6279, Test Loss: 0.6276, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 40/500 - Train Loss: 0.6275, Val Loss: 0.6264, Test Loss: 0.6261, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 41/500 - Train Loss: 0.6259, Val Loss: 0.6248, Test Loss: 0.6245, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 42/500 - Train Loss: 0.6244, Val Loss: 0.6233, Test Loss: 0.6230, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 43/500 - Train Loss: 0.6229, Val Loss: 0.6218, Test Loss: 0.6215, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 44/500 - Train Loss: 0.6213, Val Loss: 0.6203, Test Loss: 0.6200, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 45/500 - Train Loss: 0.6198, Val Loss: 0.6188, Test Loss: 0.6185, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 46/500 - Train Loss: 0.6183, Val Loss: 0.6173, Test Loss: 0.6170, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 47/500 - Train Loss: 0.6168, Val Loss: 0.6159, Test Loss: 0.6155, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 48/500 - Train Loss: 0.6153, Val Loss: 0.6144, Test Loss: 0.6141, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 49/500 - Train Loss: 0.6138, Val Loss: 0.6129, Test Loss: 0.6126, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 50/500 - Train Loss: 0.6124, Val Loss: 0.6115, Test Loss: 0.6111, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 51/500 - Train Loss: 0.6109, Val Loss: 0.6100, Test Loss: 0.6097, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 52/500 - Train Loss: 0.6094, Val Loss: 0.6086, Test Loss: 0.6082, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 53/500 - Train Loss: 0.6080, Val Loss: 0.6072, Test Loss: 0.6068, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 54/500 - Train Loss: 0.6066, Val Loss: 0.6057, Test Loss: 0.6054, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 55/500 - Train Loss: 0.6051, Val Loss: 0.6043, Test Loss: 0.6039, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 56/500 - Train Loss: 0.6037, Val Loss: 0.6029, Test Loss: 0.6025, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 57/500 - Train Loss: 0.6023, Val Loss: 0.6015, Test Loss: 0.6011, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 58/500 - Train Loss: 0.6009, Val Loss: 0.6001, Test Loss: 0.5997, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 59/500 - Train Loss: 0.5994, Val Loss: 0.5987, Test Loss: 0.5983, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 60/500 - Train Loss: 0.5980, Val Loss: 0.5973, Test Loss: 0.5969, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 61/500 - Train Loss: 0.5967, Val Loss: 0.5960, Test Loss: 0.5955, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 62/500 - Train Loss: 0.5953, Val Loss: 0.5946, Test Loss: 0.5942, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 63/500 - Train Loss: 0.5939, Val Loss: 0.5932, Test Loss: 0.5928, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 64/500 - Train Loss: 0.5925, Val Loss: 0.5919, Test Loss: 0.5914, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 65/500 - Train Loss: 0.5911, Val Loss: 0.5905, Test Loss: 0.5901, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 66/500 - Train Loss: 0.5898, Val Loss: 0.5892, Test Loss: 0.5887, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 67/500 - Train Loss: 0.5884, Val Loss: 0.5879, Test Loss: 0.5874, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 68/500 - Train Loss: 0.5871, Val Loss: 0.5865, Test Loss: 0.5861, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 69/500 - Train Loss: 0.5858, Val Loss: 0.5852, Test Loss: 0.5847, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 70/500 - Train Loss: 0.5844, Val Loss: 0.5839, Test Loss: 0.5834, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/500 - Train Loss: 0.5831, Val Loss: 0.5826, Test Loss: 0.5821, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 72/500 - Train Loss: 0.5818, Val Loss: 0.5813, Test Loss: 0.5808, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 73/500 - Train Loss: 0.5805, Val Loss: 0.5800, Test Loss: 0.5795, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 74/500 - Train Loss: 0.5792, Val Loss: 0.5787, Test Loss: 0.5782, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 75/500 - Train Loss: 0.5779, Val Loss: 0.5775, Test Loss: 0.5769, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 76/500 - Train Loss: 0.5766, Val Loss: 0.5762, Test Loss: 0.5756, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 77/500 - Train Loss: 0.5753, Val Loss: 0.5749, Test Loss: 0.5744, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 78/500 - Train Loss: 0.5740, Val Loss: 0.5737, Test Loss: 0.5731, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 79/500 - Train Loss: 0.5728, Val Loss: 0.5724, Test Loss: 0.5718, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 80/500 - Train Loss: 0.5715, Val Loss: 0.5712, Test Loss: 0.5706, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 81/500 - Train Loss: 0.5702, Val Loss: 0.5699, Test Loss: 0.5693, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 82/500 - Train Loss: 0.5690, Val Loss: 0.5687, Test Loss: 0.5681, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 83/500 - Train Loss: 0.5677, Val Loss: 0.5675, Test Loss: 0.5669, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 84/500 - Train Loss: 0.5665, Val Loss: 0.5662, Test Loss: 0.5656, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 85/500 - Train Loss: 0.5653, Val Loss: 0.5650, Test Loss: 0.5644, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 86/500 - Train Loss: 0.5640, Val Loss: 0.5638, Test Loss: 0.5632, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 87/500 - Train Loss: 0.5628, Val Loss: 0.5626, Test Loss: 0.5620, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 88/500 - Train Loss: 0.5616, Val Loss: 0.5614, Test Loss: 0.5608, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 89/500 - Train Loss: 0.5604, Val Loss: 0.5602, Test Loss: 0.5596, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 90/500 - Train Loss: 0.5592, Val Loss: 0.5590, Test Loss: 0.5584, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 91/500 - Train Loss: 0.5580, Val Loss: 0.5578, Test Loss: 0.5572, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 92/500 - Train Loss: 0.5568, Val Loss: 0.5567, Test Loss: 0.5560, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 93/500 - Train Loss: 0.5556, Val Loss: 0.5555, Test Loss: 0.5549, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 94/500 - Train Loss: 0.5544, Val Loss: 0.5543, Test Loss: 0.5537, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 95/500 - Train Loss: 0.5533, Val Loss: 0.5532, Test Loss: 0.5525, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 96/500 - Train Loss: 0.5521, Val Loss: 0.5520, Test Loss: 0.5514, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 97/500 - Train Loss: 0.5509, Val Loss: 0.5509, Test Loss: 0.5502, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 98/500 - Train Loss: 0.5498, Val Loss: 0.5498, Test Loss: 0.5491, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 99/500 - Train Loss: 0.5486, Val Loss: 0.5486, Test Loss: 0.5479, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 100/500 - Train Loss: 0.5475, Val Loss: 0.5475, Test Loss: 0.5468, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 101/500 - Train Loss: 0.5463, Val Loss: 0.5464, Test Loss: 0.5457, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 102/500 - Train Loss: 0.5452, Val Loss: 0.5453, Test Loss: 0.5446, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 103/500 - Train Loss: 0.5441, Val Loss: 0.5442, Test Loss: 0.5434, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 104/500 - Train Loss: 0.5430, Val Loss: 0.5431, Test Loss: 0.5423, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 105/500 - Train Loss: 0.5419, Val Loss: 0.5420, Test Loss: 0.5412, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 106/500 - Train Loss: 0.5407, Val Loss: 0.5409, Test Loss: 0.5401, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 107/500 - Train Loss: 0.5396, Val Loss: 0.5398, Test Loss: 0.5390, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 108/500 - Train Loss: 0.5385, Val Loss: 0.5387, Test Loss: 0.5379, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 109/500 - Train Loss: 0.5374, Val Loss: 0.5376, Test Loss: 0.5369, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 110/500 - Train Loss: 0.5364, Val Loss: 0.5365, Test Loss: 0.5358, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 111/500 - Train Loss: 0.5353, Val Loss: 0.5355, Test Loss: 0.5347, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 112/500 - Train Loss: 0.5342, Val Loss: 0.5344, Test Loss: 0.5336, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 113/500 - Train Loss: 0.5331, Val Loss: 0.5334, Test Loss: 0.5326, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 114/500 - Train Loss: 0.5321, Val Loss: 0.5323, Test Loss: 0.5315, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 115/500 - Train Loss: 0.5310, Val Loss: 0.5313, Test Loss: 0.5305, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 116/500 - Train Loss: 0.5299, Val Loss: 0.5302, Test Loss: 0.5294, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 117/500 - Train Loss: 0.5289, Val Loss: 0.5292, Test Loss: 0.5284, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 118/500 - Train Loss: 0.5278, Val Loss: 0.5282, Test Loss: 0.5273, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 119/500 - Train Loss: 0.5268, Val Loss: 0.5271, Test Loss: 0.5263, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 120/500 - Train Loss: 0.5258, Val Loss: 0.5261, Test Loss: 0.5253, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 121/500 - Train Loss: 0.5247, Val Loss: 0.5251, Test Loss: 0.5243, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 122/500 - Train Loss: 0.5237, Val Loss: 0.5241, Test Loss: 0.5233, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 123/500 - Train Loss: 0.5227, Val Loss: 0.5231, Test Loss: 0.5222, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 124/500 - Train Loss: 0.5217, Val Loss: 0.5221, Test Loss: 0.5212, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 125/500 - Train Loss: 0.5207, Val Loss: 0.5211, Test Loss: 0.5202, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 126/500 - Train Loss: 0.5197, Val Loss: 0.5201, Test Loss: 0.5192, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 127/500 - Train Loss: 0.5187, Val Loss: 0.5191, Test Loss: 0.5183, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 128/500 - Train Loss: 0.5177, Val Loss: 0.5181, Test Loss: 0.5173, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 129/500 - Train Loss: 0.5167, Val Loss: 0.5172, Test Loss: 0.5163, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 130/500 - Train Loss: 0.5157, Val Loss: 0.5162, Test Loss: 0.5153, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 131/500 - Train Loss: 0.5147, Val Loss: 0.5152, Test Loss: 0.5143, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 132/500 - Train Loss: 0.5137, Val Loss: 0.5143, Test Loss: 0.5134, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 133/500 - Train Loss: 0.5128, Val Loss: 0.5133, Test Loss: 0.5124, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 134/500 - Train Loss: 0.5118, Val Loss: 0.5124, Test Loss: 0.5115, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 135/500 - Train Loss: 0.5108, Val Loss: 0.5114, Test Loss: 0.5105, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 136/500 - Train Loss: 0.5099, Val Loss: 0.5105, Test Loss: 0.5095, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 137/500 - Train Loss: 0.5089, Val Loss: 0.5095, Test Loss: 0.5086, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 138/500 - Train Loss: 0.5080, Val Loss: 0.5086, Test Loss: 0.5077, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 139/500 - Train Loss: 0.5070, Val Loss: 0.5077, Test Loss: 0.5067, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 140/500 - Train Loss: 0.5061, Val Loss: 0.5067, Test Loss: 0.5058, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/500 - Train Loss: 0.5052, Val Loss: 0.5058, Test Loss: 0.5049, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 142/500 - Train Loss: 0.5042, Val Loss: 0.5049, Test Loss: 0.5040, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 143/500 - Train Loss: 0.5033, Val Loss: 0.5040, Test Loss: 0.5030, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 144/500 - Train Loss: 0.5024, Val Loss: 0.5031, Test Loss: 0.5021, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 145/500 - Train Loss: 0.5015, Val Loss: 0.5022, Test Loss: 0.5012, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 146/500 - Train Loss: 0.5006, Val Loss: 0.5013, Test Loss: 0.5003, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 147/500 - Train Loss: 0.4997, Val Loss: 0.5004, Test Loss: 0.4994, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 148/500 - Train Loss: 0.4988, Val Loss: 0.4995, Test Loss: 0.4985, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 149/500 - Train Loss: 0.4979, Val Loss: 0.4986, Test Loss: 0.4976, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 150/500 - Train Loss: 0.4970, Val Loss: 0.4977, Test Loss: 0.4967, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 151/500 - Train Loss: 0.4961, Val Loss: 0.4969, Test Loss: 0.4959, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 152/500 - Train Loss: 0.4952, Val Loss: 0.4960, Test Loss: 0.4950, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 153/500 - Train Loss: 0.4943, Val Loss: 0.4951, Test Loss: 0.4941, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 154/500 - Train Loss: 0.4934, Val Loss: 0.4943, Test Loss: 0.4932, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 155/500 - Train Loss: 0.4925, Val Loss: 0.4934, Test Loss: 0.4924, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 156/500 - Train Loss: 0.4917, Val Loss: 0.4925, Test Loss: 0.4915, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 157/500 - Train Loss: 0.4908, Val Loss: 0.4917, Test Loss: 0.4907, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 158/500 - Train Loss: 0.4900, Val Loss: 0.4908, Test Loss: 0.4898, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 159/500 - Train Loss: 0.4891, Val Loss: 0.4900, Test Loss: 0.4890, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 160/500 - Train Loss: 0.4882, Val Loss: 0.4892, Test Loss: 0.4881, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 161/500 - Train Loss: 0.4874, Val Loss: 0.4883, Test Loss: 0.4873, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 162/500 - Train Loss: 0.4866, Val Loss: 0.4875, Test Loss: 0.4864, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 163/500 - Train Loss: 0.4857, Val Loss: 0.4867, Test Loss: 0.4856, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 164/500 - Train Loss: 0.4849, Val Loss: 0.4859, Test Loss: 0.4848, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 165/500 - Train Loss: 0.4840, Val Loss: 0.4850, Test Loss: 0.4840, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 166/500 - Train Loss: 0.4832, Val Loss: 0.4842, Test Loss: 0.4831, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 167/500 - Train Loss: 0.4824, Val Loss: 0.4834, Test Loss: 0.4823, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 168/500 - Train Loss: 0.4816, Val Loss: 0.4826, Test Loss: 0.4815, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 169/500 - Train Loss: 0.4808, Val Loss: 0.4818, Test Loss: 0.4807, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 170/500 - Train Loss: 0.4799, Val Loss: 0.4810, Test Loss: 0.4799, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 171/500 - Train Loss: 0.4791, Val Loss: 0.4802, Test Loss: 0.4791, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 172/500 - Train Loss: 0.4783, Val Loss: 0.4794, Test Loss: 0.4783, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 173/500 - Train Loss: 0.4775, Val Loss: 0.4786, Test Loss: 0.4775, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 174/500 - Train Loss: 0.4767, Val Loss: 0.4778, Test Loss: 0.4767, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 175/500 - Train Loss: 0.4759, Val Loss: 0.4771, Test Loss: 0.4759, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 176/500 - Train Loss: 0.4751, Val Loss: 0.4763, Test Loss: 0.4751, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 177/500 - Train Loss: 0.4744, Val Loss: 0.4755, Test Loss: 0.4744, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 178/500 - Train Loss: 0.4736, Val Loss: 0.4747, Test Loss: 0.4736, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 179/500 - Train Loss: 0.4728, Val Loss: 0.4740, Test Loss: 0.4728, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 180/500 - Train Loss: 0.4720, Val Loss: 0.4732, Test Loss: 0.4721, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 181/500 - Train Loss: 0.4712, Val Loss: 0.4724, Test Loss: 0.4713, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 182/500 - Train Loss: 0.4705, Val Loss: 0.4717, Test Loss: 0.4705, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 183/500 - Train Loss: 0.4697, Val Loss: 0.4709, Test Loss: 0.4698, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 184/500 - Train Loss: 0.4690, Val Loss: 0.4702, Test Loss: 0.4690, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 185/500 - Train Loss: 0.4682, Val Loss: 0.4694, Test Loss: 0.4683, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 186/500 - Train Loss: 0.4674, Val Loss: 0.4687, Test Loss: 0.4675, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 187/500 - Train Loss: 0.4667, Val Loss: 0.4680, Test Loss: 0.4668, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 188/500 - Train Loss: 0.4659, Val Loss: 0.4672, Test Loss: 0.4660, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 189/500 - Train Loss: 0.4652, Val Loss: 0.4665, Test Loss: 0.4653, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 190/500 - Train Loss: 0.4645, Val Loss: 0.4658, Test Loss: 0.4646, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 191/500 - Train Loss: 0.4637, Val Loss: 0.4651, Test Loss: 0.4638, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 192/500 - Train Loss: 0.4630, Val Loss: 0.4643, Test Loss: 0.4631, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 193/500 - Train Loss: 0.4623, Val Loss: 0.4636, Test Loss: 0.4624, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 194/500 - Train Loss: 0.4615, Val Loss: 0.4629, Test Loss: 0.4617, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 195/500 - Train Loss: 0.4608, Val Loss: 0.4622, Test Loss: 0.4610, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 196/500 - Train Loss: 0.4601, Val Loss: 0.4615, Test Loss: 0.4603, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 197/500 - Train Loss: 0.4594, Val Loss: 0.4608, Test Loss: 0.4595, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 198/500 - Train Loss: 0.4587, Val Loss: 0.4601, Test Loss: 0.4588, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 199/500 - Train Loss: 0.4580, Val Loss: 0.4594, Test Loss: 0.4581, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 200/500 - Train Loss: 0.4573, Val Loss: 0.4587, Test Loss: 0.4574, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 201/500 - Train Loss: 0.4565, Val Loss: 0.4580, Test Loss: 0.4567, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 202/500 - Train Loss: 0.4558, Val Loss: 0.4573, Test Loss: 0.4560, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 203/500 - Train Loss: 0.4552, Val Loss: 0.4566, Test Loss: 0.4554, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 204/500 - Train Loss: 0.4545, Val Loss: 0.4559, Test Loss: 0.4547, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 205/500 - Train Loss: 0.4538, Val Loss: 0.4553, Test Loss: 0.4540, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 206/500 - Train Loss: 0.4531, Val Loss: 0.4546, Test Loss: 0.4533, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 207/500 - Train Loss: 0.4524, Val Loss: 0.4539, Test Loss: 0.4526, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 208/500 - Train Loss: 0.4517, Val Loss: 0.4532, Test Loss: 0.4520, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 209/500 - Train Loss: 0.4510, Val Loss: 0.4526, Test Loss: 0.4513, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 210/500 - Train Loss: 0.4504, Val Loss: 0.4519, Test Loss: 0.4506, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211/500 - Train Loss: 0.4497, Val Loss: 0.4513, Test Loss: 0.4500, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 212/500 - Train Loss: 0.4490, Val Loss: 0.4506, Test Loss: 0.4493, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 213/500 - Train Loss: 0.4484, Val Loss: 0.4499, Test Loss: 0.4486, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 214/500 - Train Loss: 0.4477, Val Loss: 0.4493, Test Loss: 0.4480, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 215/500 - Train Loss: 0.4470, Val Loss: 0.4487, Test Loss: 0.4473, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 216/500 - Train Loss: 0.4464, Val Loss: 0.4480, Test Loss: 0.4467, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 217/500 - Train Loss: 0.4457, Val Loss: 0.4474, Test Loss: 0.4460, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 218/500 - Train Loss: 0.4451, Val Loss: 0.4467, Test Loss: 0.4454, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 219/500 - Train Loss: 0.4444, Val Loss: 0.4461, Test Loss: 0.4447, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 220/500 - Train Loss: 0.4438, Val Loss: 0.4455, Test Loss: 0.4441, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 221/500 - Train Loss: 0.4431, Val Loss: 0.4448, Test Loss: 0.4435, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 222/500 - Train Loss: 0.4425, Val Loss: 0.4442, Test Loss: 0.4428, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 223/500 - Train Loss: 0.4419, Val Loss: 0.4436, Test Loss: 0.4422, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 224/500 - Train Loss: 0.4412, Val Loss: 0.4430, Test Loss: 0.4416, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 225/500 - Train Loss: 0.4406, Val Loss: 0.4423, Test Loss: 0.4410, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 226/500 - Train Loss: 0.4400, Val Loss: 0.4417, Test Loss: 0.4403, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 227/500 - Train Loss: 0.4394, Val Loss: 0.4411, Test Loss: 0.4397, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 228/500 - Train Loss: 0.4387, Val Loss: 0.4405, Test Loss: 0.4391, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 229/500 - Train Loss: 0.4381, Val Loss: 0.4399, Test Loss: 0.4385, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 230/500 - Train Loss: 0.4375, Val Loss: 0.4393, Test Loss: 0.4379, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 231/500 - Train Loss: 0.4369, Val Loss: 0.4387, Test Loss: 0.4373, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 232/500 - Train Loss: 0.4363, Val Loss: 0.4381, Test Loss: 0.4367, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 233/500 - Train Loss: 0.4357, Val Loss: 0.4375, Test Loss: 0.4361, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 234/500 - Train Loss: 0.4351, Val Loss: 0.4369, Test Loss: 0.4355, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 235/500 - Train Loss: 0.4345, Val Loss: 0.4363, Test Loss: 0.4349, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 236/500 - Train Loss: 0.4339, Val Loss: 0.4357, Test Loss: 0.4343, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 237/500 - Train Loss: 0.4333, Val Loss: 0.4351, Test Loss: 0.4337, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 238/500 - Train Loss: 0.4327, Val Loss: 0.4345, Test Loss: 0.4331, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 239/500 - Train Loss: 0.4321, Val Loss: 0.4340, Test Loss: 0.4325, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 240/500 - Train Loss: 0.4315, Val Loss: 0.4334, Test Loss: 0.4319, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 241/500 - Train Loss: 0.4309, Val Loss: 0.4328, Test Loss: 0.4314, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 242/500 - Train Loss: 0.4303, Val Loss: 0.4322, Test Loss: 0.4308, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 243/500 - Train Loss: 0.4297, Val Loss: 0.4317, Test Loss: 0.4302, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 244/500 - Train Loss: 0.4292, Val Loss: 0.4311, Test Loss: 0.4296, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 245/500 - Train Loss: 0.4286, Val Loss: 0.4305, Test Loss: 0.4291, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 246/500 - Train Loss: 0.4280, Val Loss: 0.4300, Test Loss: 0.4285, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 247/500 - Train Loss: 0.4274, Val Loss: 0.4294, Test Loss: 0.4279, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 248/500 - Train Loss: 0.4269, Val Loss: 0.4288, Test Loss: 0.4274, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 249/500 - Train Loss: 0.4263, Val Loss: 0.4283, Test Loss: 0.4268, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 250/500 - Train Loss: 0.4257, Val Loss: 0.4277, Test Loss: 0.4262, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 251/500 - Train Loss: 0.4252, Val Loss: 0.4272, Test Loss: 0.4257, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 252/500 - Train Loss: 0.4246, Val Loss: 0.4266, Test Loss: 0.4251, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 253/500 - Train Loss: 0.4241, Val Loss: 0.4261, Test Loss: 0.4246, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 254/500 - Train Loss: 0.4235, Val Loss: 0.4255, Test Loss: 0.4240, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 255/500 - Train Loss: 0.4230, Val Loss: 0.4250, Test Loss: 0.4235, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 256/500 - Train Loss: 0.4224, Val Loss: 0.4245, Test Loss: 0.4230, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 257/500 - Train Loss: 0.4219, Val Loss: 0.4239, Test Loss: 0.4224, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 258/500 - Train Loss: 0.4213, Val Loss: 0.4234, Test Loss: 0.4219, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 259/500 - Train Loss: 0.4208, Val Loss: 0.4229, Test Loss: 0.4213, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 260/500 - Train Loss: 0.4202, Val Loss: 0.4223, Test Loss: 0.4208, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 261/500 - Train Loss: 0.4197, Val Loss: 0.4218, Test Loss: 0.4203, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 262/500 - Train Loss: 0.4192, Val Loss: 0.4213, Test Loss: 0.4197, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 263/500 - Train Loss: 0.4186, Val Loss: 0.4208, Test Loss: 0.4192, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 264/500 - Train Loss: 0.4181, Val Loss: 0.4202, Test Loss: 0.4187, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 265/500 - Train Loss: 0.4176, Val Loss: 0.4197, Test Loss: 0.4182, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 266/500 - Train Loss: 0.4170, Val Loss: 0.4192, Test Loss: 0.4177, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 267/500 - Train Loss: 0.4165, Val Loss: 0.4187, Test Loss: 0.4171, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 268/500 - Train Loss: 0.4160, Val Loss: 0.4182, Test Loss: 0.4166, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 269/500 - Train Loss: 0.4155, Val Loss: 0.4177, Test Loss: 0.4161, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 270/500 - Train Loss: 0.4150, Val Loss: 0.4172, Test Loss: 0.4156, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 271/500 - Train Loss: 0.4145, Val Loss: 0.4167, Test Loss: 0.4151, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 272/500 - Train Loss: 0.4139, Val Loss: 0.4162, Test Loss: 0.4146, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 273/500 - Train Loss: 0.4134, Val Loss: 0.4157, Test Loss: 0.4141, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 274/500 - Train Loss: 0.4129, Val Loss: 0.4152, Test Loss: 0.4136, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 275/500 - Train Loss: 0.4124, Val Loss: 0.4147, Test Loss: 0.4131, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 276/500 - Train Loss: 0.4119, Val Loss: 0.4142, Test Loss: 0.4126, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 277/500 - Train Loss: 0.4114, Val Loss: 0.4137, Test Loss: 0.4121, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 278/500 - Train Loss: 0.4109, Val Loss: 0.4132, Test Loss: 0.4116, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 279/500 - Train Loss: 0.4104, Val Loss: 0.4127, Test Loss: 0.4111, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 280/500 - Train Loss: 0.4099, Val Loss: 0.4122, Test Loss: 0.4106, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/500 - Train Loss: 0.4094, Val Loss: 0.4117, Test Loss: 0.4101, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 282/500 - Train Loss: 0.4089, Val Loss: 0.4113, Test Loss: 0.4096, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 283/500 - Train Loss: 0.4084, Val Loss: 0.4108, Test Loss: 0.4092, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 284/500 - Train Loss: 0.4080, Val Loss: 0.4103, Test Loss: 0.4087, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 285/500 - Train Loss: 0.4075, Val Loss: 0.4098, Test Loss: 0.4082, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 286/500 - Train Loss: 0.4070, Val Loss: 0.4094, Test Loss: 0.4077, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 287/500 - Train Loss: 0.4065, Val Loss: 0.4089, Test Loss: 0.4072, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 288/500 - Train Loss: 0.4060, Val Loss: 0.4084, Test Loss: 0.4068, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 289/500 - Train Loss: 0.4056, Val Loss: 0.4079, Test Loss: 0.4063, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 290/500 - Train Loss: 0.4051, Val Loss: 0.4075, Test Loss: 0.4058, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 291/500 - Train Loss: 0.4046, Val Loss: 0.4070, Test Loss: 0.4054, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 292/500 - Train Loss: 0.4041, Val Loss: 0.4066, Test Loss: 0.4049, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 293/500 - Train Loss: 0.4037, Val Loss: 0.4061, Test Loss: 0.4044, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 294/500 - Train Loss: 0.4032, Val Loss: 0.4056, Test Loss: 0.4040, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 295/500 - Train Loss: 0.4027, Val Loss: 0.4052, Test Loss: 0.4035, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 296/500 - Train Loss: 0.4023, Val Loss: 0.4047, Test Loss: 0.4031, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 297/500 - Train Loss: 0.4018, Val Loss: 0.4043, Test Loss: 0.4026, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 298/500 - Train Loss: 0.4014, Val Loss: 0.4038, Test Loss: 0.4022, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 299/500 - Train Loss: 0.4009, Val Loss: 0.4034, Test Loss: 0.4017, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 300/500 - Train Loss: 0.4005, Val Loss: 0.4029, Test Loss: 0.4013, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 301/500 - Train Loss: 0.4000, Val Loss: 0.4025, Test Loss: 0.4008, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 302/500 - Train Loss: 0.3996, Val Loss: 0.4021, Test Loss: 0.4004, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 303/500 - Train Loss: 0.3991, Val Loss: 0.4016, Test Loss: 0.3999, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 304/500 - Train Loss: 0.3987, Val Loss: 0.4012, Test Loss: 0.3995, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 305/500 - Train Loss: 0.3982, Val Loss: 0.4007, Test Loss: 0.3990, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 306/500 - Train Loss: 0.3978, Val Loss: 0.4003, Test Loss: 0.3986, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 307/500 - Train Loss: 0.3973, Val Loss: 0.3999, Test Loss: 0.3982, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 308/500 - Train Loss: 0.3969, Val Loss: 0.3994, Test Loss: 0.3977, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 309/500 - Train Loss: 0.3965, Val Loss: 0.3990, Test Loss: 0.3973, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 310/500 - Train Loss: 0.3960, Val Loss: 0.3986, Test Loss: 0.3969, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 311/500 - Train Loss: 0.3956, Val Loss: 0.3982, Test Loss: 0.3964, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 312/500 - Train Loss: 0.3951, Val Loss: 0.3977, Test Loss: 0.3960, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 313/500 - Train Loss: 0.3947, Val Loss: 0.3973, Test Loss: 0.3956, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 314/500 - Train Loss: 0.3943, Val Loss: 0.3969, Test Loss: 0.3952, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 315/500 - Train Loss: 0.3939, Val Loss: 0.3965, Test Loss: 0.3947, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 316/500 - Train Loss: 0.3934, Val Loss: 0.3961, Test Loss: 0.3943, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 317/500 - Train Loss: 0.3930, Val Loss: 0.3956, Test Loss: 0.3939, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 318/500 - Train Loss: 0.3926, Val Loss: 0.3952, Test Loss: 0.3935, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 319/500 - Train Loss: 0.3922, Val Loss: 0.3948, Test Loss: 0.3931, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 320/500 - Train Loss: 0.3918, Val Loss: 0.3944, Test Loss: 0.3926, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 321/500 - Train Loss: 0.3913, Val Loss: 0.3940, Test Loss: 0.3922, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 322/500 - Train Loss: 0.3909, Val Loss: 0.3936, Test Loss: 0.3918, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 323/500 - Train Loss: 0.3905, Val Loss: 0.3932, Test Loss: 0.3914, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 324/500 - Train Loss: 0.3901, Val Loss: 0.3928, Test Loss: 0.3910, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 325/500 - Train Loss: 0.3897, Val Loss: 0.3924, Test Loss: 0.3906, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 326/500 - Train Loss: 0.3893, Val Loss: 0.3920, Test Loss: 0.3902, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 327/500 - Train Loss: 0.3889, Val Loss: 0.3916, Test Loss: 0.3898, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 328/500 - Train Loss: 0.3885, Val Loss: 0.3912, Test Loss: 0.3894, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 329/500 - Train Loss: 0.3881, Val Loss: 0.3908, Test Loss: 0.3890, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 330/500 - Train Loss: 0.3877, Val Loss: 0.3904, Test Loss: 0.3886, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 331/500 - Train Loss: 0.3873, Val Loss: 0.3900, Test Loss: 0.3882, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 332/500 - Train Loss: 0.3869, Val Loss: 0.3896, Test Loss: 0.3878, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 333/500 - Train Loss: 0.3865, Val Loss: 0.3892, Test Loss: 0.3874, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 334/500 - Train Loss: 0.3861, Val Loss: 0.3889, Test Loss: 0.3870, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 335/500 - Train Loss: 0.3857, Val Loss: 0.3885, Test Loss: 0.3867, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 336/500 - Train Loss: 0.3853, Val Loss: 0.3881, Test Loss: 0.3863, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 337/500 - Train Loss: 0.3849, Val Loss: 0.3877, Test Loss: 0.3859, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 338/500 - Train Loss: 0.3845, Val Loss: 0.3873, Test Loss: 0.3855, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 339/500 - Train Loss: 0.3841, Val Loss: 0.3869, Test Loss: 0.3851, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 340/500 - Train Loss: 0.3837, Val Loss: 0.3866, Test Loss: 0.3847, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 341/500 - Train Loss: 0.3834, Val Loss: 0.3862, Test Loss: 0.3844, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 342/500 - Train Loss: 0.3830, Val Loss: 0.3858, Test Loss: 0.3840, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 343/500 - Train Loss: 0.3826, Val Loss: 0.3854, Test Loss: 0.3836, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 344/500 - Train Loss: 0.3822, Val Loss: 0.3851, Test Loss: 0.3832, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 345/500 - Train Loss: 0.3818, Val Loss: 0.3847, Test Loss: 0.3829, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 346/500 - Train Loss: 0.3815, Val Loss: 0.3843, Test Loss: 0.3825, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 347/500 - Train Loss: 0.3811, Val Loss: 0.3840, Test Loss: 0.3821, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 348/500 - Train Loss: 0.3807, Val Loss: 0.3836, Test Loss: 0.3817, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 349/500 - Train Loss: 0.3803, Val Loss: 0.3832, Test Loss: 0.3814, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 350/500 - Train Loss: 0.3800, Val Loss: 0.3829, Test Loss: 0.3810, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351/500 - Train Loss: 0.3796, Val Loss: 0.3825, Test Loss: 0.3806, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 352/500 - Train Loss: 0.3792, Val Loss: 0.3822, Test Loss: 0.3803, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 353/500 - Train Loss: 0.3789, Val Loss: 0.3818, Test Loss: 0.3799, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 354/500 - Train Loss: 0.3785, Val Loss: 0.3814, Test Loss: 0.3796, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 355/500 - Train Loss: 0.3781, Val Loss: 0.3811, Test Loss: 0.3792, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 356/500 - Train Loss: 0.3778, Val Loss: 0.3807, Test Loss: 0.3788, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 357/500 - Train Loss: 0.3774, Val Loss: 0.3804, Test Loss: 0.3785, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 358/500 - Train Loss: 0.3771, Val Loss: 0.3800, Test Loss: 0.3781, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 359/500 - Train Loss: 0.3767, Val Loss: 0.3797, Test Loss: 0.3778, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 360/500 - Train Loss: 0.3764, Val Loss: 0.3793, Test Loss: 0.3774, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 361/500 - Train Loss: 0.3760, Val Loss: 0.3790, Test Loss: 0.3771, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 362/500 - Train Loss: 0.3756, Val Loss: 0.3786, Test Loss: 0.3767, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 363/500 - Train Loss: 0.3753, Val Loss: 0.3783, Test Loss: 0.3764, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 364/500 - Train Loss: 0.3749, Val Loss: 0.3780, Test Loss: 0.3760, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 365/500 - Train Loss: 0.3746, Val Loss: 0.3776, Test Loss: 0.3757, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 366/500 - Train Loss: 0.3742, Val Loss: 0.3773, Test Loss: 0.3754, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 367/500 - Train Loss: 0.3739, Val Loss: 0.3769, Test Loss: 0.3750, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 368/500 - Train Loss: 0.3736, Val Loss: 0.3766, Test Loss: 0.3747, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 369/500 - Train Loss: 0.3732, Val Loss: 0.3763, Test Loss: 0.3743, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 370/500 - Train Loss: 0.3729, Val Loss: 0.3759, Test Loss: 0.3740, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 371/500 - Train Loss: 0.3725, Val Loss: 0.3756, Test Loss: 0.3737, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 372/500 - Train Loss: 0.3722, Val Loss: 0.3753, Test Loss: 0.3733, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 373/500 - Train Loss: 0.3719, Val Loss: 0.3749, Test Loss: 0.3730, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 374/500 - Train Loss: 0.3715, Val Loss: 0.3746, Test Loss: 0.3727, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 375/500 - Train Loss: 0.3712, Val Loss: 0.3743, Test Loss: 0.3723, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 376/500 - Train Loss: 0.3709, Val Loss: 0.3740, Test Loss: 0.3720, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 377/500 - Train Loss: 0.3705, Val Loss: 0.3736, Test Loss: 0.3717, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 378/500 - Train Loss: 0.3702, Val Loss: 0.3733, Test Loss: 0.3713, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 379/500 - Train Loss: 0.3699, Val Loss: 0.3730, Test Loss: 0.3710, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 380/500 - Train Loss: 0.3695, Val Loss: 0.3727, Test Loss: 0.3707, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 381/500 - Train Loss: 0.3692, Val Loss: 0.3723, Test Loss: 0.3704, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 382/500 - Train Loss: 0.3689, Val Loss: 0.3720, Test Loss: 0.3700, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 383/500 - Train Loss: 0.3685, Val Loss: 0.3717, Test Loss: 0.3697, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 384/500 - Train Loss: 0.3682, Val Loss: 0.3714, Test Loss: 0.3694, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 385/500 - Train Loss: 0.3679, Val Loss: 0.3711, Test Loss: 0.3691, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 386/500 - Train Loss: 0.3676, Val Loss: 0.3708, Test Loss: 0.3688, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 387/500 - Train Loss: 0.3673, Val Loss: 0.3705, Test Loss: 0.3685, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 388/500 - Train Loss: 0.3669, Val Loss: 0.3701, Test Loss: 0.3681, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 389/500 - Train Loss: 0.3666, Val Loss: 0.3698, Test Loss: 0.3678, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 390/500 - Train Loss: 0.3663, Val Loss: 0.3695, Test Loss: 0.3675, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 391/500 - Train Loss: 0.3660, Val Loss: 0.3692, Test Loss: 0.3672, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 392/500 - Train Loss: 0.3657, Val Loss: 0.3689, Test Loss: 0.3669, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 393/500 - Train Loss: 0.3654, Val Loss: 0.3686, Test Loss: 0.3666, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 394/500 - Train Loss: 0.3651, Val Loss: 0.3683, Test Loss: 0.3663, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 395/500 - Train Loss: 0.3647, Val Loss: 0.3680, Test Loss: 0.3660, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 396/500 - Train Loss: 0.3644, Val Loss: 0.3677, Test Loss: 0.3657, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 397/500 - Train Loss: 0.3641, Val Loss: 0.3674, Test Loss: 0.3654, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 398/500 - Train Loss: 0.3638, Val Loss: 0.3671, Test Loss: 0.3651, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 399/500 - Train Loss: 0.3635, Val Loss: 0.3668, Test Loss: 0.3648, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 400/500 - Train Loss: 0.3632, Val Loss: 0.3665, Test Loss: 0.3645, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 401/500 - Train Loss: 0.3629, Val Loss: 0.3662, Test Loss: 0.3642, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 402/500 - Train Loss: 0.3626, Val Loss: 0.3659, Test Loss: 0.3639, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 403/500 - Train Loss: 0.3623, Val Loss: 0.3656, Test Loss: 0.3636, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 404/500 - Train Loss: 0.3620, Val Loss: 0.3653, Test Loss: 0.3633, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 405/500 - Train Loss: 0.3617, Val Loss: 0.3650, Test Loss: 0.3630, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 406/500 - Train Loss: 0.3614, Val Loss: 0.3647, Test Loss: 0.3627, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 407/500 - Train Loss: 0.3611, Val Loss: 0.3645, Test Loss: 0.3624, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 408/500 - Train Loss: 0.3608, Val Loss: 0.3642, Test Loss: 0.3621, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 409/500 - Train Loss: 0.3605, Val Loss: 0.3639, Test Loss: 0.3618, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 410/500 - Train Loss: 0.3602, Val Loss: 0.3636, Test Loss: 0.3615, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 411/500 - Train Loss: 0.3599, Val Loss: 0.3633, Test Loss: 0.3612, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 412/500 - Train Loss: 0.3597, Val Loss: 0.3630, Test Loss: 0.3609, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 413/500 - Train Loss: 0.3594, Val Loss: 0.3627, Test Loss: 0.3607, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 414/500 - Train Loss: 0.3591, Val Loss: 0.3625, Test Loss: 0.3604, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 415/500 - Train Loss: 0.3588, Val Loss: 0.3622, Test Loss: 0.3601, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 416/500 - Train Loss: 0.3585, Val Loss: 0.3619, Test Loss: 0.3598, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 417/500 - Train Loss: 0.3582, Val Loss: 0.3616, Test Loss: 0.3595, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 418/500 - Train Loss: 0.3579, Val Loss: 0.3613, Test Loss: 0.3592, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 419/500 - Train Loss: 0.3577, Val Loss: 0.3611, Test Loss: 0.3590, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 420/500 - Train Loss: 0.3574, Val Loss: 0.3608, Test Loss: 0.3587, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/500 - Train Loss: 0.3571, Val Loss: 0.3605, Test Loss: 0.3584, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 422/500 - Train Loss: 0.3568, Val Loss: 0.3602, Test Loss: 0.3581, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 423/500 - Train Loss: 0.3565, Val Loss: 0.3600, Test Loss: 0.3579, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 424/500 - Train Loss: 0.3563, Val Loss: 0.3597, Test Loss: 0.3576, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 425/500 - Train Loss: 0.3560, Val Loss: 0.3594, Test Loss: 0.3573, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 426/500 - Train Loss: 0.3557, Val Loss: 0.3592, Test Loss: 0.3570, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 427/500 - Train Loss: 0.3554, Val Loss: 0.3589, Test Loss: 0.3568, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 428/500 - Train Loss: 0.3552, Val Loss: 0.3586, Test Loss: 0.3565, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 429/500 - Train Loss: 0.3549, Val Loss: 0.3584, Test Loss: 0.3562, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 430/500 - Train Loss: 0.3546, Val Loss: 0.3581, Test Loss: 0.3560, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 431/500 - Train Loss: 0.3543, Val Loss: 0.3578, Test Loss: 0.3557, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 432/500 - Train Loss: 0.3541, Val Loss: 0.3576, Test Loss: 0.3554, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 433/500 - Train Loss: 0.3538, Val Loss: 0.3573, Test Loss: 0.3552, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 434/500 - Train Loss: 0.3535, Val Loss: 0.3570, Test Loss: 0.3549, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 435/500 - Train Loss: 0.3533, Val Loss: 0.3568, Test Loss: 0.3546, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 436/500 - Train Loss: 0.3530, Val Loss: 0.3565, Test Loss: 0.3544, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 437/500 - Train Loss: 0.3527, Val Loss: 0.3563, Test Loss: 0.3541, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 438/500 - Train Loss: 0.3525, Val Loss: 0.3560, Test Loss: 0.3539, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 439/500 - Train Loss: 0.3522, Val Loss: 0.3558, Test Loss: 0.3536, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 440/500 - Train Loss: 0.3519, Val Loss: 0.3555, Test Loss: 0.3533, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 441/500 - Train Loss: 0.3517, Val Loss: 0.3552, Test Loss: 0.3531, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 442/500 - Train Loss: 0.3514, Val Loss: 0.3550, Test Loss: 0.3528, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 443/500 - Train Loss: 0.3512, Val Loss: 0.3547, Test Loss: 0.3526, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 444/500 - Train Loss: 0.3509, Val Loss: 0.3545, Test Loss: 0.3523, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 445/500 - Train Loss: 0.3507, Val Loss: 0.3542, Test Loss: 0.3521, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 446/500 - Train Loss: 0.3504, Val Loss: 0.3540, Test Loss: 0.3518, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 447/500 - Train Loss: 0.3501, Val Loss: 0.3537, Test Loss: 0.3516, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 448/500 - Train Loss: 0.3499, Val Loss: 0.3535, Test Loss: 0.3513, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 449/500 - Train Loss: 0.3496, Val Loss: 0.3532, Test Loss: 0.3511, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 450/500 - Train Loss: 0.3494, Val Loss: 0.3530, Test Loss: 0.3508, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 451/500 - Train Loss: 0.3491, Val Loss: 0.3528, Test Loss: 0.3506, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 452/500 - Train Loss: 0.3489, Val Loss: 0.3525, Test Loss: 0.3503, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 453/500 - Train Loss: 0.3486, Val Loss: 0.3523, Test Loss: 0.3501, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 454/500 - Train Loss: 0.3484, Val Loss: 0.3520, Test Loss: 0.3498, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 455/500 - Train Loss: 0.3481, Val Loss: 0.3518, Test Loss: 0.3496, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 456/500 - Train Loss: 0.3479, Val Loss: 0.3515, Test Loss: 0.3493, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 457/500 - Train Loss: 0.3476, Val Loss: 0.3513, Test Loss: 0.3491, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 458/500 - Train Loss: 0.3474, Val Loss: 0.3511, Test Loss: 0.3489, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 459/500 - Train Loss: 0.3472, Val Loss: 0.3508, Test Loss: 0.3486, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 460/500 - Train Loss: 0.3469, Val Loss: 0.3506, Test Loss: 0.3484, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 461/500 - Train Loss: 0.3467, Val Loss: 0.3504, Test Loss: 0.3481, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 462/500 - Train Loss: 0.3464, Val Loss: 0.3501, Test Loss: 0.3479, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 463/500 - Train Loss: 0.3462, Val Loss: 0.3499, Test Loss: 0.3477, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 464/500 - Train Loss: 0.3459, Val Loss: 0.3496, Test Loss: 0.3474, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 465/500 - Train Loss: 0.3457, Val Loss: 0.3494, Test Loss: 0.3472, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 466/500 - Train Loss: 0.3455, Val Loss: 0.3492, Test Loss: 0.3470, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 467/500 - Train Loss: 0.3452, Val Loss: 0.3490, Test Loss: 0.3467, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 468/500 - Train Loss: 0.3450, Val Loss: 0.3487, Test Loss: 0.3465, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 469/500 - Train Loss: 0.3448, Val Loss: 0.3485, Test Loss: 0.3463, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 470/500 - Train Loss: 0.3445, Val Loss: 0.3483, Test Loss: 0.3460, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 471/500 - Train Loss: 0.3443, Val Loss: 0.3480, Test Loss: 0.3458, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 472/500 - Train Loss: 0.3441, Val Loss: 0.3478, Test Loss: 0.3456, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 473/500 - Train Loss: 0.3438, Val Loss: 0.3476, Test Loss: 0.3453, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 474/500 - Train Loss: 0.3436, Val Loss: 0.3474, Test Loss: 0.3451, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 475/500 - Train Loss: 0.3434, Val Loss: 0.3471, Test Loss: 0.3449, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 476/500 - Train Loss: 0.3431, Val Loss: 0.3469, Test Loss: 0.3446, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 477/500 - Train Loss: 0.3429, Val Loss: 0.3467, Test Loss: 0.3444, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 478/500 - Train Loss: 0.3427, Val Loss: 0.3465, Test Loss: 0.3442, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 479/500 - Train Loss: 0.3424, Val Loss: 0.3462, Test Loss: 0.3440, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 480/500 - Train Loss: 0.3422, Val Loss: 0.3460, Test Loss: 0.3438, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 481/500 - Train Loss: 0.3420, Val Loss: 0.3458, Test Loss: 0.3435, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 482/500 - Train Loss: 0.3418, Val Loss: 0.3456, Test Loss: 0.3433, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 483/500 - Train Loss: 0.3415, Val Loss: 0.3454, Test Loss: 0.3431, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 484/500 - Train Loss: 0.3413, Val Loss: 0.3452, Test Loss: 0.3429, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 485/500 - Train Loss: 0.3411, Val Loss: 0.3449, Test Loss: 0.3426, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 486/500 - Train Loss: 0.3409, Val Loss: 0.3447, Test Loss: 0.3424, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 487/500 - Train Loss: 0.3407, Val Loss: 0.3445, Test Loss: 0.3422, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 488/500 - Train Loss: 0.3404, Val Loss: 0.3443, Test Loss: 0.3420, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 489/500 - Train Loss: 0.3402, Val Loss: 0.3441, Test Loss: 0.3418, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 490/500 - Train Loss: 0.3400, Val Loss: 0.3439, Test Loss: 0.3416, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 491/500 - Train Loss: 0.3398, Val Loss: 0.3437, Test Loss: 0.3414, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 492/500 - Train Loss: 0.3396, Val Loss: 0.3434, Test Loss: 0.3411, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 493/500 - Train Loss: 0.3394, Val Loss: 0.3432, Test Loss: 0.3409, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 494/500 - Train Loss: 0.3391, Val Loss: 0.3430, Test Loss: 0.3407, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 495/500 - Train Loss: 0.3389, Val Loss: 0.3428, Test Loss: 0.3405, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 496/500 - Train Loss: 0.3387, Val Loss: 0.3426, Test Loss: 0.3403, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 497/500 - Train Loss: 0.3385, Val Loss: 0.3424, Test Loss: 0.3401, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 498/500 - Train Loss: 0.3383, Val Loss: 0.3422, Test Loss: 0.3399, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 499/500 - Train Loss: 0.3381, Val Loss: 0.3420, Test Loss: 0.3397, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 500/500 - Train Loss: 0.3379, Val Loss: 0.3418, Test Loss: 0.3395, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a custom logistic regression class\n",
    "class CustomLogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(CustomLogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "\n",
    "# Split the dataset into features (X) and labels (y)\n",
    "X = df['Review']\n",
    "y = df['Category']\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Vectorize the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train_tensor = Variable(torch.Tensor(X_train_tfidf.toarray()))\n",
    "y_train_tensor = Variable(torch.Tensor(y_train.values).view(-1, 1))\n",
    "X_val_tensor = Variable(torch.Tensor(X_val_tfidf.toarray()))\n",
    "y_val_tensor = Variable(torch.Tensor(y_val.values).view(-1, 1))\n",
    "X_test_tensor = Variable(torch.Tensor(X_test_tfidf.toarray()))\n",
    "y_test_tensor = Variable(torch.Tensor(y_test.values).view(-1, 1))\n",
    "\n",
    "# Initialize the custom logistic regression model\n",
    "input_size = X_train_tfidf.shape[1]\n",
    "model = CustomLogisticRegression(input_size)\n",
    "\n",
    "# Define the loss function (you can replace this with your custom loss function)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 500\n",
    "\n",
    "# Lists to store training, validation, and test loss, accuracy for each epoch\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Training loop for multiple epochs\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Evaluate on training set\n",
    "    with torch.no_grad():\n",
    "        train_predictions = (outputs > 0.5).float()\n",
    "        train_accuracy = accuracy_score(y_train_tensor.numpy(), train_predictions.numpy())\n",
    "        train_losses.append(loss.item())\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        val_loss = criterion(val_outputs, y_val_tensor)\n",
    "        val_predictions = (val_outputs > 0.5).float()\n",
    "        val_accuracy = accuracy_score(y_val_tensor.numpy(), val_predictions.numpy())\n",
    "        val_losses.append(val_loss.item())\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test_tensor)\n",
    "        test_loss = criterion(test_outputs, y_test_tensor)\n",
    "        test_predictions = (test_outputs > 0.5).float()\n",
    "        test_accuracy = accuracy_score(y_test_tensor.numpy(), test_predictions.numpy())\n",
    "        test_losses.append(test_loss.item())\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} - \"\n",
    "          f\"Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, Test Loss: {test_loss.item():.4f}, \"\n",
    "          f\"Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}, Test Acc: {test_accuracy:.4f}\")\n",
    "\n",
    "# Plot training, validation, and test loss\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "plt.plot(range(1, num_epochs + 1), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('Log Reg(NN-BCEloss): epoch_vs_loss.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot training, validation, and test accuracy\n",
    "plt.plot(range(1, num_epochs + 1), train_accuracies, label='Training Accuracy')\n",
    "plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy')\n",
    "plt.plot(range(1, num_epochs + 1), test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('Log Reg(NN-BCEloss): epoch_vs_accuracy.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9805229c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 - Train Loss: 0.5017, Val Loss: 0.5012, Test Loss: 0.5013, Train Acc: 0.1186, Val Acc: 0.1871, Test Acc: 0.1792\n",
      "Epoch 2/500 - Train Loss: 0.5013, Val Loss: 0.5008, Test Loss: 0.5008, Train Acc: 0.1828, Val Acc: 0.2767, Test Acc: 0.2763\n",
      "Epoch 3/500 - Train Loss: 0.5008, Val Loss: 0.5003, Test Loss: 0.5003, Train Acc: 0.2784, Val Acc: 0.4082, Test Acc: 0.4007\n",
      "Epoch 4/500 - Train Loss: 0.5003, Val Loss: 0.4998, Test Loss: 0.4999, Train Acc: 0.4058, Val Acc: 0.5560, Test Acc: 0.5543\n",
      "Epoch 5/500 - Train Loss: 0.4998, Val Loss: 0.4994, Test Loss: 0.4994, Train Acc: 0.5545, Val Acc: 0.6880, Test Acc: 0.6849\n",
      "Epoch 6/500 - Train Loss: 0.4994, Val Loss: 0.4989, Test Loss: 0.4989, Train Acc: 0.6874, Val Acc: 0.7873, Test Acc: 0.7855\n",
      "Epoch 7/500 - Train Loss: 0.4989, Val Loss: 0.4984, Test Loss: 0.4984, Train Acc: 0.7907, Val Acc: 0.8548, Test Acc: 0.8557\n",
      "Epoch 8/500 - Train Loss: 0.4984, Val Loss: 0.4980, Test Loss: 0.4980, Train Acc: 0.8628, Val Acc: 0.8950, Test Acc: 0.8985\n",
      "Epoch 9/500 - Train Loss: 0.4980, Val Loss: 0.4975, Test Loss: 0.4975, Train Acc: 0.9004, Val Acc: 0.9144, Test Acc: 0.9179\n",
      "Epoch 10/500 - Train Loss: 0.4975, Val Loss: 0.4970, Test Loss: 0.4970, Train Acc: 0.9176, Val Acc: 0.9210, Test Acc: 0.9219\n",
      "Epoch 11/500 - Train Loss: 0.4970, Val Loss: 0.4966, Test Loss: 0.4966, Train Acc: 0.9241, Val Acc: 0.9219, Test Acc: 0.9241\n",
      "Epoch 12/500 - Train Loss: 0.4965, Val Loss: 0.4961, Test Loss: 0.4961, Train Acc: 0.9258, Val Acc: 0.9228, Test Acc: 0.9241\n",
      "Epoch 13/500 - Train Loss: 0.4961, Val Loss: 0.4956, Test Loss: 0.4956, Train Acc: 0.9259, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 14/500 - Train Loss: 0.4956, Val Loss: 0.4952, Test Loss: 0.4952, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 15/500 - Train Loss: 0.4951, Val Loss: 0.4947, Test Loss: 0.4947, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 16/500 - Train Loss: 0.4947, Val Loss: 0.4942, Test Loss: 0.4942, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 17/500 - Train Loss: 0.4942, Val Loss: 0.4938, Test Loss: 0.4937, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 18/500 - Train Loss: 0.4937, Val Loss: 0.4933, Test Loss: 0.4933, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 19/500 - Train Loss: 0.4932, Val Loss: 0.4928, Test Loss: 0.4928, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 20/500 - Train Loss: 0.4928, Val Loss: 0.4924, Test Loss: 0.4923, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 21/500 - Train Loss: 0.4923, Val Loss: 0.4919, Test Loss: 0.4919, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 22/500 - Train Loss: 0.4918, Val Loss: 0.4914, Test Loss: 0.4914, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 23/500 - Train Loss: 0.4914, Val Loss: 0.4909, Test Loss: 0.4909, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 24/500 - Train Loss: 0.4909, Val Loss: 0.4905, Test Loss: 0.4905, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 25/500 - Train Loss: 0.4904, Val Loss: 0.4900, Test Loss: 0.4900, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 26/500 - Train Loss: 0.4899, Val Loss: 0.4895, Test Loss: 0.4895, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 27/500 - Train Loss: 0.4895, Val Loss: 0.4891, Test Loss: 0.4891, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 28/500 - Train Loss: 0.4890, Val Loss: 0.4886, Test Loss: 0.4886, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 29/500 - Train Loss: 0.4885, Val Loss: 0.4881, Test Loss: 0.4881, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 30/500 - Train Loss: 0.4881, Val Loss: 0.4877, Test Loss: 0.4876, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 31/500 - Train Loss: 0.4876, Val Loss: 0.4872, Test Loss: 0.4872, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 32/500 - Train Loss: 0.4871, Val Loss: 0.4867, Test Loss: 0.4867, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 33/500 - Train Loss: 0.4867, Val Loss: 0.4863, Test Loss: 0.4862, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 34/500 - Train Loss: 0.4862, Val Loss: 0.4858, Test Loss: 0.4858, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 35/500 - Train Loss: 0.4857, Val Loss: 0.4853, Test Loss: 0.4853, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 36/500 - Train Loss: 0.4852, Val Loss: 0.4849, Test Loss: 0.4848, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 37/500 - Train Loss: 0.4848, Val Loss: 0.4844, Test Loss: 0.4844, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 38/500 - Train Loss: 0.4843, Val Loss: 0.4839, Test Loss: 0.4839, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 39/500 - Train Loss: 0.4838, Val Loss: 0.4835, Test Loss: 0.4834, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 40/500 - Train Loss: 0.4834, Val Loss: 0.4830, Test Loss: 0.4830, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 41/500 - Train Loss: 0.4829, Val Loss: 0.4825, Test Loss: 0.4825, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 42/500 - Train Loss: 0.4824, Val Loss: 0.4821, Test Loss: 0.4820, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 43/500 - Train Loss: 0.4820, Val Loss: 0.4816, Test Loss: 0.4816, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 44/500 - Train Loss: 0.4815, Val Loss: 0.4811, Test Loss: 0.4811, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 45/500 - Train Loss: 0.4810, Val Loss: 0.4807, Test Loss: 0.4806, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 46/500 - Train Loss: 0.4805, Val Loss: 0.4802, Test Loss: 0.4801, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 47/500 - Train Loss: 0.4801, Val Loss: 0.4797, Test Loss: 0.4797, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 48/500 - Train Loss: 0.4796, Val Loss: 0.4793, Test Loss: 0.4792, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 49/500 - Train Loss: 0.4791, Val Loss: 0.4788, Test Loss: 0.4787, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 50/500 - Train Loss: 0.4787, Val Loss: 0.4783, Test Loss: 0.4783, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 51/500 - Train Loss: 0.4782, Val Loss: 0.4779, Test Loss: 0.4778, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 52/500 - Train Loss: 0.4777, Val Loss: 0.4774, Test Loss: 0.4773, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 53/500 - Train Loss: 0.4773, Val Loss: 0.4770, Test Loss: 0.4769, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 54/500 - Train Loss: 0.4768, Val Loss: 0.4765, Test Loss: 0.4764, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 55/500 - Train Loss: 0.4763, Val Loss: 0.4760, Test Loss: 0.4759, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 56/500 - Train Loss: 0.4759, Val Loss: 0.4756, Test Loss: 0.4755, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 57/500 - Train Loss: 0.4754, Val Loss: 0.4751, Test Loss: 0.4750, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 58/500 - Train Loss: 0.4749, Val Loss: 0.4746, Test Loss: 0.4745, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 59/500 - Train Loss: 0.4745, Val Loss: 0.4742, Test Loss: 0.4741, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 60/500 - Train Loss: 0.4740, Val Loss: 0.4737, Test Loss: 0.4736, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 61/500 - Train Loss: 0.4735, Val Loss: 0.4732, Test Loss: 0.4731, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 62/500 - Train Loss: 0.4730, Val Loss: 0.4728, Test Loss: 0.4727, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 63/500 - Train Loss: 0.4726, Val Loss: 0.4723, Test Loss: 0.4722, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 64/500 - Train Loss: 0.4721, Val Loss: 0.4718, Test Loss: 0.4717, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 65/500 - Train Loss: 0.4716, Val Loss: 0.4714, Test Loss: 0.4713, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 66/500 - Train Loss: 0.4712, Val Loss: 0.4709, Test Loss: 0.4708, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 67/500 - Train Loss: 0.4707, Val Loss: 0.4705, Test Loss: 0.4703, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 68/500 - Train Loss: 0.4702, Val Loss: 0.4700, Test Loss: 0.4699, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 69/500 - Train Loss: 0.4698, Val Loss: 0.4695, Test Loss: 0.4694, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 70/500 - Train Loss: 0.4693, Val Loss: 0.4691, Test Loss: 0.4689, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/500 - Train Loss: 0.4688, Val Loss: 0.4686, Test Loss: 0.4685, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 72/500 - Train Loss: 0.4684, Val Loss: 0.4681, Test Loss: 0.4680, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 73/500 - Train Loss: 0.4679, Val Loss: 0.4677, Test Loss: 0.4676, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 74/500 - Train Loss: 0.4674, Val Loss: 0.4672, Test Loss: 0.4671, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 75/500 - Train Loss: 0.4670, Val Loss: 0.4668, Test Loss: 0.4666, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 76/500 - Train Loss: 0.4665, Val Loss: 0.4663, Test Loss: 0.4662, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 77/500 - Train Loss: 0.4660, Val Loss: 0.4658, Test Loss: 0.4657, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 78/500 - Train Loss: 0.4656, Val Loss: 0.4654, Test Loss: 0.4652, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 79/500 - Train Loss: 0.4651, Val Loss: 0.4649, Test Loss: 0.4648, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 80/500 - Train Loss: 0.4647, Val Loss: 0.4644, Test Loss: 0.4643, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 81/500 - Train Loss: 0.4642, Val Loss: 0.4640, Test Loss: 0.4638, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 82/500 - Train Loss: 0.4637, Val Loss: 0.4635, Test Loss: 0.4634, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 83/500 - Train Loss: 0.4633, Val Loss: 0.4631, Test Loss: 0.4629, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 84/500 - Train Loss: 0.4628, Val Loss: 0.4626, Test Loss: 0.4625, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 85/500 - Train Loss: 0.4623, Val Loss: 0.4621, Test Loss: 0.4620, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 86/500 - Train Loss: 0.4619, Val Loss: 0.4617, Test Loss: 0.4615, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 87/500 - Train Loss: 0.4614, Val Loss: 0.4612, Test Loss: 0.4611, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 88/500 - Train Loss: 0.4609, Val Loss: 0.4608, Test Loss: 0.4606, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 89/500 - Train Loss: 0.4605, Val Loss: 0.4603, Test Loss: 0.4601, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 90/500 - Train Loss: 0.4600, Val Loss: 0.4598, Test Loss: 0.4597, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 91/500 - Train Loss: 0.4596, Val Loss: 0.4594, Test Loss: 0.4592, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 92/500 - Train Loss: 0.4591, Val Loss: 0.4589, Test Loss: 0.4588, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 93/500 - Train Loss: 0.4586, Val Loss: 0.4585, Test Loss: 0.4583, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 94/500 - Train Loss: 0.4582, Val Loss: 0.4580, Test Loss: 0.4578, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 95/500 - Train Loss: 0.4577, Val Loss: 0.4575, Test Loss: 0.4574, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 96/500 - Train Loss: 0.4572, Val Loss: 0.4571, Test Loss: 0.4569, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 97/500 - Train Loss: 0.4568, Val Loss: 0.4566, Test Loss: 0.4565, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 98/500 - Train Loss: 0.4563, Val Loss: 0.4562, Test Loss: 0.4560, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 99/500 - Train Loss: 0.4559, Val Loss: 0.4557, Test Loss: 0.4555, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 100/500 - Train Loss: 0.4554, Val Loss: 0.4553, Test Loss: 0.4551, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 101/500 - Train Loss: 0.4549, Val Loss: 0.4548, Test Loss: 0.4546, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 102/500 - Train Loss: 0.4545, Val Loss: 0.4543, Test Loss: 0.4542, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 103/500 - Train Loss: 0.4540, Val Loss: 0.4539, Test Loss: 0.4537, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 104/500 - Train Loss: 0.4536, Val Loss: 0.4534, Test Loss: 0.4532, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 105/500 - Train Loss: 0.4531, Val Loss: 0.4530, Test Loss: 0.4528, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 106/500 - Train Loss: 0.4526, Val Loss: 0.4525, Test Loss: 0.4523, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 107/500 - Train Loss: 0.4522, Val Loss: 0.4521, Test Loss: 0.4519, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 108/500 - Train Loss: 0.4517, Val Loss: 0.4516, Test Loss: 0.4514, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 109/500 - Train Loss: 0.4513, Val Loss: 0.4511, Test Loss: 0.4509, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 110/500 - Train Loss: 0.4508, Val Loss: 0.4507, Test Loss: 0.4505, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 111/500 - Train Loss: 0.4503, Val Loss: 0.4502, Test Loss: 0.4500, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 112/500 - Train Loss: 0.4499, Val Loss: 0.4498, Test Loss: 0.4496, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 113/500 - Train Loss: 0.4494, Val Loss: 0.4493, Test Loss: 0.4491, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 114/500 - Train Loss: 0.4490, Val Loss: 0.4489, Test Loss: 0.4487, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 115/500 - Train Loss: 0.4485, Val Loss: 0.4484, Test Loss: 0.4482, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 116/500 - Train Loss: 0.4480, Val Loss: 0.4480, Test Loss: 0.4477, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 117/500 - Train Loss: 0.4476, Val Loss: 0.4475, Test Loss: 0.4473, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 118/500 - Train Loss: 0.4471, Val Loss: 0.4471, Test Loss: 0.4468, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 119/500 - Train Loss: 0.4467, Val Loss: 0.4466, Test Loss: 0.4464, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 120/500 - Train Loss: 0.4462, Val Loss: 0.4461, Test Loss: 0.4459, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 121/500 - Train Loss: 0.4458, Val Loss: 0.4457, Test Loss: 0.4455, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 122/500 - Train Loss: 0.4453, Val Loss: 0.4452, Test Loss: 0.4450, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 123/500 - Train Loss: 0.4448, Val Loss: 0.4448, Test Loss: 0.4446, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 124/500 - Train Loss: 0.4444, Val Loss: 0.4443, Test Loss: 0.4441, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 125/500 - Train Loss: 0.4439, Val Loss: 0.4439, Test Loss: 0.4437, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 126/500 - Train Loss: 0.4435, Val Loss: 0.4434, Test Loss: 0.4432, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 127/500 - Train Loss: 0.4430, Val Loss: 0.4430, Test Loss: 0.4427, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 128/500 - Train Loss: 0.4426, Val Loss: 0.4425, Test Loss: 0.4423, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 129/500 - Train Loss: 0.4421, Val Loss: 0.4421, Test Loss: 0.4418, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 130/500 - Train Loss: 0.4417, Val Loss: 0.4416, Test Loss: 0.4414, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 131/500 - Train Loss: 0.4412, Val Loss: 0.4412, Test Loss: 0.4409, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 132/500 - Train Loss: 0.4408, Val Loss: 0.4407, Test Loss: 0.4405, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 133/500 - Train Loss: 0.4403, Val Loss: 0.4403, Test Loss: 0.4400, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 134/500 - Train Loss: 0.4399, Val Loss: 0.4398, Test Loss: 0.4396, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 135/500 - Train Loss: 0.4394, Val Loss: 0.4394, Test Loss: 0.4391, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 136/500 - Train Loss: 0.4389, Val Loss: 0.4389, Test Loss: 0.4387, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/500 - Train Loss: 0.4385, Val Loss: 0.4385, Test Loss: 0.4382, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 138/500 - Train Loss: 0.4380, Val Loss: 0.4380, Test Loss: 0.4378, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 139/500 - Train Loss: 0.4376, Val Loss: 0.4376, Test Loss: 0.4373, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 140/500 - Train Loss: 0.4371, Val Loss: 0.4371, Test Loss: 0.4369, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 141/500 - Train Loss: 0.4367, Val Loss: 0.4367, Test Loss: 0.4364, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 142/500 - Train Loss: 0.4362, Val Loss: 0.4362, Test Loss: 0.4360, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 143/500 - Train Loss: 0.4358, Val Loss: 0.4358, Test Loss: 0.4355, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 144/500 - Train Loss: 0.4353, Val Loss: 0.4354, Test Loss: 0.4351, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 145/500 - Train Loss: 0.4349, Val Loss: 0.4349, Test Loss: 0.4346, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 146/500 - Train Loss: 0.4344, Val Loss: 0.4345, Test Loss: 0.4342, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 147/500 - Train Loss: 0.4340, Val Loss: 0.4340, Test Loss: 0.4337, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 148/500 - Train Loss: 0.4335, Val Loss: 0.4336, Test Loss: 0.4333, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 149/500 - Train Loss: 0.4331, Val Loss: 0.4331, Test Loss: 0.4328, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 150/500 - Train Loss: 0.4326, Val Loss: 0.4327, Test Loss: 0.4324, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 151/500 - Train Loss: 0.4322, Val Loss: 0.4322, Test Loss: 0.4320, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 152/500 - Train Loss: 0.4317, Val Loss: 0.4318, Test Loss: 0.4315, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 153/500 - Train Loss: 0.4313, Val Loss: 0.4313, Test Loss: 0.4311, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 154/500 - Train Loss: 0.4309, Val Loss: 0.4309, Test Loss: 0.4306, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 155/500 - Train Loss: 0.4304, Val Loss: 0.4305, Test Loss: 0.4302, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 156/500 - Train Loss: 0.4300, Val Loss: 0.4300, Test Loss: 0.4297, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 157/500 - Train Loss: 0.4295, Val Loss: 0.4296, Test Loss: 0.4293, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 158/500 - Train Loss: 0.4291, Val Loss: 0.4291, Test Loss: 0.4288, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 159/500 - Train Loss: 0.4286, Val Loss: 0.4287, Test Loss: 0.4284, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 160/500 - Train Loss: 0.4282, Val Loss: 0.4282, Test Loss: 0.4280, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 161/500 - Train Loss: 0.4277, Val Loss: 0.4278, Test Loss: 0.4275, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 162/500 - Train Loss: 0.4273, Val Loss: 0.4274, Test Loss: 0.4271, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 163/500 - Train Loss: 0.4268, Val Loss: 0.4269, Test Loss: 0.4266, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 164/500 - Train Loss: 0.4264, Val Loss: 0.4265, Test Loss: 0.4262, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 165/500 - Train Loss: 0.4260, Val Loss: 0.4260, Test Loss: 0.4257, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 166/500 - Train Loss: 0.4255, Val Loss: 0.4256, Test Loss: 0.4253, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 167/500 - Train Loss: 0.4251, Val Loss: 0.4252, Test Loss: 0.4249, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 168/500 - Train Loss: 0.4246, Val Loss: 0.4247, Test Loss: 0.4244, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 169/500 - Train Loss: 0.4242, Val Loss: 0.4243, Test Loss: 0.4240, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 170/500 - Train Loss: 0.4237, Val Loss: 0.4239, Test Loss: 0.4235, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 171/500 - Train Loss: 0.4233, Val Loss: 0.4234, Test Loss: 0.4231, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 172/500 - Train Loss: 0.4229, Val Loss: 0.4230, Test Loss: 0.4227, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 173/500 - Train Loss: 0.4224, Val Loss: 0.4225, Test Loss: 0.4222, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 174/500 - Train Loss: 0.4220, Val Loss: 0.4221, Test Loss: 0.4218, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 175/500 - Train Loss: 0.4215, Val Loss: 0.4217, Test Loss: 0.4213, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 176/500 - Train Loss: 0.4211, Val Loss: 0.4212, Test Loss: 0.4209, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 177/500 - Train Loss: 0.4207, Val Loss: 0.4208, Test Loss: 0.4205, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 178/500 - Train Loss: 0.4202, Val Loss: 0.4204, Test Loss: 0.4200, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 179/500 - Train Loss: 0.4198, Val Loss: 0.4199, Test Loss: 0.4196, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 180/500 - Train Loss: 0.4193, Val Loss: 0.4195, Test Loss: 0.4192, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 181/500 - Train Loss: 0.4189, Val Loss: 0.4191, Test Loss: 0.4187, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 182/500 - Train Loss: 0.4185, Val Loss: 0.4186, Test Loss: 0.4183, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 183/500 - Train Loss: 0.4180, Val Loss: 0.4182, Test Loss: 0.4178, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 184/500 - Train Loss: 0.4176, Val Loss: 0.4178, Test Loss: 0.4174, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 185/500 - Train Loss: 0.4172, Val Loss: 0.4173, Test Loss: 0.4170, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 186/500 - Train Loss: 0.4167, Val Loss: 0.4169, Test Loss: 0.4165, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 187/500 - Train Loss: 0.4163, Val Loss: 0.4165, Test Loss: 0.4161, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 188/500 - Train Loss: 0.4159, Val Loss: 0.4160, Test Loss: 0.4157, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 189/500 - Train Loss: 0.4154, Val Loss: 0.4156, Test Loss: 0.4152, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 190/500 - Train Loss: 0.4150, Val Loss: 0.4152, Test Loss: 0.4148, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 191/500 - Train Loss: 0.4145, Val Loss: 0.4147, Test Loss: 0.4144, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 192/500 - Train Loss: 0.4141, Val Loss: 0.4143, Test Loss: 0.4139, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 193/500 - Train Loss: 0.4137, Val Loss: 0.4139, Test Loss: 0.4135, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 194/500 - Train Loss: 0.4132, Val Loss: 0.4134, Test Loss: 0.4131, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 195/500 - Train Loss: 0.4128, Val Loss: 0.4130, Test Loss: 0.4126, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 196/500 - Train Loss: 0.4124, Val Loss: 0.4126, Test Loss: 0.4122, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 197/500 - Train Loss: 0.4119, Val Loss: 0.4121, Test Loss: 0.4118, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 198/500 - Train Loss: 0.4115, Val Loss: 0.4117, Test Loss: 0.4114, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 199/500 - Train Loss: 0.4111, Val Loss: 0.4113, Test Loss: 0.4109, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 200/500 - Train Loss: 0.4107, Val Loss: 0.4109, Test Loss: 0.4105, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 201/500 - Train Loss: 0.4102, Val Loss: 0.4104, Test Loss: 0.4101, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 202/500 - Train Loss: 0.4098, Val Loss: 0.4100, Test Loss: 0.4096, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 203/500 - Train Loss: 0.4094, Val Loss: 0.4096, Test Loss: 0.4092, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 204/500 - Train Loss: 0.4089, Val Loss: 0.4092, Test Loss: 0.4088, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205/500 - Train Loss: 0.4085, Val Loss: 0.4087, Test Loss: 0.4084, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 206/500 - Train Loss: 0.4081, Val Loss: 0.4083, Test Loss: 0.4079, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 207/500 - Train Loss: 0.4076, Val Loss: 0.4079, Test Loss: 0.4075, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 208/500 - Train Loss: 0.4072, Val Loss: 0.4075, Test Loss: 0.4071, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 209/500 - Train Loss: 0.4068, Val Loss: 0.4070, Test Loss: 0.4066, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 210/500 - Train Loss: 0.4064, Val Loss: 0.4066, Test Loss: 0.4062, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 211/500 - Train Loss: 0.4059, Val Loss: 0.4062, Test Loss: 0.4058, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 212/500 - Train Loss: 0.4055, Val Loss: 0.4058, Test Loss: 0.4054, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 213/500 - Train Loss: 0.4051, Val Loss: 0.4053, Test Loss: 0.4049, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 214/500 - Train Loss: 0.4047, Val Loss: 0.4049, Test Loss: 0.4045, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 215/500 - Train Loss: 0.4042, Val Loss: 0.4045, Test Loss: 0.4041, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 216/500 - Train Loss: 0.4038, Val Loss: 0.4041, Test Loss: 0.4037, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 217/500 - Train Loss: 0.4034, Val Loss: 0.4037, Test Loss: 0.4033, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 218/500 - Train Loss: 0.4030, Val Loss: 0.4032, Test Loss: 0.4028, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 219/500 - Train Loss: 0.4025, Val Loss: 0.4028, Test Loss: 0.4024, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 220/500 - Train Loss: 0.4021, Val Loss: 0.4024, Test Loss: 0.4020, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 221/500 - Train Loss: 0.4017, Val Loss: 0.4020, Test Loss: 0.4016, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 222/500 - Train Loss: 0.4013, Val Loss: 0.4016, Test Loss: 0.4011, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 223/500 - Train Loss: 0.4008, Val Loss: 0.4011, Test Loss: 0.4007, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 224/500 - Train Loss: 0.4004, Val Loss: 0.4007, Test Loss: 0.4003, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 225/500 - Train Loss: 0.4000, Val Loss: 0.4003, Test Loss: 0.3999, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 226/500 - Train Loss: 0.3996, Val Loss: 0.3999, Test Loss: 0.3995, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 227/500 - Train Loss: 0.3992, Val Loss: 0.3995, Test Loss: 0.3990, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 228/500 - Train Loss: 0.3987, Val Loss: 0.3991, Test Loss: 0.3986, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 229/500 - Train Loss: 0.3983, Val Loss: 0.3986, Test Loss: 0.3982, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 230/500 - Train Loss: 0.3979, Val Loss: 0.3982, Test Loss: 0.3978, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 231/500 - Train Loss: 0.3975, Val Loss: 0.3978, Test Loss: 0.3974, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 232/500 - Train Loss: 0.3971, Val Loss: 0.3974, Test Loss: 0.3970, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 233/500 - Train Loss: 0.3967, Val Loss: 0.3970, Test Loss: 0.3965, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 234/500 - Train Loss: 0.3962, Val Loss: 0.3966, Test Loss: 0.3961, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 235/500 - Train Loss: 0.3958, Val Loss: 0.3962, Test Loss: 0.3957, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 236/500 - Train Loss: 0.3954, Val Loss: 0.3957, Test Loss: 0.3953, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 237/500 - Train Loss: 0.3950, Val Loss: 0.3953, Test Loss: 0.3949, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 238/500 - Train Loss: 0.3946, Val Loss: 0.3949, Test Loss: 0.3945, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 239/500 - Train Loss: 0.3942, Val Loss: 0.3945, Test Loss: 0.3941, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 240/500 - Train Loss: 0.3937, Val Loss: 0.3941, Test Loss: 0.3936, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 241/500 - Train Loss: 0.3933, Val Loss: 0.3937, Test Loss: 0.3932, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 242/500 - Train Loss: 0.3929, Val Loss: 0.3933, Test Loss: 0.3928, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 243/500 - Train Loss: 0.3925, Val Loss: 0.3929, Test Loss: 0.3924, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 244/500 - Train Loss: 0.3921, Val Loss: 0.3924, Test Loss: 0.3920, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 245/500 - Train Loss: 0.3917, Val Loss: 0.3920, Test Loss: 0.3916, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 246/500 - Train Loss: 0.3913, Val Loss: 0.3916, Test Loss: 0.3912, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 247/500 - Train Loss: 0.3908, Val Loss: 0.3912, Test Loss: 0.3908, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 248/500 - Train Loss: 0.3904, Val Loss: 0.3908, Test Loss: 0.3904, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 249/500 - Train Loss: 0.3900, Val Loss: 0.3904, Test Loss: 0.3899, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 250/500 - Train Loss: 0.3896, Val Loss: 0.3900, Test Loss: 0.3895, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 251/500 - Train Loss: 0.3892, Val Loss: 0.3896, Test Loss: 0.3891, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 252/500 - Train Loss: 0.3888, Val Loss: 0.3892, Test Loss: 0.3887, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 253/500 - Train Loss: 0.3884, Val Loss: 0.3888, Test Loss: 0.3883, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 254/500 - Train Loss: 0.3880, Val Loss: 0.3884, Test Loss: 0.3879, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 255/500 - Train Loss: 0.3876, Val Loss: 0.3880, Test Loss: 0.3875, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 256/500 - Train Loss: 0.3872, Val Loss: 0.3876, Test Loss: 0.3871, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 257/500 - Train Loss: 0.3868, Val Loss: 0.3872, Test Loss: 0.3867, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 258/500 - Train Loss: 0.3863, Val Loss: 0.3868, Test Loss: 0.3863, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 259/500 - Train Loss: 0.3859, Val Loss: 0.3864, Test Loss: 0.3859, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 260/500 - Train Loss: 0.3855, Val Loss: 0.3860, Test Loss: 0.3855, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 261/500 - Train Loss: 0.3851, Val Loss: 0.3856, Test Loss: 0.3851, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 262/500 - Train Loss: 0.3847, Val Loss: 0.3851, Test Loss: 0.3847, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 263/500 - Train Loss: 0.3843, Val Loss: 0.3847, Test Loss: 0.3843, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 264/500 - Train Loss: 0.3839, Val Loss: 0.3843, Test Loss: 0.3839, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 265/500 - Train Loss: 0.3835, Val Loss: 0.3839, Test Loss: 0.3835, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 266/500 - Train Loss: 0.3831, Val Loss: 0.3835, Test Loss: 0.3831, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 267/500 - Train Loss: 0.3827, Val Loss: 0.3831, Test Loss: 0.3827, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 268/500 - Train Loss: 0.3823, Val Loss: 0.3827, Test Loss: 0.3823, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 269/500 - Train Loss: 0.3819, Val Loss: 0.3824, Test Loss: 0.3818, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 270/500 - Train Loss: 0.3815, Val Loss: 0.3820, Test Loss: 0.3814, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 271/500 - Train Loss: 0.3811, Val Loss: 0.3816, Test Loss: 0.3811, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 272/500 - Train Loss: 0.3807, Val Loss: 0.3812, Test Loss: 0.3807, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 273/500 - Train Loss: 0.3803, Val Loss: 0.3808, Test Loss: 0.3803, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 274/500 - Train Loss: 0.3799, Val Loss: 0.3804, Test Loss: 0.3799, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275/500 - Train Loss: 0.3795, Val Loss: 0.3800, Test Loss: 0.3795, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 276/500 - Train Loss: 0.3791, Val Loss: 0.3796, Test Loss: 0.3791, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 277/500 - Train Loss: 0.3787, Val Loss: 0.3792, Test Loss: 0.3787, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 278/500 - Train Loss: 0.3783, Val Loss: 0.3788, Test Loss: 0.3783, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 279/500 - Train Loss: 0.3779, Val Loss: 0.3784, Test Loss: 0.3779, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 280/500 - Train Loss: 0.3775, Val Loss: 0.3780, Test Loss: 0.3775, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 281/500 - Train Loss: 0.3771, Val Loss: 0.3776, Test Loss: 0.3771, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 282/500 - Train Loss: 0.3767, Val Loss: 0.3772, Test Loss: 0.3767, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 283/500 - Train Loss: 0.3763, Val Loss: 0.3768, Test Loss: 0.3763, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 284/500 - Train Loss: 0.3759, Val Loss: 0.3764, Test Loss: 0.3759, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 285/500 - Train Loss: 0.3755, Val Loss: 0.3760, Test Loss: 0.3755, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 286/500 - Train Loss: 0.3751, Val Loss: 0.3756, Test Loss: 0.3751, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 287/500 - Train Loss: 0.3747, Val Loss: 0.3753, Test Loss: 0.3747, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 288/500 - Train Loss: 0.3744, Val Loss: 0.3749, Test Loss: 0.3743, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 289/500 - Train Loss: 0.3740, Val Loss: 0.3745, Test Loss: 0.3739, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 290/500 - Train Loss: 0.3736, Val Loss: 0.3741, Test Loss: 0.3735, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 291/500 - Train Loss: 0.3732, Val Loss: 0.3737, Test Loss: 0.3732, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 292/500 - Train Loss: 0.3728, Val Loss: 0.3733, Test Loss: 0.3728, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 293/500 - Train Loss: 0.3724, Val Loss: 0.3729, Test Loss: 0.3724, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 294/500 - Train Loss: 0.3720, Val Loss: 0.3725, Test Loss: 0.3720, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 295/500 - Train Loss: 0.3716, Val Loss: 0.3721, Test Loss: 0.3716, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 296/500 - Train Loss: 0.3712, Val Loss: 0.3718, Test Loss: 0.3712, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 297/500 - Train Loss: 0.3708, Val Loss: 0.3714, Test Loss: 0.3708, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 298/500 - Train Loss: 0.3704, Val Loss: 0.3710, Test Loss: 0.3704, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 299/500 - Train Loss: 0.3701, Val Loss: 0.3706, Test Loss: 0.3701, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 300/500 - Train Loss: 0.3697, Val Loss: 0.3702, Test Loss: 0.3697, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 301/500 - Train Loss: 0.3693, Val Loss: 0.3698, Test Loss: 0.3693, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 302/500 - Train Loss: 0.3689, Val Loss: 0.3695, Test Loss: 0.3689, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 303/500 - Train Loss: 0.3685, Val Loss: 0.3691, Test Loss: 0.3685, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 304/500 - Train Loss: 0.3681, Val Loss: 0.3687, Test Loss: 0.3681, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 305/500 - Train Loss: 0.3677, Val Loss: 0.3683, Test Loss: 0.3677, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 306/500 - Train Loss: 0.3674, Val Loss: 0.3679, Test Loss: 0.3674, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 307/500 - Train Loss: 0.3670, Val Loss: 0.3675, Test Loss: 0.3670, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 308/500 - Train Loss: 0.3666, Val Loss: 0.3672, Test Loss: 0.3666, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 309/500 - Train Loss: 0.3662, Val Loss: 0.3668, Test Loss: 0.3662, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 310/500 - Train Loss: 0.3658, Val Loss: 0.3664, Test Loss: 0.3658, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 311/500 - Train Loss: 0.3654, Val Loss: 0.3660, Test Loss: 0.3655, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 312/500 - Train Loss: 0.3651, Val Loss: 0.3656, Test Loss: 0.3651, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 313/500 - Train Loss: 0.3647, Val Loss: 0.3653, Test Loss: 0.3647, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 314/500 - Train Loss: 0.3643, Val Loss: 0.3649, Test Loss: 0.3643, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 315/500 - Train Loss: 0.3639, Val Loss: 0.3645, Test Loss: 0.3639, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 316/500 - Train Loss: 0.3635, Val Loss: 0.3641, Test Loss: 0.3636, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 317/500 - Train Loss: 0.3632, Val Loss: 0.3638, Test Loss: 0.3632, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 318/500 - Train Loss: 0.3628, Val Loss: 0.3634, Test Loss: 0.3628, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 319/500 - Train Loss: 0.3624, Val Loss: 0.3630, Test Loss: 0.3624, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 320/500 - Train Loss: 0.3620, Val Loss: 0.3626, Test Loss: 0.3620, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 321/500 - Train Loss: 0.3616, Val Loss: 0.3623, Test Loss: 0.3617, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 322/500 - Train Loss: 0.3613, Val Loss: 0.3619, Test Loss: 0.3613, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 323/500 - Train Loss: 0.3609, Val Loss: 0.3615, Test Loss: 0.3609, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 324/500 - Train Loss: 0.3605, Val Loss: 0.3611, Test Loss: 0.3605, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 325/500 - Train Loss: 0.3601, Val Loss: 0.3608, Test Loss: 0.3602, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 326/500 - Train Loss: 0.3598, Val Loss: 0.3604, Test Loss: 0.3598, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 327/500 - Train Loss: 0.3594, Val Loss: 0.3600, Test Loss: 0.3594, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 328/500 - Train Loss: 0.3590, Val Loss: 0.3597, Test Loss: 0.3591, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 329/500 - Train Loss: 0.3586, Val Loss: 0.3593, Test Loss: 0.3587, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 330/500 - Train Loss: 0.3583, Val Loss: 0.3589, Test Loss: 0.3583, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 331/500 - Train Loss: 0.3579, Val Loss: 0.3585, Test Loss: 0.3579, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 332/500 - Train Loss: 0.3575, Val Loss: 0.3582, Test Loss: 0.3576, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 333/500 - Train Loss: 0.3572, Val Loss: 0.3578, Test Loss: 0.3572, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 334/500 - Train Loss: 0.3568, Val Loss: 0.3574, Test Loss: 0.3568, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 335/500 - Train Loss: 0.3564, Val Loss: 0.3571, Test Loss: 0.3565, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 336/500 - Train Loss: 0.3560, Val Loss: 0.3567, Test Loss: 0.3561, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 337/500 - Train Loss: 0.3557, Val Loss: 0.3563, Test Loss: 0.3557, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 338/500 - Train Loss: 0.3553, Val Loss: 0.3560, Test Loss: 0.3554, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 339/500 - Train Loss: 0.3549, Val Loss: 0.3556, Test Loss: 0.3550, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 340/500 - Train Loss: 0.3546, Val Loss: 0.3552, Test Loss: 0.3546, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 341/500 - Train Loss: 0.3542, Val Loss: 0.3549, Test Loss: 0.3543, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342/500 - Train Loss: 0.3538, Val Loss: 0.3545, Test Loss: 0.3539, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 343/500 - Train Loss: 0.3535, Val Loss: 0.3542, Test Loss: 0.3535, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 344/500 - Train Loss: 0.3531, Val Loss: 0.3538, Test Loss: 0.3532, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 345/500 - Train Loss: 0.3527, Val Loss: 0.3534, Test Loss: 0.3528, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 346/500 - Train Loss: 0.3524, Val Loss: 0.3531, Test Loss: 0.3524, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 347/500 - Train Loss: 0.3520, Val Loss: 0.3527, Test Loss: 0.3521, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 348/500 - Train Loss: 0.3516, Val Loss: 0.3523, Test Loss: 0.3517, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 349/500 - Train Loss: 0.3513, Val Loss: 0.3520, Test Loss: 0.3513, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 350/500 - Train Loss: 0.3509, Val Loss: 0.3516, Test Loss: 0.3510, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 351/500 - Train Loss: 0.3505, Val Loss: 0.3513, Test Loss: 0.3506, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 352/500 - Train Loss: 0.3502, Val Loss: 0.3509, Test Loss: 0.3503, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 353/500 - Train Loss: 0.3498, Val Loss: 0.3505, Test Loss: 0.3499, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 354/500 - Train Loss: 0.3495, Val Loss: 0.3502, Test Loss: 0.3495, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 355/500 - Train Loss: 0.3491, Val Loss: 0.3498, Test Loss: 0.3492, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 356/500 - Train Loss: 0.3487, Val Loss: 0.3495, Test Loss: 0.3488, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 357/500 - Train Loss: 0.3484, Val Loss: 0.3491, Test Loss: 0.3485, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 358/500 - Train Loss: 0.3480, Val Loss: 0.3488, Test Loss: 0.3481, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 359/500 - Train Loss: 0.3477, Val Loss: 0.3484, Test Loss: 0.3478, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 360/500 - Train Loss: 0.3473, Val Loss: 0.3480, Test Loss: 0.3474, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 361/500 - Train Loss: 0.3469, Val Loss: 0.3477, Test Loss: 0.3470, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 362/500 - Train Loss: 0.3466, Val Loss: 0.3473, Test Loss: 0.3467, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 363/500 - Train Loss: 0.3462, Val Loss: 0.3470, Test Loss: 0.3463, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 364/500 - Train Loss: 0.3459, Val Loss: 0.3466, Test Loss: 0.3460, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 365/500 - Train Loss: 0.3455, Val Loss: 0.3463, Test Loss: 0.3456, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 366/500 - Train Loss: 0.3452, Val Loss: 0.3459, Test Loss: 0.3453, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 367/500 - Train Loss: 0.3448, Val Loss: 0.3456, Test Loss: 0.3449, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 368/500 - Train Loss: 0.3445, Val Loss: 0.3452, Test Loss: 0.3446, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 369/500 - Train Loss: 0.3441, Val Loss: 0.3449, Test Loss: 0.3442, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 370/500 - Train Loss: 0.3437, Val Loss: 0.3445, Test Loss: 0.3439, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 371/500 - Train Loss: 0.3434, Val Loss: 0.3442, Test Loss: 0.3435, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 372/500 - Train Loss: 0.3430, Val Loss: 0.3438, Test Loss: 0.3432, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 373/500 - Train Loss: 0.3427, Val Loss: 0.3435, Test Loss: 0.3428, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 374/500 - Train Loss: 0.3423, Val Loss: 0.3431, Test Loss: 0.3425, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 375/500 - Train Loss: 0.3420, Val Loss: 0.3428, Test Loss: 0.3421, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 376/500 - Train Loss: 0.3416, Val Loss: 0.3424, Test Loss: 0.3418, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 377/500 - Train Loss: 0.3413, Val Loss: 0.3421, Test Loss: 0.3414, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 378/500 - Train Loss: 0.3409, Val Loss: 0.3417, Test Loss: 0.3411, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 379/500 - Train Loss: 0.3406, Val Loss: 0.3414, Test Loss: 0.3407, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 380/500 - Train Loss: 0.3402, Val Loss: 0.3410, Test Loss: 0.3404, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 381/500 - Train Loss: 0.3399, Val Loss: 0.3407, Test Loss: 0.3400, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 382/500 - Train Loss: 0.3395, Val Loss: 0.3404, Test Loss: 0.3397, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 383/500 - Train Loss: 0.3392, Val Loss: 0.3400, Test Loss: 0.3393, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 384/500 - Train Loss: 0.3389, Val Loss: 0.3397, Test Loss: 0.3390, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 385/500 - Train Loss: 0.3385, Val Loss: 0.3393, Test Loss: 0.3386, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 386/500 - Train Loss: 0.3382, Val Loss: 0.3390, Test Loss: 0.3383, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 387/500 - Train Loss: 0.3378, Val Loss: 0.3386, Test Loss: 0.3379, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 388/500 - Train Loss: 0.3375, Val Loss: 0.3383, Test Loss: 0.3376, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 389/500 - Train Loss: 0.3371, Val Loss: 0.3380, Test Loss: 0.3373, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 390/500 - Train Loss: 0.3368, Val Loss: 0.3376, Test Loss: 0.3369, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 391/500 - Train Loss: 0.3364, Val Loss: 0.3373, Test Loss: 0.3366, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 392/500 - Train Loss: 0.3361, Val Loss: 0.3369, Test Loss: 0.3362, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 393/500 - Train Loss: 0.3358, Val Loss: 0.3366, Test Loss: 0.3359, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 394/500 - Train Loss: 0.3354, Val Loss: 0.3363, Test Loss: 0.3356, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 395/500 - Train Loss: 0.3351, Val Loss: 0.3359, Test Loss: 0.3352, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 396/500 - Train Loss: 0.3347, Val Loss: 0.3356, Test Loss: 0.3349, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 397/500 - Train Loss: 0.3344, Val Loss: 0.3353, Test Loss: 0.3345, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 398/500 - Train Loss: 0.3341, Val Loss: 0.3349, Test Loss: 0.3342, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 399/500 - Train Loss: 0.3337, Val Loss: 0.3346, Test Loss: 0.3339, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 400/500 - Train Loss: 0.3334, Val Loss: 0.3342, Test Loss: 0.3335, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 401/500 - Train Loss: 0.3330, Val Loss: 0.3339, Test Loss: 0.3332, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 402/500 - Train Loss: 0.3327, Val Loss: 0.3336, Test Loss: 0.3329, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 403/500 - Train Loss: 0.3324, Val Loss: 0.3332, Test Loss: 0.3325, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 404/500 - Train Loss: 0.3320, Val Loss: 0.3329, Test Loss: 0.3322, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 405/500 - Train Loss: 0.3317, Val Loss: 0.3326, Test Loss: 0.3319, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 406/500 - Train Loss: 0.3314, Val Loss: 0.3322, Test Loss: 0.3315, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 407/500 - Train Loss: 0.3310, Val Loss: 0.3319, Test Loss: 0.3312, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 408/500 - Train Loss: 0.3307, Val Loss: 0.3316, Test Loss: 0.3309, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 409/500 - Train Loss: 0.3304, Val Loss: 0.3312, Test Loss: 0.3305, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 410/500 - Train Loss: 0.3300, Val Loss: 0.3309, Test Loss: 0.3302, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 411/500 - Train Loss: 0.3297, Val Loss: 0.3306, Test Loss: 0.3299, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 412/500 - Train Loss: 0.3294, Val Loss: 0.3303, Test Loss: 0.3295, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 413/500 - Train Loss: 0.3290, Val Loss: 0.3299, Test Loss: 0.3292, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 414/500 - Train Loss: 0.3287, Val Loss: 0.3296, Test Loss: 0.3289, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 415/500 - Train Loss: 0.3284, Val Loss: 0.3293, Test Loss: 0.3285, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 416/500 - Train Loss: 0.3280, Val Loss: 0.3289, Test Loss: 0.3282, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 417/500 - Train Loss: 0.3277, Val Loss: 0.3286, Test Loss: 0.3279, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 418/500 - Train Loss: 0.3274, Val Loss: 0.3283, Test Loss: 0.3275, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 419/500 - Train Loss: 0.3270, Val Loss: 0.3280, Test Loss: 0.3272, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 420/500 - Train Loss: 0.3267, Val Loss: 0.3276, Test Loss: 0.3269, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 421/500 - Train Loss: 0.3264, Val Loss: 0.3273, Test Loss: 0.3266, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 422/500 - Train Loss: 0.3261, Val Loss: 0.3270, Test Loss: 0.3262, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 423/500 - Train Loss: 0.3257, Val Loss: 0.3267, Test Loss: 0.3259, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 424/500 - Train Loss: 0.3254, Val Loss: 0.3263, Test Loss: 0.3256, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 425/500 - Train Loss: 0.3251, Val Loss: 0.3260, Test Loss: 0.3253, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 426/500 - Train Loss: 0.3248, Val Loss: 0.3257, Test Loss: 0.3249, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 427/500 - Train Loss: 0.3244, Val Loss: 0.3254, Test Loss: 0.3246, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 428/500 - Train Loss: 0.3241, Val Loss: 0.3250, Test Loss: 0.3243, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 429/500 - Train Loss: 0.3238, Val Loss: 0.3247, Test Loss: 0.3240, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 430/500 - Train Loss: 0.3235, Val Loss: 0.3244, Test Loss: 0.3237, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 431/500 - Train Loss: 0.3231, Val Loss: 0.3241, Test Loss: 0.3233, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 432/500 - Train Loss: 0.3228, Val Loss: 0.3238, Test Loss: 0.3230, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 433/500 - Train Loss: 0.3225, Val Loss: 0.3234, Test Loss: 0.3227, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 434/500 - Train Loss: 0.3222, Val Loss: 0.3231, Test Loss: 0.3224, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 435/500 - Train Loss: 0.3218, Val Loss: 0.3228, Test Loss: 0.3220, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 436/500 - Train Loss: 0.3215, Val Loss: 0.3225, Test Loss: 0.3217, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 437/500 - Train Loss: 0.3212, Val Loss: 0.3222, Test Loss: 0.3214, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 438/500 - Train Loss: 0.3209, Val Loss: 0.3219, Test Loss: 0.3211, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 439/500 - Train Loss: 0.3206, Val Loss: 0.3215, Test Loss: 0.3208, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 440/500 - Train Loss: 0.3202, Val Loss: 0.3212, Test Loss: 0.3205, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 441/500 - Train Loss: 0.3199, Val Loss: 0.3209, Test Loss: 0.3201, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 442/500 - Train Loss: 0.3196, Val Loss: 0.3206, Test Loss: 0.3198, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 443/500 - Train Loss: 0.3193, Val Loss: 0.3203, Test Loss: 0.3195, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 444/500 - Train Loss: 0.3190, Val Loss: 0.3200, Test Loss: 0.3192, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 445/500 - Train Loss: 0.3187, Val Loss: 0.3197, Test Loss: 0.3189, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 446/500 - Train Loss: 0.3183, Val Loss: 0.3193, Test Loss: 0.3186, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 447/500 - Train Loss: 0.3180, Val Loss: 0.3190, Test Loss: 0.3182, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 448/500 - Train Loss: 0.3177, Val Loss: 0.3187, Test Loss: 0.3179, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 449/500 - Train Loss: 0.3174, Val Loss: 0.3184, Test Loss: 0.3176, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 450/500 - Train Loss: 0.3171, Val Loss: 0.3181, Test Loss: 0.3173, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 451/500 - Train Loss: 0.3168, Val Loss: 0.3178, Test Loss: 0.3170, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 452/500 - Train Loss: 0.3165, Val Loss: 0.3175, Test Loss: 0.3167, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 453/500 - Train Loss: 0.3161, Val Loss: 0.3172, Test Loss: 0.3164, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 454/500 - Train Loss: 0.3158, Val Loss: 0.3169, Test Loss: 0.3161, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 455/500 - Train Loss: 0.3155, Val Loss: 0.3165, Test Loss: 0.3158, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 456/500 - Train Loss: 0.3152, Val Loss: 0.3162, Test Loss: 0.3154, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 457/500 - Train Loss: 0.3149, Val Loss: 0.3159, Test Loss: 0.3151, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 458/500 - Train Loss: 0.3146, Val Loss: 0.3156, Test Loss: 0.3148, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 459/500 - Train Loss: 0.3143, Val Loss: 0.3153, Test Loss: 0.3145, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 460/500 - Train Loss: 0.3140, Val Loss: 0.3150, Test Loss: 0.3142, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 461/500 - Train Loss: 0.3137, Val Loss: 0.3147, Test Loss: 0.3139, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 462/500 - Train Loss: 0.3134, Val Loss: 0.3144, Test Loss: 0.3136, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 463/500 - Train Loss: 0.3130, Val Loss: 0.3141, Test Loss: 0.3133, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 464/500 - Train Loss: 0.3127, Val Loss: 0.3138, Test Loss: 0.3130, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 465/500 - Train Loss: 0.3124, Val Loss: 0.3135, Test Loss: 0.3127, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 466/500 - Train Loss: 0.3121, Val Loss: 0.3132, Test Loss: 0.3124, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 467/500 - Train Loss: 0.3118, Val Loss: 0.3129, Test Loss: 0.3121, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 468/500 - Train Loss: 0.3115, Val Loss: 0.3126, Test Loss: 0.3118, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 469/500 - Train Loss: 0.3112, Val Loss: 0.3123, Test Loss: 0.3115, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 470/500 - Train Loss: 0.3109, Val Loss: 0.3120, Test Loss: 0.3112, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 471/500 - Train Loss: 0.3106, Val Loss: 0.3117, Test Loss: 0.3109, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 472/500 - Train Loss: 0.3103, Val Loss: 0.3114, Test Loss: 0.3106, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 473/500 - Train Loss: 0.3100, Val Loss: 0.3111, Test Loss: 0.3103, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 474/500 - Train Loss: 0.3097, Val Loss: 0.3108, Test Loss: 0.3100, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/500 - Train Loss: 0.3094, Val Loss: 0.3105, Test Loss: 0.3097, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 476/500 - Train Loss: 0.3091, Val Loss: 0.3102, Test Loss: 0.3094, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 477/500 - Train Loss: 0.3088, Val Loss: 0.3099, Test Loss: 0.3091, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 478/500 - Train Loss: 0.3085, Val Loss: 0.3096, Test Loss: 0.3088, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 479/500 - Train Loss: 0.3082, Val Loss: 0.3093, Test Loss: 0.3085, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 480/500 - Train Loss: 0.3079, Val Loss: 0.3090, Test Loss: 0.3082, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 481/500 - Train Loss: 0.3076, Val Loss: 0.3087, Test Loss: 0.3079, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 482/500 - Train Loss: 0.3073, Val Loss: 0.3084, Test Loss: 0.3076, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 483/500 - Train Loss: 0.3070, Val Loss: 0.3081, Test Loss: 0.3073, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 484/500 - Train Loss: 0.3067, Val Loss: 0.3078, Test Loss: 0.3070, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 485/500 - Train Loss: 0.3064, Val Loss: 0.3075, Test Loss: 0.3067, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 486/500 - Train Loss: 0.3061, Val Loss: 0.3072, Test Loss: 0.3064, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 487/500 - Train Loss: 0.3058, Val Loss: 0.3069, Test Loss: 0.3061, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 488/500 - Train Loss: 0.3055, Val Loss: 0.3066, Test Loss: 0.3058, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 489/500 - Train Loss: 0.3052, Val Loss: 0.3063, Test Loss: 0.3055, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 490/500 - Train Loss: 0.3049, Val Loss: 0.3060, Test Loss: 0.3052, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 491/500 - Train Loss: 0.3046, Val Loss: 0.3058, Test Loss: 0.3049, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 492/500 - Train Loss: 0.3043, Val Loss: 0.3055, Test Loss: 0.3046, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 493/500 - Train Loss: 0.3040, Val Loss: 0.3052, Test Loss: 0.3043, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 494/500 - Train Loss: 0.3037, Val Loss: 0.3049, Test Loss: 0.3040, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 495/500 - Train Loss: 0.3035, Val Loss: 0.3046, Test Loss: 0.3037, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 496/500 - Train Loss: 0.3032, Val Loss: 0.3043, Test Loss: 0.3035, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 497/500 - Train Loss: 0.3029, Val Loss: 0.3040, Test Loss: 0.3032, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 498/500 - Train Loss: 0.3026, Val Loss: 0.3037, Test Loss: 0.3029, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 499/500 - Train Loss: 0.3023, Val Loss: 0.3034, Test Loss: 0.3026, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 500/500 - Train Loss: 0.3020, Val Loss: 0.3031, Test Loss: 0.3023, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAArWUlEQVR4nO3de3xU1bn/8c8zk3AN9QZaC7RQixcoBCRSC1qh1h6sykXqEaqnUlsv/OoFrW1RW+ux+jpq+fVUe6wttupBPeCloigoR0XUX7FKQEBAUcQoUKURuaUQMpfn98fsmQ4hhASyM0n29/165cW+72fFOM+stfZey9wdERGJrlihAxARkcJSIhARiTglAhGRiFMiEBGJOCUCEZGIKyp0AI3VtWtX79WrV6HDEBFpVRYvXvyJu3era1+rSwS9evWivLy80GGIiLQqZvbB3vapaUhEJOKUCEREIk6JQEQk4pQIREQiTolARCTilAhERCJOiUBEJOJa3XsEYfjr2o2Uf7CJnYkUTTUsd+Ou0/RDgXujrtnwY8M4suD3b8R/q3CODGMo+MLeP6y/v8Yd2tCDwxmKP4z7/8txX+KrvXvsX0D1iHwi+MWc65lVORu3QkciIlK/2D++yVd7/98mv26kE8HrH8zn8U9mM3xHNQOKDyEWa1g2aEzOaOixYVyzMcK6fxjlb8wXuIbfv+ERFLz8Bb6/yh/O30pD9D+qbxNfMSPSiWD2G3/g4FSK/of9kovOHV/ocERECiLUzmIzG2lmq81sjZlNqWP/F8zsBTNbbmYLzKzpG7/q8eG2D+megMOOGtactxURaVFCSwRmFgfuAk4H+gITzKx2vWYqMN3dBwA3Af8RVjx1+VtqB10S7ejVraQ5bysi0qKEWSMYAqxx97XuXgPMBEbXOqYvMD9YfrGO/aFJpBNUWorimhJ6d+3cXLcVEWlxwkwE3YF1eevrg235lgFnB8tjgS5mdliIMeV8vPUD0mbEU4dxSKfi5riliEiLVOgXyq4BTjGzN4BTgA1AqvZBZnaxmZWbWXllZWWT3HjTJ28D4LHPYqZnR0UkusJMBBuAnnnrPYJtOe7+N3c/290HAdcH27bUvpC7T3P3Mncv69atzgl2Gq2q6uPMtYub5noiIq1VmIlgEdDHzHqbWTtgPDA7/wAz62pm2RiuBe4NMZ7dVO3cBEC74kOa65YiIi1SaInA3ZPAZcA84C3gEXdfaWY3mdmo4LDhwGozewc4ArglrHhq2169GYB2HVUjEJFoC/WFMnefC8ytte2GvOXHgMfCjGFv/rFrKwAdO362ELcXEWkxCt1ZXDDbd20l5k7nkiMKHYqISEFFNhFsramic9rpUqKXyUQk2iKbCLYn/kGnNBzUUe8QiEi0RTcRJKvpkDY+00GJQESiLbKJoCq9i/bpGJ3axwsdiohIQUU2EezwJMXpOO2LIvsrEBEBIpwIqj1FzON0KFaNQESiLbKJoMacWDpOhyIlAhGJtsgmgl2AeREdiiP7KxARAaKcCAwsXaSmIRGJvEgnAlyJQEQkkokgmagmaQbpYj01JCKRF8lPwV27tgDgXqwagYhEXiQTQXV1ZuRRpx3xmGYnE5Foi2Qi2LVrGwAxOhQ4EhGRwotkIqgOEgFKBCIi4SYCMxtpZqvNbI2ZTalj/+fN7EUze8PMlpvZt8KMJ2tXTSYRWEyJQEQktERgZnHgLuB0oC8wwcz61jrsZ2SmsBxEZk7j34UVT75dNVUAxGKdmuN2IiItWpg1giHAGndf6+41wExgdK1jHPhMsHwQ8LcQ48nZWbMdALOOzXE7EZEWLcxE0B1Yl7e+PtiW70bgfDNbT2Zu48vrupCZXWxm5WZWXllZecCB7Ur8A4B4UecDvpaISGtX6M7iCcD97t4D+BbwgJntEZO7T3P3Mncv69at2wHftDqxA4BYXIlARCTMRLAB6Jm33iPYlu/7wCMA7v4qmcd4uoYYEwC7gkRQVNQl7FuJiLR4YSaCRUAfM+ttZu3IdAbPrnXMh8CpAGZ2HJlEcOBtP/uwK7kTUI1ARARCTATungQuA+YBb5F5Omilmd1kZqOCw34EXGRmy4AZwER397BiykqkagAoKtJTQyIiRWFe3N3nkukEzt92Q97yKmBYmDHUpSadAKA4rqeGREQK3VlcEIlsIijWC2UiIhFNBEkA4kWqEYiIRDIR1KQTFLtTXNyu0KGIiBRcJBNBIpsI4pEsvojIbiL5SZhIJyl2aBfXXAQiIpFMBLvSSYrcaadpKkVEopkIEukURW5qGhIRIaqJwFMUO0oEIiJENBHsSicpAorVNCQiEs1EkPAUcXUWi4gAkU0EafURiIgEIvlJWOMp4m56akhEhIgmggRpYuosFhEBIpoIkkHTUDslAhGRaCaCGpyYx1QjEBEh5ERgZiPNbLWZrTGzKXXs/08zWxr8vGNmW8KMJytJmpgbxXpqSEQkvIlpzCwO3AWcBqwHFpnZ7GAyGgDc/aq84y8HBoUVT74ETtxN7xGIiBBujWAIsMbd17p7DTATGF3P8RPITFcZugRgHlMfgYgI4SaC7sC6vPX1wbY9mNkXgN7A/BDjyUkEfQR6fFREpOV0Fo8HHnP3VF07zexiMys3s/LKysoDvlkS1FksIhII85NwA9Azb71HsK0u46mnWcjdp7l7mbuXdevW7YADqzHHiKmzWESEcBPBIqCPmfU2s3ZkPuxn1z7IzI4FDgFeDTGWHHcnaYalVSMQEYEQE4G7J4HLgHnAW8Aj7r7SzG4ys1F5h44HZrq7hxVLvmQwcT0eVyIQESHEx0cB3H0uMLfWthtqrd8YZgy1JT1IBMQoUtOQiEiL6SxuNrvVCGKRK76IyB4i90mYSmceTHKPEY+pRiAiErlE8M+mobieGhIRIYqJIJUIluKYKRGIiEQvESSrMwseL2wgIiItROQSQSqVSQRmoT4wJSLSakQuESQTQY0g3CdnRURajeglglQNAKZEICICRDERZPsI1DQkIgJEMBGkUrsA9RGIiGRFLhEkc4mguMCRiIi0DJFLBKmgj0BNQyIiGZFLBIlkUCNANQIREYhgIkilMzWCWEyJQEQEIpgIksls01C7wgYiItJCRC4R5GoESgQiIkDIicDMRprZajNbY2ZT9nLMv5rZKjNbaWb/E2Y8kPdCmZqGRESAEMdZMLM4cBdwGrAeWGRms919Vd4xfYBrgWHuvtnMDg8rnqzs6KMWU41ARAQaUCMws7PMbH9qDkOANe6+1t1rgJnA6FrHXATc5e6bAdz97/txn0bJ1ghicSUCERFoWNPQucC7Zna7mR3biGt3B9blra8PtuU7GjjazP5iZn81s5F1XcjMLjazcjMrr6ysbEQIe0qlMzUC9RGIiGTsMxG4+/nAIOA94H4zezX4YO7SBPcvAvoAw4EJwD1mdnAdMUxz9zJ3L+vWrdsB3TCZ7SyOtz+g64iItBUNavJx923AY2Sad44ExgJLzOzyek7bAPTMW+8RbMu3Hpjt7gl3fx94h0xiCE128nolAhGRjIb0EYwys1nAAqAYGOLupwOlwI/qOXUR0MfMeptZO2A8MLvWMU+QqQ1gZl3JNBWtbVwRGkedxSIiu2vIU0PjgP9095fzN7r7DjP7/t5OcvekmV0GzAPiwL3uvtLMbgLK3X12sO+bZrYKSAE/dvdN+1uYhsj2ERTFOoR5GxGRVqMhieBG4KPsipl1BI5w9wp3f6G+E919LjC31rYb8pYduDr4aRa5pqEiNQ2JiEDD+ggeBdJ566lgW6uUChJBUZFqBCIi0LBEUBS8BwBAsNxqG9gT6QQxd0w1AhERoGGJoNLMRmVXzGw08El4IYUrlU5S5BAr0nwEIiLQsD6CS4GHzOy/ACPzkth3Q40qRMl0ijiuN4tFRAL7TATu/h5wopmVBOtVoUcVoqRnagTxuGoEIiLQwEHnzOwMoB/QwcwAcPebQowrNIl0kjhOUTxyI3CLiNSpIS+U/Z7MeEOXk2kaOgf4QshxhSaZTlHkKBGIiAQa8mk41N2/C2x2938HvkrmDeBWKZlOEgeKYlboUEREWoSGJILq4N8dZvY5IEFmvKFWKekp4q5EICKS1ZA+gqeCEUF/BSwBHLgnzKDClEyniKlpSEQkp95EEExI84K7bwH+bGZPAx3cfWtzBBeGpKeIYxTHVSMQEYF9NA25e5rMdJPZ9V2tOQkAJD1NzCEeU41ARAQa1kfwgpmNs+xzo61cytPEXTUCEZGshiSCS8gMMrfLzLaZ2XYz2xZyXKFJehoDilQjEBEBGvZmcVNMSdliJIMaQVxPDYmIAA1IBGb2tbq2156oZi/njgTuIDMxzR/d/dZa+yeSeRopO4Xlf7n7H/d13QORIo2ps1hEJKchj4/+OG+5AzAEWAx8vb6TzCxOpqP5NDJzEy8ys9nuvqrWoQ+7+2UND/nAJEkTU41ARCSnIU1DZ+Wvm1lP4DcNuPYQYI27rw3OmwmMBmongmaVcqfIjWK9RyAiAjSss7i29cBxDTiuO5khq/PP617HcePMbLmZPRYkmVClcGJuerNYRCTQkD6C35J5mxgyiWMgmTeMm8JTwAx332VmlwD/TR1NTmZ2MXAxwOc///kDumESx4hTpD4CERGgYX0E5XnLSTIf3H9pwHkbgPxv+D34Z6cwAO6+KW/1j8DtdV3I3acB0wDKysq8rmMaKoVjbnp8VEQk0JBE8BhQ7e4pyHQCm1knd9+xj/MWAX3MrDeZBDAe+E7+AWZ2pLt/FKyOAt5qVPT7IYmDx1QjEBEJNOjNYqBj3npH4Pl9neTuSeAyYB6ZD/hH3H2lmd2UNwfyFWa20syWAVcAExsT/P5I4cRQjUBEJKshNYIO+dNTunuVmXVqyMXdfS4wt9a2G/KWrwWubWCsTSIJqhGIiORpyNfif5jZ8dkVMxsM7AwvpHClIJMI9NSQiAjQsBrBZOBRM/sbmakqP0tm6spWKWlgHtN8BCIigYa8ULbIzI4Fjgk2rXb3RLhhhScFQIxi1QhERICGTV7/Q6Czu69w9xVAiZn9n/BDC0fSwD2uISZERAINaR+5KJihDAB33wxcFFpEIUuhpiERkXwN+TSM509KEwwm1y68kMKTTqdIm+HENPqoiEigIZ3FzwIPm9kfgvVLgGfCCyk8qeSuzIKahkREchqSCH5KZpyfS4P15WSeHGp1EsnMU6/ucYr1QpmICNCApqFgAvvXgAoyQ0t/nWYYCiIMqWR1sBQnphqBiAhQT43AzI4GJgQ/nwAPA7j7iOYJrekl8xKBiIhk1Nc09DbwCnCmu68BMLOrmiWqkKRSQR+BEoGISE59TUNnAx8BL5rZPWZ2Kpk3i1utf9YIGtI1IiISDXtNBO7+hLuPB44FXiQz1MThZna3mX2zmeJrUsmgRmBKBCIiOQ3pLP6Hu/9PMHdxD+ANMk8StTrJRJAITIlARCSrUc9Quvtmd5/m7qeGFVCYUulsH0FxQeMQEWlJIvUwfbaPQDUCEZF/CjURmNlIM1ttZmvMbEo9x40zMzezsjDjSaYyg6ZaTDUCEZGs0BJBMCbRXcDpQF9ggpn1reO4LsCVZF5aC1Uyqc5iEZHawqwRDAHWuPtad68BZgKj6zjul8BtQHUd+5pUro/AVCMQEckKMxF0B9blra8PtuUEU2D2dPc59V3IzC42s3IzK6+srNzvgJLJmsz11DQkIpJTsM5iM4sBvwZ+tK9jgyeVyty9rFu3bvt9z2Q6SATWKkfRFhEJRZiJYAPQM2+9R7AtqwvwZWCBmVUAJwKzw+wwTgR9BLGYEoGISFaYiWAR0MfMelvmK/h4YHZ2p7tvdfeu7t7L3XsBfwVGuXt5WAFlawSxWPuwbiEi0uqElgjcPQlcBswjM2z1I+6+0sxuMrNRYd23Ponc46OqEYiIZIX6HKW7zwXm1tp2w16OHR5mLJBXIzDVCEREsqL1ZnFQI4jFVSMQEcmKViJIZxNBhwJHIiLSckQrEWRrBHp8VEQkJ1qJIFsjKFKNQEQkK1KJIBEkgriahkREciKVCJLpJACxoo4FjkREpOWIZCIo1gtlIiI5kUoECU8Sc6e4WIPOiYhkRSoRJNNJihyKYlboUEREWozoJQKcorgSgYhIVrQSgaeIOxTFIlVsEZF6ReoTMZFOBolANQIRkayIJYIURUBRPFLFFhGpV6Q+ERO5piHVCEREsiKVCDJ9BKbOYhGRPKEmAjMbaWarzWyNmU2pY/+lZvammS01s/9nZn3DjCeRThFHTUMiIvlC+0Q0szhwF3A60BeYUMcH/f+4e393HwjcTmYy+9AkSRNzU9OQiEieML8aDwHWuPtad68BZgKj8w9w9215q50BDzEekp7ONA0pEYiI5IQ5VWV3YF3e+nrgK7UPMrMfAlcD7YCvhxgPSU8TcyhW05CISE7BPxHd/S53Pwr4KfCzuo4xs4vNrNzMyisrK/f7XklPE8OIq0YgIpITZo1gA9Azb71HsG1vZgJ317XD3acB0wDKysr2u/koiRPzGMV6akjagEQiwfr166muri50KNKCdOjQgR49ejRqcM0wE8EioI+Z9SaTAMYD38k/wMz6uPu7weoZwLuEKEGamMeJa4gJaQPWr19Ply5d6NWrF2b6ciPg7mzatIn169fTu3fvBp8XWiJw96SZXQbMA+LAve6+0sxuAsrdfTZwmZl9A0gAm4ELwooHMjWC9nqPQNqI6upqJQHZjZlx2GGH0dgm9DBrBLj7XGBurW035C1fGeb9a0vhxNBTQ9J2KAlIbfvzNxGpNpKkAx6jnZ4aEhHJidQnYo05MY9TXBSpYouEYtOmTQwcOJCBAwfy2c9+lu7du+fWa2pq6j23vLycK664Yp/3GDp0aFOFC8DkyZPp3r076XS6Sa/b2oXaNNTSJHHVCESayGGHHcbSpUsBuPHGGykpKeGaa67J7U8mkxQV1f0RU1ZWRllZ2T7vsXDhwiaJFSCdTjNr1ix69uzJSy+9xIgRI5rs2vnqK3dL1bqiPUA1BuZFtFeNQNqYf39qJav+tm3fBzZC3899hl+c1a9R50ycOJEOHTrwxhtvMGzYMMaPH8+VV15JdXU1HTt25L777uOYY45hwYIFTJ06laeffpobb7yRDz/8kLVr1/Lhhx8yefLkXG2hpKSEqqoqFixYwI033kjXrl1ZsWIFgwcP5sEHH8TMmDt3LldffTWdO3dm2LBhrF27lqeffnqP2BYsWEC/fv0499xzmTFjRi4RbNy4kUsvvZS1a9cCcPfddzN06FCmT5/O1KlTMTMGDBjAAw88wMSJEznzzDP59re/vUd8P//5zznkkEN4++23eeeddxgzZgzr1q2jurqaK6+8kosvvhiAZ599luuuu45UKkXXrl157rnnOOaYY1i4cCHdunUjnU5z9NFH8+qrr9KtW7f9/u/XGJFKBAkAj+vNYpEQrV+/noULFxKPx9m2bRuvvPIKRUVFPP/881x33XX8+c9/3uOct99+mxdffJHt27dzzDHHMGnSpD2eg3/jjTdYuXIln/vc5xg2bBh/+ctfKCsr45JLLuHll1+md+/eTJgwYa9xzZgxgwkTJjB69Giuu+46EokExcXFXHHFFZxyyinMmjWLVCpFVVUVK1eu5Oabb2bhwoV07dqVTz/9dJ/lXrJkCStWrMg9tnnvvfdy6KGHsnPnTk444QTGjRtHOp3moosuysX76aefEovFOP/883nooYeYPHkyzz//PKWlpc2WBCBKicCdhBnucdqpRiBtTGO/uYfpnHPOIR6PA7B161YuuOAC3n33XcyMRCJR5zlnnHEG7du3p3379hx++OFs3LiRHj167HbMkCFDctsGDhxIRUUFJSUlfPGLX8x9+E6YMIFp06btcf2amhrmzp3Lr3/9a7p06cJXvvIV5s2bx5lnnsn8+fOZPn06APF4nIMOOojp06dzzjnn0LVrVwAOPfTQfZZ7yJAhuz27f+eddzJr1iwA1q1bx7vvvktlZSVf+9rXcsdlr3vhhRcyevRoJk+ezL333sv3vve9fd6vKUUmEaQSO0mZQbpIiUAkRJ07d84t//znP2fEiBHMmjWLiooKhg8fXuc57du3zy3H43GSyeR+HbM38+bNY8uWLfTv3x+AHTt20LFjR84888wGXwOgqKgo19GcTqd36xTPL/eCBQt4/vnnefXVV+nUqRPDhw+v9w3wnj17csQRRzB//nxef/11HnrooUbFdaAi84mYqPkHAO5FahoSaSZbt26le/fuANx///1Nfv1jjjmGtWvXUlFRAcDDDz9c53EzZszgj3/8IxUVFVRUVPD+++/z3HPPsWPHDk499VTuvjszuk0qlWLr1q18/etf59FHH2XTpk0AuaahXr16sXjxYgBmz5691xrO1q1bOeSQQ+jUqRNvv/02f/3rXwE48cQTefnll3n//fd3uy7AD37wA84///zdalTNJTKfiDWJfyYCdRaLNI+f/OQnXHvttQwaNKhR3+AbqmPHjvzud79j5MiRDB48mC5dunDQQQftdsyOHTt49tlnOeOMM3LbOnfuzEknncRTTz3FHXfcwYsvvkj//v0ZPHgwq1atol+/flx//fWccsoplJaWcvXVVwNw0UUX8dJLL1FaWsqrr766Wy0g38iRI0kmkxx33HFMmTKFE088EYBu3boxbdo0zj77bEpLSzn33HNz54waNYqqqqpmbxYCMPdQpwBocmVlZV5eXt7o8zb9fSXDnxlPv43H8tA1j2gEUmn13nrrLY477rhCh1FwVVVVlJSU4O788Ic/pE+fPlx11VWFDqvRysvLueqqq3jllVcO+Fp1/W2Y2WJ3r/OZ3ch8NU4kqoKlYiUBkTbknnvuYeDAgfTr14+tW7dyySWXFDqkRrv11lsZN24c//Ef/1GQ+0emszhRszNYalfQOESkaV111VWtsgaQb8qUKUyZsse07s0mMjWCmuQOAMyUCERE8kUmESQSqhGIiNQlMokg+9SQxdrv40gRkWiJTiJIZmoEsViHAkciItKyhJoIzGykma02szVmtkdPiJldbWarzGy5mb1gZl8IK5ZEMnirTzUCkSYxYsQI5s2bt9u23/zmN0yaNGmv5wwfPpzs49/f+ta32LJlyx7H3HjjjUydOrXeez/xxBOsWrUqt37DDTfw/PPPNyL6+kVtuOrQEoGZxYG7gNOBvsAEM+tb67A3gDJ3HwA8BtweVjyJoEZgphqBSFOYMGECM2fO3G3bzJkz6x34Ld/cuXM5+OCD9+vetRPBTTfdxDe+8Y39ulZttYerDksYL9jtrzBrBEOANe6+1t1rgJnA6PwD3P1Fd98RrP4V6EFIEsldgJqGpI16Zgrcd0bT/jxT/+OM3/72t5kzZ05uvJ2Kigr+9re/cfLJJzNp0iTKysro168fv/jFL+o8v1evXnzyyScA3HLLLRx99NGcdNJJrF69OnfMPffcwwknnEBpaSnjxo1jx44dLFy4kNmzZ/PjH/+YgQMH8t577zFx4kQee+wxAF544QUGDRpE//79ufDCC9m1a1fufr/4xS84/vjj6d+/P2+//XadcWWHq540aRIzZszIbd+4cSNjx46ltLSU0tLS3FwJ06dPZ8CAAZSWlvJv//ZvALvFA5nhqrPXPvnkkxk1ahR9+2a+F48ZM4bBgwfTr1+/3QbMe/bZZzn++OMpLS3l1FNPJZ1O06dPn9x8xOl0mi996UuNnp+4LmEmgu7Aurz19cG2vfk+8ExdO8zsYjMrN7Py/S10TSrTNGTxjvt1vojs7tBDD2XIkCE880zmf9uZM2fyr//6r5gZt9xyC+Xl5SxfvpyXXnqJ5cuX7/U6ixcvZubMmSxdupS5c+eyaNGi3L6zzz6bRYsWsWzZMo477jj+9Kc/MXToUEaNGsWvfvUrli5dylFHHZU7vrq6mokTJ/Lwww/z5ptvkkwmc+MIAXTt2pUlS5YwadKkvTY/ZYerHjt2LHPmzMmNJ5QdrnrZsmUsWbKEfv365Yarnj9/PsuWLeOOO+7Y5+9tyZIl3HHHHbzzzjtAZrjqxYsXU15ezp133smmTZuorKzkoosu4s9//jPLli3j0Ucf3W24aqBJh6tuES+Umdn5QBlwSl373X0aMA0yQ0zszz1yNYJ4p/0LUqQlO/3Wgtw22zw0evRoZs6cyZ/+9CcAHnnkEaZNm0YymeSjjz5i1apVDBgwoM5rvPLKK4wdO5ZOnTL/b44aNSq3b8WKFfzsZz9jy5YtVFVV8S//8i/1xrN69Wp69+7N0UcfDcAFF1zAXXfdxeTJk4FMYgEYPHgwjz/++B7nR3W46jATwQagZ956j2DbbszsG8D1wCnuviusYGpSmUvHi1QjEGkqo0eP5qqrrmLJkiXs2LGDwYMH8/777zN16lQWLVrEIYccwsSJE+sdgrk+EydO5IknnqC0tJT777+fBQsWHFC82aGs9zaMdVSHqw6zaWgR0MfMelvmdd7xwOz8A8xsEPAHYJS7/z3EWKiJZYoaj9c9WqCINF5JSQkjRozgwgsvzHUSb9u2jc6dO3PQQQexcePGXNPR3nzta1/jiSeeYOfOnWzfvp2nnnoqt2/79u0ceeSRJBKJ3T70unTpwvbt2/e41jHHHENFRQVr1qwB4IEHHuCUU+psaKhTVIerDi0RuHsSuAyYB7wFPOLuK83sJjPL1v1+BZQAj5rZUjObvZfLHbBEj8yge0XtSsK6hUgkTZgwgWXLluUSQWlpKYMGDeLYY4/lO9/5DsOGDav3/OOPP55zzz2X0tJSTj/9dE444YTcvl/+8pd85StfYdiwYRx77LG57ePHj+dXv/oVgwYN4r333stt79ChA/fddx/nnHMO/fv3JxaLcemllzaoHFEerjoyw1A//u7j3PjSXYw85DZuH1fnSKwirYqGoY6mhgxXrWGo9+LsPmfj635C53bqIxCR1ims4aojkwgAqpMpOhY37xRwIiJNZcqUKXzwwQecdNJJTXrdyCSCRCpNIuVKBCIitUQmEVQnUgB0bKdEICKSLzKJYGeQCDqoRiAispvIJILqmszLHWoaEhHZXYsYYqI57FTTkEiT2rRpE6eeeioAH3/8MfF4PDfuzeuvv067dvXPBrhgwQLatWvH0KFD93rMmDFj+Pjjj3MvWkk4opcIVCMQaRKHHXYYS5cuBTJzCJSUlHDNNdc0+PwFCxZQUlKy10SwZcsWFi9eTElJCWvXruWLX/xiU4S9h2QySVFRZD4K6xSZ0u+sUR+BtF23vX4bb39a97DK++vYQ4/lp0N+2qhzFi9ezNVXX01VVRVdu3bl/vvv58gjj+TOO+/k97//PUVFRfTt25dbb72V3//+98TjcR588EF++9vfcvLJJ+92rccff5yzzjqLI444gpkzZ3LdddcBsGbNGi699FIqKyuJx+M8+uijHHXUUdx22208+OCDxGIxTj/9dG699VaGDx/O1KlTKSsr45NPPqGsrIyKigruv/9+Hn/8caqqqkilUsyZM4fRo0ezefNmEokEN998M6NHZ0bNnz59OlOnTsXMGDBgAL/73e8YMGAA77zzDsXFxWzbto3S0tLcemsUmUSgp4ZEwuXuXH755Tz55JN069aNhx9+mOuvv557772XW2+9lffff5/27duzZcsWDj74YC699NJ6axEzZszghhtu4IgjjmDcuHG5RHDeeecxZcoUxo4dS3V1Nel0mmeeeYYnn3yS1157jU6dOu02Ns/eLFmyhOXLl3PooYeSTCaZNWsWn/nMZ/jkk0848cQTGTVqFKtWreLmm29m4cKFdO3alU8//ZQuXbowfPhw5syZw5gxY5g5cyZnn312q00CEKFEoKYhacsa+809DLt27WLFihWcdtppQGZgtiOPPBKAAQMGcN555zFmzBjGjBmzz2tt3LiRd999l5NOOgkzo7i4mBUrVvCFL3yBDRs2MHbsWCAzthBkxub/3ve+lxvKuiHDQZ922mm549yd6667jpdffplYLMaGDRvYuHEj8+fPr3OY6R/84AfcfvvtjBkzhvvuu4977rmnEb+plicyiaBaiUAkVO5Ov379ePXVV/fYN2fOHF5++WWeeuopbrnlFt588816r/XII4+wefPm3Hj827ZtY8aMGUyZUv+sabXlDwdde3jn/IHgHnroISorK1m8eDHFxcX06tWr3uGghw0bRkVFBQsWLCCVSvHlL3+5UXG1NJF5fDT3HkG7yBRZpFm1b9+eysrKXCJIJBKsXLmSdDrNunXrGDFiBLfddhtbt26lqqpqr0NJQ6ZZ6Nlnn80NB52dxaxLly706NGDJ554AsjUQnbs2MFpp53Gfffdx44dmZlv6xoOOn/qyNq2bt3K4YcfTnFxMS+++CIffPABwF6HmQb47ne/y3e+850mHQW0UCLzqZjtLFaNQCQcsViMxx57jJ/+9KeUlpYycOBAFi5cSCqV4vzzz6d///4MGjSIK664goMPPpizzjqLWbNmMXDgwN1G0qyoqOCDDz7IDckM0Lt3bw466CBee+01HnjgAe68804GDBjA0KFD+fjjjxk5ciSjRo2irKyMgQMH5qahvOaaa7j77rsZNGhQbn7kupx33nmUl5fTv39/pk+fnhvyem/DTGfP2bx5c2747dYsMsNQ/+/Kj5n1xgbunDCI4nhk8p+0YRqGurAee+wxnnzySR544IFCh7KHxg5DHWofgZmNBO4A4sAf3f3WWvu/BvwGGACMd/e9190O0Df7fZZv9vtsWJcXkQi5/PLLeeaZZ5g7d26hQ2kSoSUCM4sDdwGnAeuBRWY2291X5R32ITARaPhbKCIiBfbb3/620CE0qTBrBEOANe6+FsDMZgKjgVwicPeKYF86xDhE2ix3x8wKHYa0IPvT3B9mY3l3YF3e+vpgW6OZ2cVmVm5m5ZWVlU0SnEhr16FDBzZt2rRf/+NL2+TubNq0Kfd+RUO1ivcI3H0aMA0yncUFDkekRejRowfr169HX44kX4cOHejRo0ejzgkzEWwAeuat9wi2iUgTKC4uzr1wJXIgwmwaWgT0MbPeZtYOGA/MDvF+IiKyH0JLBO6eBC4D5gFvAY+4+0ozu8nMRgGY2Qlmth44B/iDma0MKx4REalbqH0E7j4XmFtr2w15y4vINBmJiEiBtLo3i82sEvhgP0/vCuz9PfO2SWWOBpU5Gg6kzF9w92517Wh1ieBAmFn53l6xbqtU5mhQmaMhrDJr0B0RkYhTIhARibioJYJphQ6gAFTmaFCZoyGUMkeqj0BERPYUtRqBiIjUokQgIhJxkUgEZjbSzFab2Roza9zs1y2Ymd1rZn83sxV52w41s+fM7N3g30OC7WZmdwa/g+VmdnzhIt9/ZtbTzF40s1VmttLMrgy2t9lym1kHM3vdzJYFZf73YHtvM3stKNvDwVAumFn7YH1NsL9XQQtwAMwsbmZvmNnTwXqbLrOZVZjZm2a21MzKg22h/223+USQN0HO6UBfYIKZ9S1sVE3mfmBkrW1TgBfcvQ/wQrAOmfL3CX4uBu5uphibWhL4kbv3BU4Efhj892zL5d4FfN3dS4GBwEgzOxG4DfhPd/8SsBn4fnD894HNwfb/DI5rra4kM0RNVhTKPMLdB+a9LxD+37a7t+kf4KvAvLz1a4FrCx1XE5avF7Aib301cGSwfCSwOlj+AzChruNa8w/wJJlZ8CJRbqATsAT4Cpk3TIuC7bm/czLje301WC4KjrNCx74fZe0RfPB9HXgasAiUuQLoWmtb6H/bbb5GQBNOkNNKHOHuHwXLHwNHBMtt7vcQVP8HAa/RxssdNJEsBf4OPAe8B2zxzOCOsHu5cmUO9m8FDmvWgJvGb4CfANkZDA+j7ZfZgf81s8VmdnGwLfS/7VYxMY3sH3d3M2uTzwebWQnwZ2Cyu2/Ln66xLZbb3VPAQDM7GJgFHFvYiMJlZmcCf3f3xWY2vMDhNKeT3H2DmR0OPGdmb+fvDOtvOwo1gqhNkLPRzI4ECP79e7C9zfwezKyYTBJ4yN0fDza3+XIDuPsW4EUyzSIHm1n2y1x+uXJlDvYfBGxq3kgP2DBglJlVADPJNA/dQdsuM+6+Ifj372QS/hCa4W87CokgahPkzAYuCJYvINOGnt3+3eBJgxOBrXnVzVbDMl/9/wS85e6/ztvVZsttZt2CmgBm1pFMn8hbZBLCt4PDapc5+7v4NjDfg0bk1sLdr3X3Hu7ei8z/s/Pd/TzacJnNrLOZdckuA98EVtAcf9uF7hxppg6YbwHvkGlXvb7Q8TRhuWYAHwEJMu2D3yfTLvoC8C7wPHBocKyReXrqPeBNoKzQ8e9nmU8i0466HFga/HyrLZcbGAC8EZR5BXBDsP2LwOvAGuBRoH2wvUOwvibY/8VCl+EAyz8ceLqtlzko27LgZ2X2s6o5/rY1xISISMRFoWlIRETqoUQgIhJxSgQiIhGnRCAiEnFKBCIiEadEIFKLmaWC0R+zP002Yq2Z9bK80WJFWgINMSGyp53uPrDQQYg0F9UIRBooGCv+9mC8+NfN7EvB9l5mNj8YE/4FM/t8sP0IM5sVzCOwzMyGBpeKm9k9wdwC/xu8LSxSMEoEInvqWKtp6Ny8fVvdvT/wX2RGxwT4LfDf7j4AeAi4M9h+J/CSZ+YROJ7M26KQGT/+LnfvB2wBxoVaGpF90JvFIrWYWZW7l9SxvYLMBDFrg4HvPnb3w8zsEzLjwCeC7R+5e1czqwR6uPuuvGv0Ap7zzCQjmNlPgWJ3v7kZiiZSJ9UIRBrH97LcGLvyllOor04KTIlApHHOzfv31WB5IZkRMgHOA14Jll8AJkFuYpmDmitIkcbQNxGRPXUMZgPLetbds4+QHmJmy8l8q58QbLscuM/MfgxUAt8Ltl8JTDOz75P55j+JzGixIi2K+ghEGijoIyhz908KHYtIU1LTkIhIxKlGICIScaoRiIhEnBKBiEjEKRGIiEScEoGISMQpEYiIRNz/B2lWRUKgOTUMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a custom loss function\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Your custom loss calculation\n",
    "        loss = torch.mean(torch.abs(y_pred - y_true))  # Example: Mean absolute error\n",
    "        return loss\n",
    "\n",
    "# Define a custom logistic regression class\n",
    "class CustomLogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(CustomLogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "# Split the dataset into features (X) and labels (y)\n",
    "X = df['Review']\n",
    "y = df['Category']\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Vectorize the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train_tensor = Variable(torch.Tensor(X_train_tfidf.toarray()))\n",
    "y_train_tensor = Variable(torch.Tensor(y_train.values).view(-1, 1))\n",
    "X_val_tensor = Variable(torch.Tensor(X_val_tfidf.toarray()))\n",
    "y_val_tensor = Variable(torch.Tensor(y_val.values).view(-1, 1))\n",
    "X_test_tensor = Variable(torch.Tensor(X_test_tfidf.toarray()))\n",
    "y_test_tensor = Variable(torch.Tensor(y_test.values).view(-1, 1))\n",
    "\n",
    "# Initialize the custom logistic regression model\n",
    "input_size = X_train_tfidf.shape[1]\n",
    "model = CustomLogisticRegression(input_size)\n",
    "\n",
    "# Define the custom loss function\n",
    "custom_loss = CustomLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 500\n",
    "\n",
    "# Lists to store training, validation, and test loss, accuracy for each epoch\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Training loop for multiple epochs\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = custom_loss(outputs, y_train_tensor)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Evaluate on training set\n",
    "    with torch.no_grad():\n",
    "        train_predictions = (outputs > 0.5).float()\n",
    "        train_accuracy = accuracy_score(y_train_tensor.numpy(), train_predictions.numpy())\n",
    "        train_losses.append(loss.item())\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        val_loss = custom_loss(val_outputs, y_val_tensor)\n",
    "        val_predictions = (val_outputs > 0.5).float()\n",
    "        val_accuracy = accuracy_score(y_val_tensor.numpy(), val_predictions.numpy())\n",
    "        val_losses.append(val_loss.item())\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test_tensor)\n",
    "        test_loss = custom_loss(test_outputs, y_test_tensor)\n",
    "        test_predictions = (test_outputs > 0.5).float()\n",
    "        test_accuracy = accuracy_score(y_test_tensor.numpy(), test_predictions.numpy())\n",
    "        test_losses.append(test_loss.item())\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} - \"\n",
    "          f\"Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, Test Loss: {test_loss.item():.4f}, \"\n",
    "          f\"Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}, Test Acc: {test_accuracy:.4f}\")\n",
    "\n",
    "# Plot training, validation, and test loss\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "plt.plot(range(1, num_epochs + 1), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('Log Reg(NN-MAEloss): epoch_vs_loss.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot training, validation, and test accuracy\n",
    "plt.plot(range(1, num_epochs + 1), train_accuracies, label='Training Accuracy')\n",
    "plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy')\n",
    "plt.plot(range(1, num_epochs + 1), test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('Log Reg(NN-MAEloss): epoch_vs_accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39a9a99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 - Train Loss: 0.4742, Val Loss: 0.4732, Test Loss: 0.4731, Train Acc: 0.1186, Val Acc: 0.2123, Test Acc: 0.2154\n",
      "Epoch 2/500 - Train Loss: 0.4732, Val Loss: 0.4721, Test Loss: 0.4721, Train Acc: 0.2145, Val Acc: 0.3857, Test Acc: 0.3919\n",
      "Epoch 3/500 - Train Loss: 0.4721, Val Loss: 0.4711, Test Loss: 0.4710, Train Acc: 0.3880, Val Acc: 0.6117, Test Acc: 0.6218\n",
      "Epoch 4/500 - Train Loss: 0.4710, Val Loss: 0.4700, Test Loss: 0.4700, Train Acc: 0.6073, Val Acc: 0.7899, Test Acc: 0.7886\n",
      "Epoch 5/500 - Train Loss: 0.4700, Val Loss: 0.4690, Test Loss: 0.4689, Train Acc: 0.7876, Val Acc: 0.8839, Test Acc: 0.8835\n",
      "Epoch 6/500 - Train Loss: 0.4689, Val Loss: 0.4679, Test Loss: 0.4679, Train Acc: 0.8832, Val Acc: 0.9144, Test Acc: 0.9148\n",
      "Epoch 7/500 - Train Loss: 0.4679, Val Loss: 0.4669, Test Loss: 0.4668, Train Acc: 0.9176, Val Acc: 0.9223, Test Acc: 0.9232\n",
      "Epoch 8/500 - Train Loss: 0.4668, Val Loss: 0.4658, Test Loss: 0.4658, Train Acc: 0.9252, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 9/500 - Train Loss: 0.4658, Val Loss: 0.4648, Test Loss: 0.4648, Train Acc: 0.9259, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 10/500 - Train Loss: 0.4648, Val Loss: 0.4638, Test Loss: 0.4637, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 11/500 - Train Loss: 0.4637, Val Loss: 0.4628, Test Loss: 0.4627, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 12/500 - Train Loss: 0.4627, Val Loss: 0.4618, Test Loss: 0.4617, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 13/500 - Train Loss: 0.4617, Val Loss: 0.4607, Test Loss: 0.4607, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 14/500 - Train Loss: 0.4607, Val Loss: 0.4597, Test Loss: 0.4596, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 15/500 - Train Loss: 0.4596, Val Loss: 0.4587, Test Loss: 0.4586, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 16/500 - Train Loss: 0.4586, Val Loss: 0.4577, Test Loss: 0.4576, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 17/500 - Train Loss: 0.4576, Val Loss: 0.4567, Test Loss: 0.4566, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 18/500 - Train Loss: 0.4566, Val Loss: 0.4557, Test Loss: 0.4556, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 19/500 - Train Loss: 0.4556, Val Loss: 0.4547, Test Loss: 0.4546, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 20/500 - Train Loss: 0.4546, Val Loss: 0.4538, Test Loss: 0.4536, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 21/500 - Train Loss: 0.4536, Val Loss: 0.4528, Test Loss: 0.4527, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 22/500 - Train Loss: 0.4526, Val Loss: 0.4518, Test Loss: 0.4517, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 23/500 - Train Loss: 0.4516, Val Loss: 0.4508, Test Loss: 0.4507, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 24/500 - Train Loss: 0.4507, Val Loss: 0.4499, Test Loss: 0.4497, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 25/500 - Train Loss: 0.4497, Val Loss: 0.4489, Test Loss: 0.4488, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 26/500 - Train Loss: 0.4487, Val Loss: 0.4479, Test Loss: 0.4478, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 27/500 - Train Loss: 0.4477, Val Loss: 0.4470, Test Loss: 0.4468, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 28/500 - Train Loss: 0.4468, Val Loss: 0.4460, Test Loss: 0.4459, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 29/500 - Train Loss: 0.4458, Val Loss: 0.4451, Test Loss: 0.4449, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 30/500 - Train Loss: 0.4449, Val Loss: 0.4441, Test Loss: 0.4440, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 31/500 - Train Loss: 0.4439, Val Loss: 0.4432, Test Loss: 0.4430, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 32/500 - Train Loss: 0.4430, Val Loss: 0.4422, Test Loss: 0.4421, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 33/500 - Train Loss: 0.4420, Val Loss: 0.4413, Test Loss: 0.4411, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 34/500 - Train Loss: 0.4411, Val Loss: 0.4404, Test Loss: 0.4402, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 35/500 - Train Loss: 0.4401, Val Loss: 0.4394, Test Loss: 0.4393, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 36/500 - Train Loss: 0.4392, Val Loss: 0.4385, Test Loss: 0.4383, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 37/500 - Train Loss: 0.4383, Val Loss: 0.4376, Test Loss: 0.4374, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 38/500 - Train Loss: 0.4373, Val Loss: 0.4367, Test Loss: 0.4365, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 39/500 - Train Loss: 0.4364, Val Loss: 0.4358, Test Loss: 0.4356, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 40/500 - Train Loss: 0.4355, Val Loss: 0.4348, Test Loss: 0.4346, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 41/500 - Train Loss: 0.4346, Val Loss: 0.4339, Test Loss: 0.4337, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 42/500 - Train Loss: 0.4337, Val Loss: 0.4330, Test Loss: 0.4328, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 43/500 - Train Loss: 0.4327, Val Loss: 0.4321, Test Loss: 0.4319, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 44/500 - Train Loss: 0.4318, Val Loss: 0.4312, Test Loss: 0.4310, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 45/500 - Train Loss: 0.4309, Val Loss: 0.4303, Test Loss: 0.4301, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 46/500 - Train Loss: 0.4300, Val Loss: 0.4295, Test Loss: 0.4292, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 47/500 - Train Loss: 0.4291, Val Loss: 0.4286, Test Loss: 0.4283, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 48/500 - Train Loss: 0.4282, Val Loss: 0.4277, Test Loss: 0.4275, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 49/500 - Train Loss: 0.4274, Val Loss: 0.4268, Test Loss: 0.4266, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 50/500 - Train Loss: 0.4265, Val Loss: 0.4259, Test Loss: 0.4257, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 51/500 - Train Loss: 0.4256, Val Loss: 0.4251, Test Loss: 0.4248, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 52/500 - Train Loss: 0.4247, Val Loss: 0.4242, Test Loss: 0.4240, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 53/500 - Train Loss: 0.4238, Val Loss: 0.4233, Test Loss: 0.4231, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 54/500 - Train Loss: 0.4230, Val Loss: 0.4225, Test Loss: 0.4222, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 55/500 - Train Loss: 0.4221, Val Loss: 0.4216, Test Loss: 0.4214, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 56/500 - Train Loss: 0.4212, Val Loss: 0.4208, Test Loss: 0.4205, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 57/500 - Train Loss: 0.4204, Val Loss: 0.4199, Test Loss: 0.4197, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 58/500 - Train Loss: 0.4195, Val Loss: 0.4191, Test Loss: 0.4188, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 59/500 - Train Loss: 0.4187, Val Loss: 0.4182, Test Loss: 0.4180, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 60/500 - Train Loss: 0.4178, Val Loss: 0.4174, Test Loss: 0.4171, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 61/500 - Train Loss: 0.4170, Val Loss: 0.4166, Test Loss: 0.4163, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 62/500 - Train Loss: 0.4161, Val Loss: 0.4157, Test Loss: 0.4154, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 63/500 - Train Loss: 0.4153, Val Loss: 0.4149, Test Loss: 0.4146, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 64/500 - Train Loss: 0.4145, Val Loss: 0.4141, Test Loss: 0.4138, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 65/500 - Train Loss: 0.4136, Val Loss: 0.4132, Test Loss: 0.4129, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 66/500 - Train Loss: 0.4128, Val Loss: 0.4124, Test Loss: 0.4121, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 67/500 - Train Loss: 0.4120, Val Loss: 0.4116, Test Loss: 0.4113, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 68/500 - Train Loss: 0.4111, Val Loss: 0.4108, Test Loss: 0.4105, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 69/500 - Train Loss: 0.4103, Val Loss: 0.4100, Test Loss: 0.4097, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 70/500 - Train Loss: 0.4095, Val Loss: 0.4092, Test Loss: 0.4089, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/500 - Train Loss: 0.4087, Val Loss: 0.4084, Test Loss: 0.4080, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 72/500 - Train Loss: 0.4079, Val Loss: 0.4076, Test Loss: 0.4072, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 73/500 - Train Loss: 0.4071, Val Loss: 0.4068, Test Loss: 0.4064, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 74/500 - Train Loss: 0.4063, Val Loss: 0.4060, Test Loss: 0.4056, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 75/500 - Train Loss: 0.4055, Val Loss: 0.4052, Test Loss: 0.4049, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 76/500 - Train Loss: 0.4047, Val Loss: 0.4044, Test Loss: 0.4041, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 77/500 - Train Loss: 0.4039, Val Loss: 0.4036, Test Loss: 0.4033, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 78/500 - Train Loss: 0.4031, Val Loss: 0.4028, Test Loss: 0.4025, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 79/500 - Train Loss: 0.4023, Val Loss: 0.4021, Test Loss: 0.4017, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 80/500 - Train Loss: 0.4015, Val Loss: 0.4013, Test Loss: 0.4009, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 81/500 - Train Loss: 0.4007, Val Loss: 0.4005, Test Loss: 0.4002, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 82/500 - Train Loss: 0.4000, Val Loss: 0.3997, Test Loss: 0.3994, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 83/500 - Train Loss: 0.3992, Val Loss: 0.3990, Test Loss: 0.3986, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 84/500 - Train Loss: 0.3984, Val Loss: 0.3982, Test Loss: 0.3978, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 85/500 - Train Loss: 0.3976, Val Loss: 0.3975, Test Loss: 0.3971, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 86/500 - Train Loss: 0.3969, Val Loss: 0.3967, Test Loss: 0.3963, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 87/500 - Train Loss: 0.3961, Val Loss: 0.3960, Test Loss: 0.3956, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 88/500 - Train Loss: 0.3954, Val Loss: 0.3952, Test Loss: 0.3948, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 89/500 - Train Loss: 0.3946, Val Loss: 0.3945, Test Loss: 0.3941, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 90/500 - Train Loss: 0.3938, Val Loss: 0.3937, Test Loss: 0.3933, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 91/500 - Train Loss: 0.3931, Val Loss: 0.3930, Test Loss: 0.3926, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 92/500 - Train Loss: 0.3924, Val Loss: 0.3922, Test Loss: 0.3918, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 93/500 - Train Loss: 0.3916, Val Loss: 0.3915, Test Loss: 0.3911, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 94/500 - Train Loss: 0.3909, Val Loss: 0.3908, Test Loss: 0.3904, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 95/500 - Train Loss: 0.3901, Val Loss: 0.3900, Test Loss: 0.3896, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 96/500 - Train Loss: 0.3894, Val Loss: 0.3893, Test Loss: 0.3889, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 97/500 - Train Loss: 0.3887, Val Loss: 0.3886, Test Loss: 0.3882, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 98/500 - Train Loss: 0.3879, Val Loss: 0.3879, Test Loss: 0.3874, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 99/500 - Train Loss: 0.3872, Val Loss: 0.3872, Test Loss: 0.3867, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 100/500 - Train Loss: 0.3865, Val Loss: 0.3864, Test Loss: 0.3860, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 101/500 - Train Loss: 0.3858, Val Loss: 0.3857, Test Loss: 0.3853, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 102/500 - Train Loss: 0.3850, Val Loss: 0.3850, Test Loss: 0.3846, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 103/500 - Train Loss: 0.3843, Val Loss: 0.3843, Test Loss: 0.3839, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 104/500 - Train Loss: 0.3836, Val Loss: 0.3836, Test Loss: 0.3832, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 105/500 - Train Loss: 0.3829, Val Loss: 0.3829, Test Loss: 0.3825, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 106/500 - Train Loss: 0.3822, Val Loss: 0.3822, Test Loss: 0.3818, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 107/500 - Train Loss: 0.3815, Val Loss: 0.3815, Test Loss: 0.3811, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 108/500 - Train Loss: 0.3808, Val Loss: 0.3808, Test Loss: 0.3804, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 109/500 - Train Loss: 0.3801, Val Loss: 0.3801, Test Loss: 0.3797, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 110/500 - Train Loss: 0.3794, Val Loss: 0.3795, Test Loss: 0.3790, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 111/500 - Train Loss: 0.3787, Val Loss: 0.3788, Test Loss: 0.3783, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 112/500 - Train Loss: 0.3780, Val Loss: 0.3781, Test Loss: 0.3776, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 113/500 - Train Loss: 0.3773, Val Loss: 0.3774, Test Loss: 0.3769, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 114/500 - Train Loss: 0.3767, Val Loss: 0.3767, Test Loss: 0.3763, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 115/500 - Train Loss: 0.3760, Val Loss: 0.3761, Test Loss: 0.3756, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 116/500 - Train Loss: 0.3753, Val Loss: 0.3754, Test Loss: 0.3749, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 117/500 - Train Loss: 0.3746, Val Loss: 0.3747, Test Loss: 0.3742, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 118/500 - Train Loss: 0.3740, Val Loss: 0.3741, Test Loss: 0.3736, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 119/500 - Train Loss: 0.3733, Val Loss: 0.3734, Test Loss: 0.3729, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 120/500 - Train Loss: 0.3726, Val Loss: 0.3728, Test Loss: 0.3722, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 121/500 - Train Loss: 0.3720, Val Loss: 0.3721, Test Loss: 0.3716, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 122/500 - Train Loss: 0.3713, Val Loss: 0.3714, Test Loss: 0.3709, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 123/500 - Train Loss: 0.3706, Val Loss: 0.3708, Test Loss: 0.3703, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 124/500 - Train Loss: 0.3700, Val Loss: 0.3701, Test Loss: 0.3696, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 125/500 - Train Loss: 0.3693, Val Loss: 0.3695, Test Loss: 0.3690, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 126/500 - Train Loss: 0.3687, Val Loss: 0.3689, Test Loss: 0.3683, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 127/500 - Train Loss: 0.3680, Val Loss: 0.3682, Test Loss: 0.3677, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 128/500 - Train Loss: 0.3674, Val Loss: 0.3676, Test Loss: 0.3670, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 129/500 - Train Loss: 0.3667, Val Loss: 0.3669, Test Loss: 0.3664, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 130/500 - Train Loss: 0.3661, Val Loss: 0.3663, Test Loss: 0.3658, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 131/500 - Train Loss: 0.3655, Val Loss: 0.3657, Test Loss: 0.3651, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 132/500 - Train Loss: 0.3648, Val Loss: 0.3651, Test Loss: 0.3645, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 133/500 - Train Loss: 0.3642, Val Loss: 0.3644, Test Loss: 0.3639, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 134/500 - Train Loss: 0.3636, Val Loss: 0.3638, Test Loss: 0.3633, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 135/500 - Train Loss: 0.3629, Val Loss: 0.3632, Test Loss: 0.3626, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 136/500 - Train Loss: 0.3623, Val Loss: 0.3626, Test Loss: 0.3620, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 137/500 - Train Loss: 0.3617, Val Loss: 0.3620, Test Loss: 0.3614, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 138/500 - Train Loss: 0.3611, Val Loss: 0.3614, Test Loss: 0.3608, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 139/500 - Train Loss: 0.3604, Val Loss: 0.3607, Test Loss: 0.3602, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 140/500 - Train Loss: 0.3598, Val Loss: 0.3601, Test Loss: 0.3596, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/500 - Train Loss: 0.3592, Val Loss: 0.3595, Test Loss: 0.3589, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 142/500 - Train Loss: 0.3586, Val Loss: 0.3589, Test Loss: 0.3583, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 143/500 - Train Loss: 0.3580, Val Loss: 0.3583, Test Loss: 0.3577, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 144/500 - Train Loss: 0.3574, Val Loss: 0.3577, Test Loss: 0.3571, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 145/500 - Train Loss: 0.3568, Val Loss: 0.3571, Test Loss: 0.3565, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 146/500 - Train Loss: 0.3562, Val Loss: 0.3565, Test Loss: 0.3559, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 147/500 - Train Loss: 0.3556, Val Loss: 0.3560, Test Loss: 0.3554, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 148/500 - Train Loss: 0.3550, Val Loss: 0.3554, Test Loss: 0.3548, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 149/500 - Train Loss: 0.3544, Val Loss: 0.3548, Test Loss: 0.3542, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 150/500 - Train Loss: 0.3538, Val Loss: 0.3542, Test Loss: 0.3536, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 151/500 - Train Loss: 0.3532, Val Loss: 0.3536, Test Loss: 0.3530, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 152/500 - Train Loss: 0.3526, Val Loss: 0.3530, Test Loss: 0.3524, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 153/500 - Train Loss: 0.3520, Val Loss: 0.3525, Test Loss: 0.3518, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 154/500 - Train Loss: 0.3515, Val Loss: 0.3519, Test Loss: 0.3513, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 155/500 - Train Loss: 0.3509, Val Loss: 0.3513, Test Loss: 0.3507, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 156/500 - Train Loss: 0.3503, Val Loss: 0.3507, Test Loss: 0.3501, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 157/500 - Train Loss: 0.3497, Val Loss: 0.3502, Test Loss: 0.3495, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 158/500 - Train Loss: 0.3492, Val Loss: 0.3496, Test Loss: 0.3490, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 159/500 - Train Loss: 0.3486, Val Loss: 0.3491, Test Loss: 0.3484, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 160/500 - Train Loss: 0.3480, Val Loss: 0.3485, Test Loss: 0.3478, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 161/500 - Train Loss: 0.3475, Val Loss: 0.3479, Test Loss: 0.3473, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 162/500 - Train Loss: 0.3469, Val Loss: 0.3474, Test Loss: 0.3467, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 163/500 - Train Loss: 0.3463, Val Loss: 0.3468, Test Loss: 0.3462, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 164/500 - Train Loss: 0.3458, Val Loss: 0.3463, Test Loss: 0.3456, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 165/500 - Train Loss: 0.3452, Val Loss: 0.3457, Test Loss: 0.3451, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 166/500 - Train Loss: 0.3447, Val Loss: 0.3452, Test Loss: 0.3445, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 167/500 - Train Loss: 0.3441, Val Loss: 0.3446, Test Loss: 0.3440, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 168/500 - Train Loss: 0.3436, Val Loss: 0.3441, Test Loss: 0.3434, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 169/500 - Train Loss: 0.3430, Val Loss: 0.3435, Test Loss: 0.3429, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 170/500 - Train Loss: 0.3425, Val Loss: 0.3430, Test Loss: 0.3423, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 171/500 - Train Loss: 0.3419, Val Loss: 0.3425, Test Loss: 0.3418, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 172/500 - Train Loss: 0.3414, Val Loss: 0.3419, Test Loss: 0.3413, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 173/500 - Train Loss: 0.3408, Val Loss: 0.3414, Test Loss: 0.3407, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 174/500 - Train Loss: 0.3403, Val Loss: 0.3409, Test Loss: 0.3402, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 175/500 - Train Loss: 0.3398, Val Loss: 0.3404, Test Loss: 0.3397, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 176/500 - Train Loss: 0.3392, Val Loss: 0.3398, Test Loss: 0.3391, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 177/500 - Train Loss: 0.3387, Val Loss: 0.3393, Test Loss: 0.3386, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 178/500 - Train Loss: 0.3382, Val Loss: 0.3388, Test Loss: 0.3381, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 179/500 - Train Loss: 0.3376, Val Loss: 0.3383, Test Loss: 0.3376, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 180/500 - Train Loss: 0.3371, Val Loss: 0.3377, Test Loss: 0.3370, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 181/500 - Train Loss: 0.3366, Val Loss: 0.3372, Test Loss: 0.3365, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 182/500 - Train Loss: 0.3361, Val Loss: 0.3367, Test Loss: 0.3360, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 183/500 - Train Loss: 0.3356, Val Loss: 0.3362, Test Loss: 0.3355, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 184/500 - Train Loss: 0.3350, Val Loss: 0.3357, Test Loss: 0.3350, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 185/500 - Train Loss: 0.3345, Val Loss: 0.3352, Test Loss: 0.3345, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 186/500 - Train Loss: 0.3340, Val Loss: 0.3347, Test Loss: 0.3340, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 187/500 - Train Loss: 0.3335, Val Loss: 0.3342, Test Loss: 0.3335, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 188/500 - Train Loss: 0.3330, Val Loss: 0.3337, Test Loss: 0.3329, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 189/500 - Train Loss: 0.3325, Val Loss: 0.3332, Test Loss: 0.3324, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 190/500 - Train Loss: 0.3320, Val Loss: 0.3327, Test Loss: 0.3319, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 191/500 - Train Loss: 0.3315, Val Loss: 0.3322, Test Loss: 0.3314, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 192/500 - Train Loss: 0.3310, Val Loss: 0.3317, Test Loss: 0.3310, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 193/500 - Train Loss: 0.3305, Val Loss: 0.3312, Test Loss: 0.3305, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 194/500 - Train Loss: 0.3300, Val Loss: 0.3307, Test Loss: 0.3300, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 195/500 - Train Loss: 0.3295, Val Loss: 0.3302, Test Loss: 0.3295, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 196/500 - Train Loss: 0.3290, Val Loss: 0.3297, Test Loss: 0.3290, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 197/500 - Train Loss: 0.3285, Val Loss: 0.3293, Test Loss: 0.3285, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 198/500 - Train Loss: 0.3280, Val Loss: 0.3288, Test Loss: 0.3280, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 199/500 - Train Loss: 0.3275, Val Loss: 0.3283, Test Loss: 0.3275, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 200/500 - Train Loss: 0.3270, Val Loss: 0.3278, Test Loss: 0.3271, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 201/500 - Train Loss: 0.3266, Val Loss: 0.3273, Test Loss: 0.3266, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 202/500 - Train Loss: 0.3261, Val Loss: 0.3269, Test Loss: 0.3261, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 203/500 - Train Loss: 0.3256, Val Loss: 0.3264, Test Loss: 0.3256, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 204/500 - Train Loss: 0.3251, Val Loss: 0.3259, Test Loss: 0.3251, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 205/500 - Train Loss: 0.3246, Val Loss: 0.3255, Test Loss: 0.3247, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 206/500 - Train Loss: 0.3242, Val Loss: 0.3250, Test Loss: 0.3242, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 207/500 - Train Loss: 0.3237, Val Loss: 0.3245, Test Loss: 0.3237, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 208/500 - Train Loss: 0.3232, Val Loss: 0.3241, Test Loss: 0.3233, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 209/500 - Train Loss: 0.3228, Val Loss: 0.3236, Test Loss: 0.3228, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 210/500 - Train Loss: 0.3223, Val Loss: 0.3231, Test Loss: 0.3223, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211/500 - Train Loss: 0.3218, Val Loss: 0.3227, Test Loss: 0.3219, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 212/500 - Train Loss: 0.3214, Val Loss: 0.3222, Test Loss: 0.3214, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 213/500 - Train Loss: 0.3209, Val Loss: 0.3218, Test Loss: 0.3210, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 214/500 - Train Loss: 0.3205, Val Loss: 0.3213, Test Loss: 0.3205, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 215/500 - Train Loss: 0.3200, Val Loss: 0.3209, Test Loss: 0.3201, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 216/500 - Train Loss: 0.3195, Val Loss: 0.3204, Test Loss: 0.3196, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 217/500 - Train Loss: 0.3191, Val Loss: 0.3200, Test Loss: 0.3192, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 218/500 - Train Loss: 0.3186, Val Loss: 0.3195, Test Loss: 0.3187, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 219/500 - Train Loss: 0.3182, Val Loss: 0.3191, Test Loss: 0.3183, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 220/500 - Train Loss: 0.3177, Val Loss: 0.3186, Test Loss: 0.3178, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 221/500 - Train Loss: 0.3173, Val Loss: 0.3182, Test Loss: 0.3174, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 222/500 - Train Loss: 0.3168, Val Loss: 0.3178, Test Loss: 0.3169, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 223/500 - Train Loss: 0.3164, Val Loss: 0.3173, Test Loss: 0.3165, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 224/500 - Train Loss: 0.3160, Val Loss: 0.3169, Test Loss: 0.3161, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 225/500 - Train Loss: 0.3155, Val Loss: 0.3165, Test Loss: 0.3156, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 226/500 - Train Loss: 0.3151, Val Loss: 0.3160, Test Loss: 0.3152, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 227/500 - Train Loss: 0.3146, Val Loss: 0.3156, Test Loss: 0.3148, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 228/500 - Train Loss: 0.3142, Val Loss: 0.3152, Test Loss: 0.3143, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 229/500 - Train Loss: 0.3138, Val Loss: 0.3147, Test Loss: 0.3139, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 230/500 - Train Loss: 0.3133, Val Loss: 0.3143, Test Loss: 0.3135, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 231/500 - Train Loss: 0.3129, Val Loss: 0.3139, Test Loss: 0.3130, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 232/500 - Train Loss: 0.3125, Val Loss: 0.3135, Test Loss: 0.3126, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 233/500 - Train Loss: 0.3121, Val Loss: 0.3131, Test Loss: 0.3122, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 234/500 - Train Loss: 0.3116, Val Loss: 0.3126, Test Loss: 0.3118, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 235/500 - Train Loss: 0.3112, Val Loss: 0.3122, Test Loss: 0.3113, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 236/500 - Train Loss: 0.3108, Val Loss: 0.3118, Test Loss: 0.3109, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 237/500 - Train Loss: 0.3104, Val Loss: 0.3114, Test Loss: 0.3105, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 238/500 - Train Loss: 0.3099, Val Loss: 0.3110, Test Loss: 0.3101, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 239/500 - Train Loss: 0.3095, Val Loss: 0.3106, Test Loss: 0.3097, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 240/500 - Train Loss: 0.3091, Val Loss: 0.3102, Test Loss: 0.3093, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 241/500 - Train Loss: 0.3087, Val Loss: 0.3097, Test Loss: 0.3089, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 242/500 - Train Loss: 0.3083, Val Loss: 0.3093, Test Loss: 0.3085, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 243/500 - Train Loss: 0.3079, Val Loss: 0.3089, Test Loss: 0.3080, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 244/500 - Train Loss: 0.3075, Val Loss: 0.3085, Test Loss: 0.3076, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 245/500 - Train Loss: 0.3071, Val Loss: 0.3081, Test Loss: 0.3072, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 246/500 - Train Loss: 0.3067, Val Loss: 0.3077, Test Loss: 0.3068, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 247/500 - Train Loss: 0.3062, Val Loss: 0.3073, Test Loss: 0.3064, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 248/500 - Train Loss: 0.3058, Val Loss: 0.3069, Test Loss: 0.3060, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 249/500 - Train Loss: 0.3054, Val Loss: 0.3065, Test Loss: 0.3056, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 250/500 - Train Loss: 0.3050, Val Loss: 0.3061, Test Loss: 0.3052, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 251/500 - Train Loss: 0.3046, Val Loss: 0.3058, Test Loss: 0.3048, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 252/500 - Train Loss: 0.3042, Val Loss: 0.3054, Test Loss: 0.3045, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 253/500 - Train Loss: 0.3039, Val Loss: 0.3050, Test Loss: 0.3041, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 254/500 - Train Loss: 0.3035, Val Loss: 0.3046, Test Loss: 0.3037, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 255/500 - Train Loss: 0.3031, Val Loss: 0.3042, Test Loss: 0.3033, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 256/500 - Train Loss: 0.3027, Val Loss: 0.3038, Test Loss: 0.3029, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 257/500 - Train Loss: 0.3023, Val Loss: 0.3034, Test Loss: 0.3025, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 258/500 - Train Loss: 0.3019, Val Loss: 0.3031, Test Loss: 0.3021, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 259/500 - Train Loss: 0.3015, Val Loss: 0.3027, Test Loss: 0.3017, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 260/500 - Train Loss: 0.3011, Val Loss: 0.3023, Test Loss: 0.3014, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 261/500 - Train Loss: 0.3007, Val Loss: 0.3019, Test Loss: 0.3010, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 262/500 - Train Loss: 0.3004, Val Loss: 0.3015, Test Loss: 0.3006, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 263/500 - Train Loss: 0.3000, Val Loss: 0.3012, Test Loss: 0.3002, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 264/500 - Train Loss: 0.2996, Val Loss: 0.3008, Test Loss: 0.2998, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 265/500 - Train Loss: 0.2992, Val Loss: 0.3004, Test Loss: 0.2995, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 266/500 - Train Loss: 0.2988, Val Loss: 0.3000, Test Loss: 0.2991, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 267/500 - Train Loss: 0.2985, Val Loss: 0.2997, Test Loss: 0.2987, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 268/500 - Train Loss: 0.2981, Val Loss: 0.2993, Test Loss: 0.2984, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 269/500 - Train Loss: 0.2977, Val Loss: 0.2989, Test Loss: 0.2980, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 270/500 - Train Loss: 0.2974, Val Loss: 0.2986, Test Loss: 0.2976, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 271/500 - Train Loss: 0.2970, Val Loss: 0.2982, Test Loss: 0.2973, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 272/500 - Train Loss: 0.2966, Val Loss: 0.2979, Test Loss: 0.2969, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 273/500 - Train Loss: 0.2962, Val Loss: 0.2975, Test Loss: 0.2965, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 274/500 - Train Loss: 0.2959, Val Loss: 0.2971, Test Loss: 0.2962, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 275/500 - Train Loss: 0.2955, Val Loss: 0.2968, Test Loss: 0.2958, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 276/500 - Train Loss: 0.2952, Val Loss: 0.2964, Test Loss: 0.2954, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 277/500 - Train Loss: 0.2948, Val Loss: 0.2961, Test Loss: 0.2951, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 278/500 - Train Loss: 0.2944, Val Loss: 0.2957, Test Loss: 0.2947, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 279/500 - Train Loss: 0.2941, Val Loss: 0.2954, Test Loss: 0.2944, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 280/500 - Train Loss: 0.2937, Val Loss: 0.2950, Test Loss: 0.2940, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/500 - Train Loss: 0.2934, Val Loss: 0.2947, Test Loss: 0.2937, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 282/500 - Train Loss: 0.2930, Val Loss: 0.2943, Test Loss: 0.2933, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 283/500 - Train Loss: 0.2927, Val Loss: 0.2940, Test Loss: 0.2930, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 284/500 - Train Loss: 0.2923, Val Loss: 0.2936, Test Loss: 0.2926, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 285/500 - Train Loss: 0.2919, Val Loss: 0.2933, Test Loss: 0.2923, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 286/500 - Train Loss: 0.2916, Val Loss: 0.2929, Test Loss: 0.2919, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 287/500 - Train Loss: 0.2913, Val Loss: 0.2926, Test Loss: 0.2916, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 288/500 - Train Loss: 0.2909, Val Loss: 0.2922, Test Loss: 0.2912, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 289/500 - Train Loss: 0.2906, Val Loss: 0.2919, Test Loss: 0.2909, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 290/500 - Train Loss: 0.2902, Val Loss: 0.2916, Test Loss: 0.2906, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 291/500 - Train Loss: 0.2899, Val Loss: 0.2912, Test Loss: 0.2902, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 292/500 - Train Loss: 0.2895, Val Loss: 0.2909, Test Loss: 0.2899, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 293/500 - Train Loss: 0.2892, Val Loss: 0.2905, Test Loss: 0.2895, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 294/500 - Train Loss: 0.2888, Val Loss: 0.2902, Test Loss: 0.2892, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 295/500 - Train Loss: 0.2885, Val Loss: 0.2899, Test Loss: 0.2889, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 296/500 - Train Loss: 0.2882, Val Loss: 0.2896, Test Loss: 0.2885, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 297/500 - Train Loss: 0.2878, Val Loss: 0.2892, Test Loss: 0.2882, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 298/500 - Train Loss: 0.2875, Val Loss: 0.2889, Test Loss: 0.2879, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 299/500 - Train Loss: 0.2872, Val Loss: 0.2886, Test Loss: 0.2875, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 300/500 - Train Loss: 0.2868, Val Loss: 0.2882, Test Loss: 0.2872, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 301/500 - Train Loss: 0.2865, Val Loss: 0.2879, Test Loss: 0.2869, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 302/500 - Train Loss: 0.2862, Val Loss: 0.2876, Test Loss: 0.2866, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 303/500 - Train Loss: 0.2859, Val Loss: 0.2873, Test Loss: 0.2862, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 304/500 - Train Loss: 0.2855, Val Loss: 0.2869, Test Loss: 0.2859, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 305/500 - Train Loss: 0.2852, Val Loss: 0.2866, Test Loss: 0.2856, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 306/500 - Train Loss: 0.2849, Val Loss: 0.2863, Test Loss: 0.2853, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 307/500 - Train Loss: 0.2845, Val Loss: 0.2860, Test Loss: 0.2849, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 308/500 - Train Loss: 0.2842, Val Loss: 0.2857, Test Loss: 0.2846, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 309/500 - Train Loss: 0.2839, Val Loss: 0.2854, Test Loss: 0.2843, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 310/500 - Train Loss: 0.2836, Val Loss: 0.2850, Test Loss: 0.2840, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 311/500 - Train Loss: 0.2833, Val Loss: 0.2847, Test Loss: 0.2837, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 312/500 - Train Loss: 0.2829, Val Loss: 0.2844, Test Loss: 0.2834, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 313/500 - Train Loss: 0.2826, Val Loss: 0.2841, Test Loss: 0.2830, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 314/500 - Train Loss: 0.2823, Val Loss: 0.2838, Test Loss: 0.2827, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 315/500 - Train Loss: 0.2820, Val Loss: 0.2835, Test Loss: 0.2824, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 316/500 - Train Loss: 0.2817, Val Loss: 0.2832, Test Loss: 0.2821, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 317/500 - Train Loss: 0.2814, Val Loss: 0.2829, Test Loss: 0.2818, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 318/500 - Train Loss: 0.2811, Val Loss: 0.2826, Test Loss: 0.2815, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 319/500 - Train Loss: 0.2808, Val Loss: 0.2823, Test Loss: 0.2812, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 320/500 - Train Loss: 0.2804, Val Loss: 0.2820, Test Loss: 0.2809, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 321/500 - Train Loss: 0.2801, Val Loss: 0.2816, Test Loss: 0.2806, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 322/500 - Train Loss: 0.2798, Val Loss: 0.2813, Test Loss: 0.2803, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 323/500 - Train Loss: 0.2795, Val Loss: 0.2810, Test Loss: 0.2800, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 324/500 - Train Loss: 0.2792, Val Loss: 0.2807, Test Loss: 0.2797, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 325/500 - Train Loss: 0.2789, Val Loss: 0.2805, Test Loss: 0.2794, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 326/500 - Train Loss: 0.2786, Val Loss: 0.2802, Test Loss: 0.2791, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 327/500 - Train Loss: 0.2783, Val Loss: 0.2799, Test Loss: 0.2788, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 328/500 - Train Loss: 0.2780, Val Loss: 0.2796, Test Loss: 0.2785, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 329/500 - Train Loss: 0.2777, Val Loss: 0.2793, Test Loss: 0.2782, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 330/500 - Train Loss: 0.2774, Val Loss: 0.2790, Test Loss: 0.2779, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 331/500 - Train Loss: 0.2771, Val Loss: 0.2787, Test Loss: 0.2776, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 332/500 - Train Loss: 0.2768, Val Loss: 0.2784, Test Loss: 0.2773, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 333/500 - Train Loss: 0.2765, Val Loss: 0.2781, Test Loss: 0.2770, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 334/500 - Train Loss: 0.2762, Val Loss: 0.2778, Test Loss: 0.2767, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 335/500 - Train Loss: 0.2759, Val Loss: 0.2775, Test Loss: 0.2764, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 336/500 - Train Loss: 0.2757, Val Loss: 0.2772, Test Loss: 0.2761, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 337/500 - Train Loss: 0.2754, Val Loss: 0.2770, Test Loss: 0.2758, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 338/500 - Train Loss: 0.2751, Val Loss: 0.2767, Test Loss: 0.2756, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 339/500 - Train Loss: 0.2748, Val Loss: 0.2764, Test Loss: 0.2753, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 340/500 - Train Loss: 0.2745, Val Loss: 0.2761, Test Loss: 0.2750, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 341/500 - Train Loss: 0.2742, Val Loss: 0.2758, Test Loss: 0.2747, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 342/500 - Train Loss: 0.2739, Val Loss: 0.2755, Test Loss: 0.2744, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 343/500 - Train Loss: 0.2736, Val Loss: 0.2753, Test Loss: 0.2741, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 344/500 - Train Loss: 0.2734, Val Loss: 0.2750, Test Loss: 0.2739, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 345/500 - Train Loss: 0.2731, Val Loss: 0.2747, Test Loss: 0.2736, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 346/500 - Train Loss: 0.2728, Val Loss: 0.2744, Test Loss: 0.2733, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 347/500 - Train Loss: 0.2725, Val Loss: 0.2742, Test Loss: 0.2730, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 348/500 - Train Loss: 0.2722, Val Loss: 0.2739, Test Loss: 0.2727, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 349/500 - Train Loss: 0.2720, Val Loss: 0.2736, Test Loss: 0.2725, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 350/500 - Train Loss: 0.2717, Val Loss: 0.2733, Test Loss: 0.2722, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351/500 - Train Loss: 0.2714, Val Loss: 0.2731, Test Loss: 0.2719, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 352/500 - Train Loss: 0.2711, Val Loss: 0.2728, Test Loss: 0.2716, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 353/500 - Train Loss: 0.2709, Val Loss: 0.2725, Test Loss: 0.2714, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 354/500 - Train Loss: 0.2706, Val Loss: 0.2723, Test Loss: 0.2711, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 355/500 - Train Loss: 0.2703, Val Loss: 0.2720, Test Loss: 0.2708, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 356/500 - Train Loss: 0.2700, Val Loss: 0.2717, Test Loss: 0.2706, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 357/500 - Train Loss: 0.2698, Val Loss: 0.2715, Test Loss: 0.2703, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 358/500 - Train Loss: 0.2695, Val Loss: 0.2712, Test Loss: 0.2700, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 359/500 - Train Loss: 0.2692, Val Loss: 0.2709, Test Loss: 0.2698, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 360/500 - Train Loss: 0.2690, Val Loss: 0.2707, Test Loss: 0.2695, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 361/500 - Train Loss: 0.2687, Val Loss: 0.2704, Test Loss: 0.2692, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 362/500 - Train Loss: 0.2684, Val Loss: 0.2701, Test Loss: 0.2690, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 363/500 - Train Loss: 0.2682, Val Loss: 0.2699, Test Loss: 0.2687, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 364/500 - Train Loss: 0.2679, Val Loss: 0.2696, Test Loss: 0.2684, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 365/500 - Train Loss: 0.2676, Val Loss: 0.2694, Test Loss: 0.2682, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 366/500 - Train Loss: 0.2674, Val Loss: 0.2691, Test Loss: 0.2679, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 367/500 - Train Loss: 0.2671, Val Loss: 0.2688, Test Loss: 0.2677, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 368/500 - Train Loss: 0.2668, Val Loss: 0.2686, Test Loss: 0.2674, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 369/500 - Train Loss: 0.2666, Val Loss: 0.2683, Test Loss: 0.2672, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 370/500 - Train Loss: 0.2663, Val Loss: 0.2681, Test Loss: 0.2669, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 371/500 - Train Loss: 0.2661, Val Loss: 0.2678, Test Loss: 0.2666, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 372/500 - Train Loss: 0.2658, Val Loss: 0.2676, Test Loss: 0.2664, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 373/500 - Train Loss: 0.2656, Val Loss: 0.2673, Test Loss: 0.2661, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 374/500 - Train Loss: 0.2653, Val Loss: 0.2671, Test Loss: 0.2659, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 375/500 - Train Loss: 0.2650, Val Loss: 0.2668, Test Loss: 0.2656, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 376/500 - Train Loss: 0.2648, Val Loss: 0.2666, Test Loss: 0.2654, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 377/500 - Train Loss: 0.2645, Val Loss: 0.2663, Test Loss: 0.2651, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 378/500 - Train Loss: 0.2643, Val Loss: 0.2661, Test Loss: 0.2649, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 379/500 - Train Loss: 0.2640, Val Loss: 0.2658, Test Loss: 0.2646, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 380/500 - Train Loss: 0.2638, Val Loss: 0.2656, Test Loss: 0.2644, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 381/500 - Train Loss: 0.2635, Val Loss: 0.2653, Test Loss: 0.2641, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 382/500 - Train Loss: 0.2633, Val Loss: 0.2651, Test Loss: 0.2639, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 383/500 - Train Loss: 0.2630, Val Loss: 0.2649, Test Loss: 0.2636, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 384/500 - Train Loss: 0.2628, Val Loss: 0.2646, Test Loss: 0.2634, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 385/500 - Train Loss: 0.2626, Val Loss: 0.2644, Test Loss: 0.2632, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 386/500 - Train Loss: 0.2623, Val Loss: 0.2641, Test Loss: 0.2629, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 387/500 - Train Loss: 0.2621, Val Loss: 0.2639, Test Loss: 0.2627, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 388/500 - Train Loss: 0.2618, Val Loss: 0.2637, Test Loss: 0.2624, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 389/500 - Train Loss: 0.2616, Val Loss: 0.2634, Test Loss: 0.2622, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 390/500 - Train Loss: 0.2613, Val Loss: 0.2632, Test Loss: 0.2620, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 391/500 - Train Loss: 0.2611, Val Loss: 0.2629, Test Loss: 0.2617, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 392/500 - Train Loss: 0.2609, Val Loss: 0.2627, Test Loss: 0.2615, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 393/500 - Train Loss: 0.2606, Val Loss: 0.2625, Test Loss: 0.2612, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 394/500 - Train Loss: 0.2604, Val Loss: 0.2622, Test Loss: 0.2610, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 395/500 - Train Loss: 0.2601, Val Loss: 0.2620, Test Loss: 0.2608, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 396/500 - Train Loss: 0.2599, Val Loss: 0.2618, Test Loss: 0.2605, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 397/500 - Train Loss: 0.2597, Val Loss: 0.2615, Test Loss: 0.2603, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 398/500 - Train Loss: 0.2594, Val Loss: 0.2613, Test Loss: 0.2601, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 399/500 - Train Loss: 0.2592, Val Loss: 0.2611, Test Loss: 0.2598, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 400/500 - Train Loss: 0.2590, Val Loss: 0.2609, Test Loss: 0.2596, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 401/500 - Train Loss: 0.2587, Val Loss: 0.2606, Test Loss: 0.2594, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 402/500 - Train Loss: 0.2585, Val Loss: 0.2604, Test Loss: 0.2591, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 403/500 - Train Loss: 0.2583, Val Loss: 0.2602, Test Loss: 0.2589, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 404/500 - Train Loss: 0.2580, Val Loss: 0.2599, Test Loss: 0.2587, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 405/500 - Train Loss: 0.2578, Val Loss: 0.2597, Test Loss: 0.2585, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 406/500 - Train Loss: 0.2576, Val Loss: 0.2595, Test Loss: 0.2582, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 407/500 - Train Loss: 0.2574, Val Loss: 0.2593, Test Loss: 0.2580, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 408/500 - Train Loss: 0.2571, Val Loss: 0.2590, Test Loss: 0.2578, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 409/500 - Train Loss: 0.2569, Val Loss: 0.2588, Test Loss: 0.2576, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 410/500 - Train Loss: 0.2567, Val Loss: 0.2586, Test Loss: 0.2573, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 411/500 - Train Loss: 0.2564, Val Loss: 0.2584, Test Loss: 0.2571, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 412/500 - Train Loss: 0.2562, Val Loss: 0.2582, Test Loss: 0.2569, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 413/500 - Train Loss: 0.2560, Val Loss: 0.2579, Test Loss: 0.2567, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 414/500 - Train Loss: 0.2558, Val Loss: 0.2577, Test Loss: 0.2565, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 415/500 - Train Loss: 0.2556, Val Loss: 0.2575, Test Loss: 0.2562, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 416/500 - Train Loss: 0.2553, Val Loss: 0.2573, Test Loss: 0.2560, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 417/500 - Train Loss: 0.2551, Val Loss: 0.2571, Test Loss: 0.2558, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 418/500 - Train Loss: 0.2549, Val Loss: 0.2569, Test Loss: 0.2556, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 419/500 - Train Loss: 0.2547, Val Loss: 0.2566, Test Loss: 0.2554, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 420/500 - Train Loss: 0.2545, Val Loss: 0.2564, Test Loss: 0.2551, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/500 - Train Loss: 0.2542, Val Loss: 0.2562, Test Loss: 0.2549, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 422/500 - Train Loss: 0.2540, Val Loss: 0.2560, Test Loss: 0.2547, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 423/500 - Train Loss: 0.2538, Val Loss: 0.2558, Test Loss: 0.2545, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 424/500 - Train Loss: 0.2536, Val Loss: 0.2556, Test Loss: 0.2543, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 425/500 - Train Loss: 0.2534, Val Loss: 0.2554, Test Loss: 0.2541, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 426/500 - Train Loss: 0.2532, Val Loss: 0.2552, Test Loss: 0.2539, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 427/500 - Train Loss: 0.2529, Val Loss: 0.2549, Test Loss: 0.2537, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 428/500 - Train Loss: 0.2527, Val Loss: 0.2547, Test Loss: 0.2534, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 429/500 - Train Loss: 0.2525, Val Loss: 0.2545, Test Loss: 0.2532, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 430/500 - Train Loss: 0.2523, Val Loss: 0.2543, Test Loss: 0.2530, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 431/500 - Train Loss: 0.2521, Val Loss: 0.2541, Test Loss: 0.2528, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 432/500 - Train Loss: 0.2519, Val Loss: 0.2539, Test Loss: 0.2526, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 433/500 - Train Loss: 0.2517, Val Loss: 0.2537, Test Loss: 0.2524, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 434/500 - Train Loss: 0.2515, Val Loss: 0.2535, Test Loss: 0.2522, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 435/500 - Train Loss: 0.2513, Val Loss: 0.2533, Test Loss: 0.2520, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 436/500 - Train Loss: 0.2511, Val Loss: 0.2531, Test Loss: 0.2518, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 437/500 - Train Loss: 0.2508, Val Loss: 0.2529, Test Loss: 0.2516, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 438/500 - Train Loss: 0.2506, Val Loss: 0.2527, Test Loss: 0.2514, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 439/500 - Train Loss: 0.2504, Val Loss: 0.2525, Test Loss: 0.2512, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 440/500 - Train Loss: 0.2502, Val Loss: 0.2523, Test Loss: 0.2510, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 441/500 - Train Loss: 0.2500, Val Loss: 0.2521, Test Loss: 0.2508, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 442/500 - Train Loss: 0.2498, Val Loss: 0.2519, Test Loss: 0.2506, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 443/500 - Train Loss: 0.2496, Val Loss: 0.2517, Test Loss: 0.2504, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 444/500 - Train Loss: 0.2494, Val Loss: 0.2515, Test Loss: 0.2502, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 445/500 - Train Loss: 0.2492, Val Loss: 0.2513, Test Loss: 0.2500, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 446/500 - Train Loss: 0.2490, Val Loss: 0.2511, Test Loss: 0.2498, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 447/500 - Train Loss: 0.2488, Val Loss: 0.2509, Test Loss: 0.2496, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 448/500 - Train Loss: 0.2486, Val Loss: 0.2507, Test Loss: 0.2494, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 449/500 - Train Loss: 0.2484, Val Loss: 0.2505, Test Loss: 0.2492, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 450/500 - Train Loss: 0.2482, Val Loss: 0.2503, Test Loss: 0.2490, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 451/500 - Train Loss: 0.2480, Val Loss: 0.2501, Test Loss: 0.2488, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 452/500 - Train Loss: 0.2478, Val Loss: 0.2499, Test Loss: 0.2486, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 453/500 - Train Loss: 0.2476, Val Loss: 0.2497, Test Loss: 0.2484, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 454/500 - Train Loss: 0.2474, Val Loss: 0.2495, Test Loss: 0.2482, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 455/500 - Train Loss: 0.2472, Val Loss: 0.2494, Test Loss: 0.2480, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 456/500 - Train Loss: 0.2470, Val Loss: 0.2492, Test Loss: 0.2478, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 457/500 - Train Loss: 0.2469, Val Loss: 0.2490, Test Loss: 0.2476, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 458/500 - Train Loss: 0.2467, Val Loss: 0.2488, Test Loss: 0.2474, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 459/500 - Train Loss: 0.2465, Val Loss: 0.2486, Test Loss: 0.2472, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 460/500 - Train Loss: 0.2463, Val Loss: 0.2484, Test Loss: 0.2471, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 461/500 - Train Loss: 0.2461, Val Loss: 0.2482, Test Loss: 0.2469, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 462/500 - Train Loss: 0.2459, Val Loss: 0.2480, Test Loss: 0.2467, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 463/500 - Train Loss: 0.2457, Val Loss: 0.2478, Test Loss: 0.2465, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 464/500 - Train Loss: 0.2455, Val Loss: 0.2477, Test Loss: 0.2463, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 465/500 - Train Loss: 0.2453, Val Loss: 0.2475, Test Loss: 0.2461, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 466/500 - Train Loss: 0.2451, Val Loss: 0.2473, Test Loss: 0.2459, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 467/500 - Train Loss: 0.2450, Val Loss: 0.2471, Test Loss: 0.2457, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 468/500 - Train Loss: 0.2448, Val Loss: 0.2469, Test Loss: 0.2456, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 469/500 - Train Loss: 0.2446, Val Loss: 0.2467, Test Loss: 0.2454, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 470/500 - Train Loss: 0.2444, Val Loss: 0.2466, Test Loss: 0.2452, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 471/500 - Train Loss: 0.2442, Val Loss: 0.2464, Test Loss: 0.2450, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 472/500 - Train Loss: 0.2440, Val Loss: 0.2462, Test Loss: 0.2448, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 473/500 - Train Loss: 0.2438, Val Loss: 0.2460, Test Loss: 0.2446, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 474/500 - Train Loss: 0.2437, Val Loss: 0.2458, Test Loss: 0.2445, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 475/500 - Train Loss: 0.2435, Val Loss: 0.2457, Test Loss: 0.2443, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 476/500 - Train Loss: 0.2433, Val Loss: 0.2455, Test Loss: 0.2441, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 477/500 - Train Loss: 0.2431, Val Loss: 0.2453, Test Loss: 0.2439, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 478/500 - Train Loss: 0.2429, Val Loss: 0.2451, Test Loss: 0.2437, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 479/500 - Train Loss: 0.2427, Val Loss: 0.2449, Test Loss: 0.2436, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 480/500 - Train Loss: 0.2426, Val Loss: 0.2448, Test Loss: 0.2434, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 481/500 - Train Loss: 0.2424, Val Loss: 0.2446, Test Loss: 0.2432, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 482/500 - Train Loss: 0.2422, Val Loss: 0.2444, Test Loss: 0.2430, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 483/500 - Train Loss: 0.2420, Val Loss: 0.2442, Test Loss: 0.2429, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 484/500 - Train Loss: 0.2419, Val Loss: 0.2441, Test Loss: 0.2427, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 485/500 - Train Loss: 0.2417, Val Loss: 0.2439, Test Loss: 0.2425, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 486/500 - Train Loss: 0.2415, Val Loss: 0.2437, Test Loss: 0.2423, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 487/500 - Train Loss: 0.2413, Val Loss: 0.2436, Test Loss: 0.2422, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 488/500 - Train Loss: 0.2411, Val Loss: 0.2434, Test Loss: 0.2420, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 489/500 - Train Loss: 0.2410, Val Loss: 0.2432, Test Loss: 0.2418, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 490/500 - Train Loss: 0.2408, Val Loss: 0.2430, Test Loss: 0.2416, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 491/500 - Train Loss: 0.2406, Val Loss: 0.2429, Test Loss: 0.2415, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 492/500 - Train Loss: 0.2405, Val Loss: 0.2427, Test Loss: 0.2413, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 493/500 - Train Loss: 0.2403, Val Loss: 0.2425, Test Loss: 0.2411, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 494/500 - Train Loss: 0.2401, Val Loss: 0.2424, Test Loss: 0.2410, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 495/500 - Train Loss: 0.2399, Val Loss: 0.2422, Test Loss: 0.2408, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 496/500 - Train Loss: 0.2398, Val Loss: 0.2420, Test Loss: 0.2406, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 497/500 - Train Loss: 0.2396, Val Loss: 0.2419, Test Loss: 0.2404, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 498/500 - Train Loss: 0.2394, Val Loss: 0.2417, Test Loss: 0.2403, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 499/500 - Train Loss: 0.2393, Val Loss: 0.2415, Test Loss: 0.2401, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n",
      "Epoch 500/500 - Train Loss: 0.2391, Val Loss: 0.2414, Test Loss: 0.2399, Train Acc: 0.9260, Val Acc: 0.9228, Test Acc: 0.9245\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a custom loss function with BCE and MSE\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, weight_bce=0.5, weight_mse=0.5):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.weight_bce = weight_bce\n",
    "        self.weight_mse = weight_mse\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        bce_loss = self.bce_loss(y_pred, y_true)\n",
    "        mse_loss = self.mse_loss(y_pred, y_true)\n",
    "\n",
    "        # Combine BCE and MSE losses\n",
    "        loss = self.weight_bce * bce_loss + self.weight_mse * mse_loss\n",
    "        return loss\n",
    "\n",
    "# Define a custom logistic regression class\n",
    "class CustomLogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(CustomLogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "# Function to train a model with a given loss function\n",
    "def train_model(model, criterion, optimizer, X_train, y_train, X_val, y_val, num_epochs=500):\n",
    "    input_size = X_train.shape[1]\n",
    "\n",
    "    # Convert the data to PyTorch tensors\n",
    "    X_train_tensor = Variable(torch.Tensor(X_train))\n",
    "    y_train_tensor = Variable(torch.Tensor(y_train.values).view(-1, 1))\n",
    "    X_val_tensor = Variable(torch.Tensor(X_val))\n",
    "    y_val_tensor = Variable(torch.Tensor(y_val.values).view(-1, 1))\n",
    "\n",
    "    # Lists to store training and validation loss for each epoch\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Evaluate on training set\n",
    "        with torch.no_grad():\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val_tensor)\n",
    "            val_loss = criterion(val_outputs, y_val_tensor)\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "\n",
    "# Split the dataset into features (X) and labels (y)\n",
    "X = df['Review']\n",
    "y = df['']\n",
    "\n",
    "# Apply SMOTE to handle imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X.values.reshape(-1, 1), y)\n",
    "\n",
    "# Split the resampled data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Vectorize the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train.flatten())\n",
    "X_val_tfidf = vectorizer.transform(X_val.flatten())\n",
    "X_test_tfidf = vectorizer.transform(X_test.flatten())\n",
    "\n",
    "# Initialize the custom logistic regression model\n",
    "input_size = X_train_tfidf.shape[1]\n",
    "model = CustomLogisticRegression(input_size)\n",
    "\n",
    "# Define the custom loss function\n",
    "custom_loss = CustomLoss(weight_bce=1.0, weight_mse=1.0)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 500\n",
    "\n",
    "# Train the model and collect losses\n",
    "train_losses, val_losses = train_model(model, custom_loss, optimizer, X_train_tfidf.toarray(), y_train, X_val_tfidf.toarray(), y_val, num_epochs=num_epochs)\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7eb704fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with BCE Loss\n",
      "Training model with MAE Loss\n",
      "Training model with MSE Loss\n",
      "Training model with Custom Combined Loss\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('final_data.csv')\n",
    "\n",
    "\n",
    "# Define a custom loss function as a combination of MSE and BCE\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, weight_mse=0.5, weight_bce=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.weight_mse = weight_mse\n",
    "        self.weight_bce = weight_bce\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        mse_loss = self.mse_loss(y_pred, y_true)\n",
    "        bce_loss = self.bce_loss(y_pred, y_true)\n",
    "        combined_loss = self.weight_mse * mse_loss + self.weight_bce * bce_loss\n",
    "        return combined_loss\n",
    "\n",
    "# Define a custom logistic regression class\n",
    "class CustomLogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(CustomLogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "# Function to train a model with a given loss function\n",
    "def train_model(model, criterion, optimizer, X_train, y_train, X_val, y_val, num_epochs=500):\n",
    "    input_size = X_train.shape[1]\n",
    "\n",
    "    # Convert the data to PyTorch tensors\n",
    "    X_train_tensor = Variable(torch.Tensor(X_train))\n",
    "    y_train_tensor = Variable(torch.Tensor(y_train.values).view(-1, 1))\n",
    "    X_val_tensor = Variable(torch.Tensor(X_val))\n",
    "    y_val_tensor = Variable(torch.Tensor(y_val.values).view(-1, 1))\n",
    "\n",
    "    # Lists to store training and validation loss for each epoch\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Evaluate on training set\n",
    "        with torch.no_grad():\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val_tensor)\n",
    "            val_loss = criterion(val_outputs, y_val_tensor)\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "\n",
    "# Split the dataset into features (X) and labels (y)\n",
    "X = df['Review']\n",
    "y = df['Category']\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Vectorize the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'BCE Loss': CustomLogisticRegression(X_train_tfidf.shape[1]),\n",
    "    'MAE Loss': CustomLogisticRegression(X_train_tfidf.shape[1]),\n",
    "    'MSE Loss': CustomLogisticRegression(X_train_tfidf.shape[1]),\n",
    "    'Custom Combined Loss': CustomLogisticRegression(X_train_tfidf.shape[1]),\n",
    "}\n",
    "\n",
    "# Define optimizers and loss functions for each model\n",
    "optimizers = {name: optim.SGD(model.parameters(), lr=0.01) for name, model in models.items()}\n",
    "criterion_bce = nn.BCELoss()\n",
    "criterion_mae = nn.L1Loss()\n",
    "criterion_mse = torch.nn.MSELoss()\n",
    "criterion_custom = CombinedLoss(weight_mse=0.5, weight_bce=0.5)\n",
    "\n",
    "# Train models and collect losses\n",
    "all_losses = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training model with {model_name}\")\n",
    "    if model_name == 'BCE Loss':\n",
    "        criterion = criterion_bce\n",
    "    elif model_name == 'MAE Loss':\n",
    "        criterion = criterion_mae\n",
    "    elif model_name == 'MSE Loss':\n",
    "        criterion = criterion_mse\n",
    "    else:\n",
    "        criterion = criterion_custom\n",
    "\n",
    "    optimizer = optimizers[model_name]\n",
    "    train_losses, val_losses = train_model(model, criterion, optimizer, X_train_tfidf.toarray(), y_train, X_val_tfidf.toarray(), y_val)\n",
    "    all_losses[model_name] = {'train_losses': train_losses, 'val_losses': val_losses}\n",
    "\n",
    "# Plot training and validation loss for each model\n",
    "for model_name, losses in all_losses.items():\n",
    "    plt.plot(range(1, num_epochs + 1), losses['train_losses'], label=f'{model_name} - Training Loss')\n",
    "    plt.plot(range(1, num_epochs + 1), losses['val_losses'], label=f'{model_name} - Validation Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('x Log Reg(NN-All): epoch_vs_loss.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a69c4",
   "metadata": {},
   "source": [
    "<h5>Using SMOTE since the dataset is highly imbalanced<h5>\n",
    "    @article{chawla2002smote,\n",
    "  title={SMOTE: synthetic minority over-sampling technique},\n",
    "  author={Chawla, Nitesh V and Bowyer, Kevin W and Hall, Lawrence O and Kegelmeyer, W Philip},\n",
    "  journal={Journal of artificial intelligence research},\n",
    "  volume={16},\n",
    "  pages={321--357},\n",
    "  year={2002}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba919282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading imbalanced_learn-0.11.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (3.2.0)\n",
      "Downloading imbalanced_learn-0.11.0-py3-none-any.whl (235 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.6/235.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.11.0 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34f75e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages (2.1.2)\n",
      "Requirement already satisfied: scikit-learn in /home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages (1.3.2)\n",
      "Requirement already satisfied: imbalanced-learn in /home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages (from pandas) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b084d2c0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Category', 'Review'], dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('final_data.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b85cc5",
   "metadata": {},
   "source": [
    "<h5>Logistic Regression from Sklearn Module with SMOTE<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e826d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples before SMOTE: 12084\n",
      "Number of samples after SMOTE: 13419\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      2794\n",
      "           1       0.78      0.38      0.51       227\n",
      "\n",
      "    accuracy                           0.95      3021\n",
      "   macro avg       0.87      0.69      0.74      3021\n",
      "weighted avg       0.94      0.95      0.94      3021\n",
      "\n",
      "Accuracy: 0.9457133399536577\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming you have a list of texts (X) and corresponding labels (y)\n",
    "# Replace X and y with your actual data\n",
    "\n",
    "# Example:\n",
    "X = df['Review']\n",
    "y = df['Category']  # 1 for positive, 0 for negative\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Specify the desired ratio for the minority class oversampling\n",
    "# In this case, we want to oversample the minority class by a factor of 10\n",
    "sampling_strategy = 0.2\n",
    "\n",
    "# Convert text data to numerical features using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Apply SMOTE to oversample the minority class\n",
    "smote = SMOTE(sampling_strategy=sampling_strategy, random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# Print the number of samples before and after SMOTE\n",
    "print(f\"Number of samples before SMOTE: {len(y_train)}\")\n",
    "print(f\"Number of samples after SMOTE: {len(y_resampled)}\")\n",
    "\n",
    "# Train a classifier on the resampled data\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Convert the test set to TF-IDF\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dd837b",
   "metadata": {},
   "source": [
    "<h5>Vanilla Logistic Regression from Sklearn Module<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6870e779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9417411453161205\n",
      "Confusion Matrix:\n",
      "[[2744   50]\n",
      " [ 126  101]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      2794\n",
      "           1       0.67      0.44      0.53       227\n",
      "\n",
      "    accuracy                           0.94      3021\n",
      "   macro avg       0.81      0.71      0.75      3021\n",
      "weighted avg       0.93      0.94      0.94      3021\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/mlproject/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Assuming you have a DataFrame 'df' with columns 'text' and 'label'\n",
    "# Replace 'your_dataframe' with your actual DataFrame name\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = df['Review']\n",
    "y = df['Category']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text data using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vect, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_vect)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Classification Report:\\n{class_report}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e67b7c3e-0a33-4438-a7db-56e088b223df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples before SMOTE: 12084\n",
      "Number of samples after SMOTE: 13419\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "180 fits failed out of a total of 720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/mrahm/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.8333706  0.8333706  0.8333706         nan 0.8333706\n",
      " 0.8333706  0.8333706         nan 0.8333706  0.8333706  0.8333706\n",
      "        nan 0.8333706  0.85721741 0.85296957        nan 0.8333706\n",
      " 0.85721741 0.85296957        nan 0.8333706  0.85721741 0.85296957\n",
      "        nan 0.8333706  0.8333706  0.8333706         nan 0.8333706\n",
      " 0.8333706  0.8333706         nan 0.8333706  0.8333706  0.8333706\n",
      "        nan 0.83299802 0.86399855 0.86340246        nan 0.83299802\n",
      " 0.86399855 0.86340246        nan 0.83299802 0.86399855 0.86340246\n",
      "        nan 0.86034757 0.85371503 0.8540131         nan 0.86034757\n",
      " 0.85371503 0.8540131         nan 0.86034757 0.85371503 0.8540131\n",
      "        nan 0.83836426 0.88300163 0.88262905        nan 0.83836426\n",
      " 0.88300163 0.88262905        nan 0.83836426 0.88300163 0.88262905\n",
      "        nan 0.90938233 0.91295964 0.91295958        nan 0.90938233\n",
      " 0.91295964 0.91295958        nan 0.90938233 0.91295964 0.91295958\n",
      "        nan 0.8961178  0.91258684 0.91273587        nan 0.8961178\n",
      " 0.91258684 0.91273587        nan 0.8961178  0.91258684 0.91273587\n",
      "        nan 0.94947539 0.95133839 0.95111479        nan 0.94947539\n",
      " 0.95111479 0.95111479        nan 0.94947539 0.95111479 0.95111479\n",
      "        nan 0.93919129 0.93635941 0.93635941        nan 0.93919129\n",
      " 0.93635941 0.93635941        nan 0.93919129 0.93635941 0.93635941\n",
      "        nan 0.94954993 0.9590886  0.95908866        nan 0.94954993\n",
      " 0.95923769 0.95908866        nan 0.94954993 0.95923769 0.95908866\n",
      "        nan 0.94209762 0.94619604 0.94619601        nan 0.94209762\n",
      " 0.94619601 0.94619601        nan 0.94209762 0.94619601 0.94619601]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 100, 'class_weight': None, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best Accuracy:  0.9592376907536717\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      2794\n",
      "           1       0.53      0.51      0.52       227\n",
      "\n",
      "    accuracy                           0.93      3021\n",
      "   macro avg       0.74      0.73      0.74      3021\n",
      "weighted avg       0.93      0.93      0.93      3021\n",
      "\n",
      "Accuracy: 0.9285004965243296\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming you have a DataFrame 'df' with columns 'Review' and 'Category'\n",
    "X = df['Review']\n",
    "y = df['Category']  # 1 for positive, 0 for negative\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Specify the desired ratio for the minority class oversampling\n",
    "# In this case, we want to oversample the minority class by a factor of 10\n",
    "sampling_strategy = 0.2\n",
    "\n",
    "# Convert text data to numerical features using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Apply SMOTE to oversample the minority class\n",
    "smote = SMOTE(sampling_strategy=sampling_strategy, random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# Print the number of samples before and after SMOTE\n",
    "print(f\"Number of samples before SMOTE: {len(y_train)}\")\n",
    "print(f\"Number of samples after SMOTE: {len(y_resampled)}\")\n",
    "\n",
    "# Define the logistic regression model\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Define the hyperparameters to search\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'max_iter': [100, 500, 1000],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(logreg_model, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Fit the GridSearchCV object to the resampled data\n",
    "grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Print the best parameters and their corresponding accuracy\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Accuracy: \", grid_search.best_score_)\n",
    "\n",
    "# Use the best model for predictions on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "y_pred = best_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a30d85e",
   "metadata": {},
   "source": [
    "<h4>2.3 Roberta-Large<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a513b981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Category', 'Review'], dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('final_data.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e8ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "train_encodings = tokenizer(list(train_df['Review']), truncation=True, padding=True, max_length=256, return_tensors='pt')\n",
    "val_encodings = tokenizer(list(val_df['Review']), truncation=True, padding=True, max_length=256, return_tensors='pt')\n",
    "test_encodings = tokenizer(list(test_df['Review']), truncation=True, padding=True, max_length=256, return_tensors='pt')\n",
    "\n",
    "# Create custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = CustomDataset(train_encodings, list(train_df['Category']))\n",
    "val_dataset = CustomDataset(val_encodings, list(val_df['Category']))\n",
    "test_dataset = CustomDataset(test_encodings, list(test_df['Category']))\n",
    "\n",
    "# Initialize RoBERTa model\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-large')\n",
    "\n",
    "# Initialize optimizer and criterion\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Create DataLoader for training, validation, and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_loss += loss.item()\n",
    "        _, predicted = outputs.logits.max(1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_losses.append(epoch_train_loss / len(train_loader))\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            epoch_val_loss += loss.item()\n",
    "            _, predicted = outputs.logits.max(1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += predicted.eq(labels).sum().item()\n",
    "\n",
    "    val_accuracy = correct_val / total_val\n",
    "    val_losses.append(epoch_val_loss / len(val_loader))\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "# Testing\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "test_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        _, predicted_labels = torch.max(logits, 1)\n",
    "        test_predictions.extend(predicted_labels.cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate test accuracy\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Loss plots\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy plots\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562c629d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97118876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4df4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e97b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fcbbfce",
   "metadata": {},
   "source": [
    "<h2>LDA and feature mapping has been performed on LDA.ipynb file<h2>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
